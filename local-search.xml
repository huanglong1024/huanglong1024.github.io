<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>【月报】2024-01-繁花</title>
    <link href="/2024/01/31/2024-01/"/>
    <url>/2024/01/31/2024-01/</url>
    
    <content type="html"><![CDATA[<p><img src="/../img/fanhua.jpeg" alt="繁花"></p><blockquote><p>2023年一年没怎么看过剧，没想到2024年一开始就一头扎进了追剧的浪潮中～</p></blockquote><h2 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h2><ol><li><p>因为所做的新项目需要和公司內的其他服务做深度集成，兄弟团队又没有足够的人手，这个月开始，我需要帮助团队做一些 inner source 的工作，以完成兄弟团队所承担的部分。不过我挺开心的，学到了不少兄弟团队的东西，对 V1 的整体业务理解也更深刻了一些。</p></li><li><p>认识的好几个同事去 Canada 了，不过他们说那边吃的贼贵，自己做饭吃，好多人都瘦了，Ca 生活水深火热啊朋友😂</p></li><li><p>公司年会办的比去年简陋了些，不过奖品还是一如既往的丰厚，发了好多 iphone 和 ipad，运气有点小差，只得到一个安慰奖。不过年会举办点——园博园倒是出奇意料的大，到处逛了逛，挺不错的。</p></li></ol><h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><h3 id="书籍"><a href="#书籍" class="headerlink" title="书籍"></a>书籍</h3><p>今年给自己订了三百个小时的阅读任务，希望自己可以多读多看多充实。万事开头难，第一个月算是开了一个不错的头，读了不少书。技术为主，闲读为辅。</p><ul><li><p>《计算机是怎样跑起来的》&amp;《程序是怎样跑起来的》</p><blockquote><p>一个作者写的，因为成书已经十几年了，书中所举的有些例子稍显过时了。不过这两本书的前几章对我来说还是值得一看的。</p></blockquote></li><li><p>《深入理解 nginx》 进行中</p><blockquote><p>一直以来对 nginx 始终不是很了解，nginx 网络真是博大精深啊～</p></blockquote></li><li><p>《Flink原理与实践》</p><blockquote><p>重新看了一遍 flink 的知识，虽然我平时用不上，不过还是对大数据的相关技术栈抱有一定兴趣。</p></blockquote></li><li><p>《变形记》</p><blockquote><p>读的过程中，我一直幻想着某天格里高尔能从甲虫重新变成人，可惜并没有奇迹发生。卡夫卡给了他同自己命运一般的安排，也如这个世界上的绝大多数人一样。</p></blockquote></li><li><p><a href="https://spark-reference-doc-cn.readthedocs.io/zh-cn/latest/index.html">Spark 2.2.x 中文官方参考文档</a></p><blockquote><p>在越来越强调实时的时代里，Spark 仍然有他的位置。</p></blockquote></li></ul><h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><h3 id="看剧"><a href="#看剧" class="headerlink" title="看剧"></a>看剧</h3><p>我不是一个经常看剧的人，一来是国内大多数电视剧都拍的比较一般，鲜有好剧。偶尔有几部还不错的剧集(比如去年国内比较热的《狂飙》和《漫长的季节》等)，我又没有那么多空闲的时间去追，基本都是快速过一遍评价和剧情居多。不过今年初，王家卫+胡歌的组合还是吸引了我，和平饭店，黄河路的霓虹，股市中的造福神话和天台孤影，以及那个年代的人情。繁花一场游戏一场梦。</p><h2 id="随便看看-amp-听听"><a href="#随便看看-amp-听听" class="headerlink" title="随便看看&amp;听听"></a>随便看看&amp;听听</h2><h3 id="播客"><a href="#播客" class="headerlink" title="播客"></a>播客</h3><p><a href="https://podcasts.apple.com/cn/podcast/%E5%9F%BA%E6%9C%AC%E6%97%A0%E5%AE%B3-mostly-harmless/id1512748339?i=1000643424571">基本无害：扬州生存手册</a></p><p><a href="https://podcasts.apple.com/cn/podcast/109-%E7%89%B9%E6%96%AF%E6%8B%89cybertruck-%E4%B8%8A-%E8%80%81%E7%BE%8E%E7%9A%AE%E5%8D%A1%E6%8C%87%E5%8D%97-%E5%AF%B9%E8%AF%9D%E5%98%89%E5%AE%BE-%E8%AE%B8%E6%96%B0%E7%86%A0-%E8%80%81%E5%8D%B0/id1586870724?i=1000642208455">孤岛车谈：特斯拉 Cybetruck</a></p><h3 id="开心一下"><a href="#开心一下" class="headerlink" title="开心一下"></a>开心一下</h3><p><a href="https://www.zhihu.com/question/641338592">如何看待前端大佬【黄玄】参加也许你要恋爱了相亲节目？</a>  </p><p>虽然不是搞前端的，不过在上学那会儿之前就有关注黄玄了，当时还是赖佬推荐给我的。偶尔也会点进黄玄的博客看看。这次在推特上看到不少前端开源圈子的人转这个恋综，感觉还挺有意思的，就快速看了下。这下真前端娱乐圈了。</p>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>月报</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【技术修养】关于工程素养</title>
    <link href="/2024/01/05/engineering-literacy/"/>
    <url>/2024/01/05/engineering-literacy/</url>
    
    <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>我是学软件工程专业的，大学那会，软件工程是我们的必修课，有3个学分。教那门课的老师经常提醒我们，作为软件工程专业的学生，你们得有工程能力。造一架飞机是一个工程，挖一条隧道是一个工程，做一个软件也是一个工程，得有工程师的思维，得有全局意识。</p><p>老实说，这些话，我到现在也是一知半解。</p><p>写这篇文章仅仅是对自己目前的所学的一个小的总结，仅仅从个人的角度，聊聊一个软件工程师，特别是后端软件工程师，需要具备咋样的工程素养。此篇也是自己对相关知识体系的一个简单梳理，用于后面自查。</p><p><img src="/../img/%E5%B7%A5%E7%A8%8B%E7%B4%A0%E5%85%BB.png"></p><h2 id="计算机基础知识"><a href="#计算机基础知识" class="headerlink" title="计算机基础知识"></a>计算机基础知识</h2><p>基础知识是作为一个程序员的内功。基座得搭好，上层建筑才稳当。这些知识自己也都还在不断学习之中，简短称述一下以自勉。</p><ul><li>操作系统与计算机组成原理</li><li>计算机网络</li><li>数据结构与算法</li><li>编程语言</li><li>软件架构+数据库+中间件+领域知识</li><li>实践能力+工具链使用</li></ul><h2 id="开发规范"><a href="#开发规范" class="headerlink" title="开发规范"></a>开发规范</h2><h3 id="项目结构规范"><a href="#项目结构规范" class="headerlink" title="项目结构规范"></a>项目结构规范</h3><p>搭建项目软件开发的第一步，如何划分是个细致活。对于 java 而言，看过的很多项目结构都大差不差，对于 go lang 而言，就有不少分歧。举个简单的例子，比如 golang 的项目中，不少开源的论坛和文章中倡导去掉 dto 层，利用 golang struct 中的 tag 来做扩展，来定义 dto 的返回对象字段(reference: <a href="https://dsysd-dev.medium.com/stop-using-dtos-in-go-its-not-java-96ef4794481a">Stop Using DTOs in Go, It’s Not Java</a>)。golang is not java！(😂)</p><p>这里简单陈列下网上 java 和 golang 的项目结构（仅做参考）</p><ul><li><a href="https://segmentfault.com/a/1190000022110134">java项目结构</a></li><li><a href="https://makeoptim.com/golang/standards/project-layout/">golang 编程规范 - 项目目录结构</a></li></ul><h3 id="编程语言规范"><a href="#编程语言规范" class="headerlink" title="编程语言规范"></a>编程语言规范</h3><p>一些开源的代码规范。</p><ul><li>java <ul><li>Google java 风格指南：<a href="https://google.github.io/styleguide/">https://google.github.io/styleguide/</a></li><li>阿里巴巴java开发手册：<a href="https://github.com/mysterin/alibaba-java-specification/blob/master/alibaba-java-specification.md">https://github.com/mysterin/alibaba-java-specification/blob/master/alibaba-java-specification.md</a></li><li>腾讯 java 安全指南：<a href="https://github.com/Tencent/secguide/blob/main/Java%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97.md">https://github.com/Tencent/secguide/blob/main/Java%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97.md</a></li></ul></li><li>golang<ul><li>Google golang 风格指南：<a href="https://google.github.io/styleguide/">https://google.github.io/styleguide/</a></li><li>Uber golang 风格指南：<a href="https://github.com/uber-go/guide?tab=readme-ov-file">https://github.com/uber-go/guide?tab=readme-ov-file</a></li><li>腾讯 go 代码规范：<a href="https://www.cnblogs.com/xuweiqiang/p/15337132.html">https://www.cnblogs.com/xuweiqiang/p/15337132.html</a></li><li>腾讯 golang 安全指南：<a href="https://github.com/Tencent/secguide/blob/main/Go%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97.md">https://github.com/Tencent/secguide/blob/main/Go%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97.md</a></li></ul></li></ul><h3 id="Git-规范"><a href="#Git-规范" class="headerlink" title="Git 规范"></a>Git 规范</h3><p>好的代码提交规范是项目的生命线。</p><p>【git 分支与代码提交规范】</p><ul><li>小批量代码提交，每次代码提交时尽可能&lt;=400行</li></ul><p>【git commit log 规范】</p><p>通用Commit Message 格式如下。</p><p>目前规范使用较多的是 <a href="https://github.com/angular/angular.js/blob/master/DEVELOPERS.md#-git-commit-guidelines">Angular 团队的规范 </a>, 继而衍生了 <a href="https://www.conventionalcommits.org/en/v1.0.0/">Conventional Commits specification</a>. 很多工具也是基于此规范, 它的 message 格式如下:</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-params">&lt;type&gt;</span>(<span class="hljs-params">&lt;scope&gt;</span>): <span class="hljs-params">&lt;subject&gt;</span><br><span class="hljs-comment">// 空一行</span><br><span class="hljs-params">&lt;body&gt;</span><br><span class="hljs-comment">// 空一行</span><br><span class="hljs-params">&lt;footer&gt;</span><br></code></pre></td></tr></table></figure><blockquote><p>备注：</p><p>git commit 提交时需要换行时，请使用Bash命令行的Git，你可以执行以下操作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">&gt;</span><span class="bash">git commit -m <span class="hljs-string">&quot;this is</span></span><br><span class="hljs-meta">&gt;</span><span class="bash"><span class="hljs-string">&gt; a line</span></span> <br><span class="hljs-meta">&gt;</span><span class="bash"><span class="hljs-string">&gt; with new lines</span></span><br><span class="hljs-meta">&gt;</span><span class="bash"><span class="hljs-string">&gt; maybe&quot;</span></span><br></code></pre></td></tr></table></figure><ul><li>-m 后面使用双引号</li><li>换行时，直接按回车enter键</li><li>log输入完后，输入“ ，再回车就可以commit成功了</li></ul></blockquote><p><strong>简单汇总：</strong></p><img src="/../img/git_specification.png" alt="image-20220922183347992" style="zoom:67%;"><p>Reference:</p><ul><li><a href="https://github.com/angular/angular/blob/22b96b9/CONTRIBUTING.md#-commit-message-guidelines">Angular git 提交信息规范</a></li><li><a href="https://zjdoc-gitguide.readthedocs.io/zh-cn/latest/index.html">开源文档 GitGuide</a></li></ul><h3 id="CodeReview"><a href="#CodeReview" class="headerlink" title="CodeReview"></a>CodeReview</h3><blockquote><p>当我在CR的时候，我在CR什么？</p></blockquote><p>硅谷的知名互联网公司，都搞merge request/push request合入mainline之前的code review。Google为了保证review质量，还搞了Readability认证。网上有很多<a href="https://www.pullrequest.com/blog/google-code-review-readability-certification/">资料、报道</a>有讲解到。Google在<a href="https://google.github.io/eng-practices/review/reviewer/looking-for.html">公开网站</a>上也有说到。</p><p>Code Review 的大方向</p><p><img src="/../img/code_review_specification.png" alt="code review"></p><p>Reference:</p><ul><li><p><a href="https://google.github.io/eng-practices">Google Engineering Practices Documentation</a></p></li><li><p><a href="https://lib.jimmysong.io/eng-practices/">谷歌工程实践 宋净超中文翻译版</a></p></li></ul><h3 id="代码坏味道"><a href="#代码坏味道" class="headerlink" title="代码坏味道"></a>代码坏味道</h3><p>写一份好的代码，拒绝坏味道。</p><p>Reference:</p><ul><li><a href="https://book-refactoring2.ifmicro.com/docs/ch3.html">重构-代码坏味道</a></li><li><a href="https://juejin.cn/post/6962812178537644063">25种代码坏味道总结+优化示例</a></li></ul><h3 id="主干开发？大仓小仓之争？开发流程理念的理解"><a href="#主干开发？大仓小仓之争？开发流程理念的理解" class="headerlink" title="主干开发？大仓小仓之争？开发流程理念的理解"></a>主干开发？大仓小仓之争？开发流程理念的理解</h3><p>在我人生第一家公司那里，我第一次了解到了大仓的概念。依稀记得当时公司内有很多大仓小仓的讨论，是屠龙术还是前朝宝剑斩今朝的官，大家各说纷云。不管用哪种，都了解一下其中的利弊，也挺好的。</p><p>Reference:</p><ul><li><a href="https://zhuanlan.zhihu.com/p/28524745">为什么Google上十亿行代码都放在同一个仓库里?</a></li><li><a href="https://cloud.tencent.com/developer/article/1881386">从微信后端仓库发展史谈谈单仓和多仓</a></li><li><a href="https://36kr.com/p/1218375440667012">Google 和腾讯为什么都采用主干开发模式？</a></li><li><a href="https://juejin.cn/post/6967981728619544606">特性分支开发模式 or 主干开发模式，团队该如何选择？</a></li><li><a href="https://codec.wang/blog/mono-repo-in-js">大仓实践录：Lerna/NPM/Yarn Workspace 方案组合和性能对比</a></li><li><a href="https://my.oschina.net/u/5783135/blog/10750685">前端 monorepo 大仓权限设计的思考与实现</a></li></ul><h2 id="项目管理能力"><a href="#项目管理能力" class="headerlink" title="项目管理能力"></a>项目管理能力</h2><p>不要只是低头写代码，有时候，也得抬头看看上下游，看看这艘船到哪了。</p><ul><li>需求分析要透彻</li><li>协调上下流的沟通能力</li><li>能合理规划开发流程和进度</li><li>及时暴露问题</li></ul><p>Reference:</p><ul><li><a href="https://github.com/zhengda/The-Mythical-Man-Month-zh/blob/main/docs/README.md">人月神话</a></li></ul><h2 id="文档撰写能力"><a href="#文档撰写能力" class="headerlink" title="文档撰写能力"></a>文档撰写能力</h2><blockquote><p>绝大部分的程序员都讨厌写文档，但又讨厌别人不写文档。</p></blockquote><p>个人的理解上，我们需要掌握以下文档的编写：</p><ul><li>需求分析文档：一般产品会写需求文档PRD，但是作为程序员，我们也应该具备撰写需求分析文档的能力。</li><li>架构设计文档：对项目的整体架构设计</li><li>技术设计文档：仅需要概要设计文档，详细设计就是代码本身</li><li>API参考文档（reference doc）一般由代码直接生成。它的量是最大的，变更最频繁的</li><li>SDK或者框架使用文档/教程：自己封装的SDK、框架等，写个详细的教程传递出去，让更多人用</li><li>技术分享文档：个人的技术输出，当然了，很多时候也用 PPT，我更喜欢用文档。</li><li>Readme文档：每个项目的介绍文档，这个还挺重要的，一份好的 readme 就是一个项目最好的”个人简历”</li><li>新人文档：帮助团队新同学快速了解团队工作内容，快速融入。我个人认为这个很重要，一份好的新人文档也相当于对自己团队的工作内容总结和工作要求说明。</li></ul><p>Reference:</p><ul><li><a href="https://github.com/google/styleguide/blob/gh-pages/docguide/README.md">Google documentation guide</a></li><li><a href="https://github.com/ruanyf/document-style-guide">中文技术文档的写作规范 阮一峰</a> </li></ul><h2 id="测试能力"><a href="#测试能力" class="headerlink" title="测试能力"></a>测试能力</h2><p>作为一个有责任心的程序员，从来不是写完代码就完事了。我们得保证代码的质量，除了依靠测试同学的努力，自身也得投入部分精力。据我所知，现在很多大厂都会要求编程人员写单测，搞测试左移，这也被称之为 TDD，即测试驱动开发。这种做法是否有效，有多大效果我这里不想高谈阔论。但是我个人觉得，自己写的代码，自测的质量是一定要保证的。</p><h2 id="软件维护能力"><a href="#软件维护能力" class="headerlink" title="软件维护能力"></a>软件维护能力</h2><p><img src="/../img/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F.png" alt="软件工程生命周期"></p><p>​                                     软件生命周期</p><p>从软件工程的角度来说，软件的维护占据了其生命周期的绝大部分。如果维护软件的正常运行，又如何度量软件的运行质量呢？这里我简单说两个我个人比较关心的点——SLA 和 Troubleshooting。</p><h3 id="SLA"><a href="#SLA" class="headerlink" title="SLA"></a>SLA</h3><p>一般软件服务都会有 SLA 的保证，特别是对中台类型的服务。SLA 是服务质量的重要衡量指标。其主要的衡量纬度如下：</p><ul><li><p>服务可用性</p></li><li><p>错误率</p></li><li><p>安全性</p></li><li><p>响应时间</p></li><li><p>业务成果</p></li><li><p>首次呼叫解决率</p></li><li><p>放弃率</p></li></ul><p>Reference:</p><ul><li><a href="https://aws.amazon.com/cn/what-is/service-level-agreement/">什么是服务等级协议（SLA）</a></li></ul><h3 id="Troubleshooting"><a href="#Troubleshooting" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h3><p>Troubleshooting = trouble(问题/故障) + shooter(射手/枪手)</p><blockquote><p>简而言之：用 shooter 将 trouble maker 解决掉</p></blockquote><p><img src="/../img/troubleshooting%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F.png"></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术修养</tag>
      
      <tag>工程素养</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2023年终总结--探索更大的世界和生活</title>
    <link href="/2024/01/01/2023-year-end-summary/"/>
    <url>/2024/01/01/2023-year-end-summary/</url>
    
    <content type="html"><![CDATA[<h1 id="2023年终总结–探索更大的世界和生活"><a href="#2023年终总结–探索更大的世界和生活" class="headerlink" title="2023年终总结–探索更大的世界和生活"></a>2023年终总结–探索更大的世界和生活</h1><p>在提笔写之前，我又重新去翻看了我去年的年终总结。那时候的我，刚换了一份新的工作，来到了新的城市，幻想着新的生活。我在文中的最后自问：“2023 年呢？有什么规划吗？想去做什么？” 我没有答案。直到今天，我想我可以去回答这个问题了。</p><p>还是先简单聊聊工作吧。今年在 TrendMicro 度过了完整的一年，主要的工作还是项目的各种开发事宜。年初的时候帮助团队调研 open telemetry 的技术方案，在 Azure 环境上搭建好了一个基本可实施的线上环境，用我们目前在跑的 web 后台服务进行了一个简单的集成，并在团队中进行了相关技术分享。但是最终这个方案还是没有被采纳。一方面我们目前的服务量级并没有那么大，这个阶段做这种集成收益并不那么显著。另一方面，我们了解到公司内部 SRE 团队也在搭建公司级别的 open telemetry 平台，我们可以等他们实践完再做权衡，或者等他们平台稳定了，考虑接入他们的平台，对我们来说，更为方便，毕竟不需要多花人力来维护平台，成本上是更为划算的。不过相关的 research 和分享也让我自己和团队的同事对这方面的技术有了更为深入的了解，也减少了我们后续接入公司相关平台的认知学习时间。年中的时候，作为核心开发参与了团队新项目的整体架构设计和核心代码研发。根据业务的服务边界设计了整体的微服务架构，并调研了 GRPC 框架，帮助团队设计和实施了GRPC 服务 IDL 文件管理的方案，即采用镜像仓库 + api 大仓(通过结构来划分领域) + semantic version. 同时，因为该项目需求的缘故，对市场上的 golang 的规则引擎和 SQL builder 方案进行了一次 research, 研究了不少开源库，比如 gendry, govaluate 等等，甚有收获。同时这个研发过程中，自己对于 Azure 上的相关组件（如service bus，adx）的使用也更为了解。十月份的时候，又开始了另一个新项目的 research 工作 ，做了大量的业务和技术方案调研，目前该项目的 POC 工作基本完成，总体的服务架构设计也基本就绪，处于技术研发的阶段中，估计得明年 Q1 才能 release 了。</p><p>学习上，今年看了不少的书。根据微信读书的统计，本年度总共看了 130 个小时，读完了15 本书籍，书籍分类上，看的最多的还是计算机相关的。除了微信读书，我另一个偏好就是看一些开源社区的文章和一些官方的技术文档，并且逐渐开始尝试看一些英文的资料，比如 HackerNews，Medium 这样的站点，个人体验上，有些英文的技术文章确实写的很好，深度和广度都很不错的，不过想系统的学习某一类知识，还是看书和官方的技术文档更成体系。这里简单分享一些我今年看过并且觉得还不错的书。</p><ul><li>《万历十五年》</li><li>《冬牧场》</li><li>《智慧的疆界》</li><li>《硅谷之火》</li><li>《Unix 传奇》</li><li>《大规模分布式存储系统》</li><li>《网络是怎样链接的》</li><li>《k8s 权威指南》</li><li>《当我谈跑步时，我谈些什么》</li></ul><p>另外，我从去年开始听小宇宙的播客，老实话，这给我打开了一扇窗，让我看到了更广阔的世界。根据小宇宙的统计，我去年一共听了八百多个小时的时长，算得上是小宇宙的高强度使用人群了。我习惯于听一些技术博客，比如开源面对面，RustTalk ，从零道一，还有 ggtalk 等等。里面讨论了很多程序员职业发展相关的话题，当然也有一些生活上的闲谈。正所谓以人为鉴，可明得失。听这些计算机界的前辈们聊聊技术，谈谈人生，也是一件趣事。另外基本无害和随机游走也是我钟爱的节目，遗憾的是老徐的随机游走今年还没有更新节目，似乎放弃维护了？这倒是让我想起了我非常喜欢的一个开源博主，面向信仰编程，他也不再更新的新的文章了，我在推特上关注了他，了解到他离开了 Shopee ，似乎去了创业公司。写博客和做播客都是兴趣，每个人都有自己的生活，兴趣终有一天会消散，但是留下的足迹却让他人受益匪浅。这是我理解的开源的意义。</p><p>除此之外，本年度我最想完成的一个学习项是学好英语。但很遗憾，我没能很好的完成任务。我能很长时间投入去写一段代码，去看一本书，去排查一个 bug ，但是我很难花一个小时全身心的投入去背单词，或者练习口语。感觉还是意志力的问题吧，我的意志力还是太差了。不过三天打鱼 两天晒网，终归是比没打鱼的强。自我感觉现在的英语水平相较于 2023 年年初还是有不少进步的，阅读大部分的英文技术文档都能大概看懂，只是口语上还是欠缺很多。希望 2024 年，英语水平能再进一步。</p><p>聊完了工作与学习，再聊聊生活。</p><p>骑行上，今年骑行了江心洲，将军山，中山陵，以及记不清的南京的大街小巷。也买了不少的装备，比如夜间的尾灯，头盔，骑行服等，看着还真有模有样的。不过大都时候还是啥都不带，拎着车就直接开骑了，简单干脆。另外，因为组内同事的邀请，也报名参加了公司的吉他培训班。买了一把入门的雅马哈 F310，跟着老师每两周上一次课。我比较懒，每次都要到上课前一天晚上疯狂练习，像是回到了开学前狂补作业的学生时代。不过马马虎虎的练习倒也有些收获，现在也能大差不差的跟着五线谱弹上那么一小段，当然，只能弹入门的小曲，大横按和快速的大调切换还是手忙脚乱。此外，今年也看了不少的电影，剧集和动漫。这些是闲适的放松时刻。其中很多已经记不清了，有些记忆深刻的，在此简单做个记录。</p><ul><li>老友记第一季到第十季</li><li>蒙古草原，天气晴</li><li>铃芽之旅</li><li>迷失东京</li><li>西部世界</li></ul><p>最后，聊聊旅行。我非常喜欢 b 站上的一位 up 主，Linksphotograph。他是一个风光摄影师，爬山，摄影，探索世界是他生活的主格调。如果你拍的不够好，那是因为你离的还不够近。我也因为他的影响，买入了人生的第一台相机。虽然不能跟他一样洒脱，但我也学着 Links 一样，踏出了脚步，去感受路。</p><p>今年去过很多地方，五月份去了上海，感受了外滩的繁华，武康路的民国小巷，参观了世博馆，并赶上了正在举办的梵高展览，踏入了梵高的世界。六月份去了一趟庐山，山上的牯岭小镇真的很漂亮，东线和西线景色各异，山风清凉。还废了老大劲去看了三叠泉瀑布，可惜水流不大，但是那三千多个台阶至今回想起来还是后怕。另外，五老峰的云海和庐山的日出也是别样的美景。八月份的时候，去了一趟杭州，晚上围着西湖，走了好几个小时。路过断桥，桥上挤满了人，人头攒动。不过离开断桥后，人流就少了不少，晚上西湖的风吹的很舒服，走了几个小时也不觉得累。十二月初，去日本待了十来天，体验了异国的风土人情。去过福冈，熊本，阿苏火山，别府，汤布院，京都，奈良还有大阪。我非常喜欢熊本和京都，可能是喜欢动漫吧，熊本和京都会有一种让我走进动漫世界的感觉。阿苏火山是从山底徒步上去的，登山的风景很是开阔，冷风很大，行走之间，像是漫步在旷野。另外，去过的这些城市都有很多的神社，印象最深的是京都的八坂神社，夜间的灯笼泛着白光，很是纯净。如果有机会的，还想再去一次，去看看东京，看看富士山。</p><p>好了，洋洋洒洒写了一大堆，也到了该收尾的时候了。我不想重复去年的话术，说自己不知道想干什么，只想正确的浪费时间。我知道我想干什么，我想攀更高的峰，走更多的路，看更多的书，我还想在技术领域上能有更长足的进步，如果能有幸能参与一两个开源项目那就更好了。这就是我2024年的规划。</p><p>就写这么多了，明年见朋友们。</p>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>年终总结</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【月报】2023-12-日本自由行</title>
    <link href="/2023/12/31/2023-12/"/>
    <url>/2023/12/31/2023-12/</url>
    
    <content type="html"><![CDATA[<p><img src="/../img/qingshuishi.jpg" alt="清水寺"></p><blockquote><p>清水寺</p></blockquote><h2 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h2><ol><li>去日本参加了公司的 AI Contest 活动，第一参加这种类型的活动，感觉还是挺新奇的，也玩的很开心。希望公司能越来越好～</li></ol><h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><h3 id="书籍"><a href="#书籍" class="headerlink" title="书籍"></a>书籍</h3><ul><li><p>《深入理解 java 虚拟机》</p><blockquote><p>常读常新。</p></blockquote></li><li><p>《大规模分布式存储系统：原理解析与架构实战》</p><blockquote><p>前面几章还是不错的，能够感受出作者的知识面很广</p></blockquote></li></ul><h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><h3 id="下雪了"><a href="#下雪了" class="headerlink" title="下雪了"></a>下雪了</h3><p>南京连续下了几天的雪，白茫茫的一片。对于一个没怎么见过雪的南方人来说，太福音了。</p><h3 id="日本自由行"><a href="#日本自由行" class="headerlink" title="日本自由行"></a>日本自由行</h3><p>十二月初，去日本待了十来天，体验了异国的风土人情。去过福冈，熊本，阿苏火山，别府，汤布院，京都，奈良还有大阪。我非常喜欢熊本和京都，可能是喜欢动漫吧，熊本和京都会有一种让我走进动漫世界的感觉。阿苏火山是从山底徒步上去的，登山的风景很是开阔，冷风很大，行走之间，像是漫步在旷野。另外，去过的这些城市都有很多的神社，印象最深的是京都的八坂神社，夜间的灯笼泛着白光，很是纯净。如果有机会的，还想再去一次，去看看东京，看看富士山。</p><h2 id="随便看看-amp-听听"><a href="#随便看看-amp-听听" class="headerlink" title="随便看看&amp;听听"></a>随便看看&amp;听听</h2><h3 id="基本无害"><a href="#基本无害" class="headerlink" title="基本无害"></a>基本无害</h3><ul><li><p><a href="https://podcasts.apple.com/cn/podcast/%E5%9F%BA%E6%9C%AC%E6%97%A0%E5%AE%B3-mostly-harmless/id1512748339?i=1000633387461">EP105 南京生存手册：谁问你上哪个大学了？</a></p></li><li><p><a href="https://podcasts.apple.com/cn/podcast/%E5%9F%BA%E6%9C%AC%E6%97%A0%E5%AE%B3-mostly-harmless/id1512748339?i=1000633387461">EP107 南京生存手册：从吃到逛，一期解决</a></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>月报</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【月报】2023-11-红猪</title>
    <link href="/2023/12/01/2023-11/"/>
    <url>/2023/12/01/2023-11/</url>
    
    <content type="html"><![CDATA[<p><img src="/../img/hongzhu.png" alt="红猪"></p><blockquote><p>红猪：亚德里亚海最自由的飞行员</p></blockquote><h2 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h2><ol><li><p>leader 的签证之前已经下来了，跟着公司其他人一样，这个月一起去 Canada 办公了。开始了 Canada 和 南京这边 co-work 。</p></li><li><p>团建攻防箭，体验了一把🏹，现在回想起来还觉得有意思。</p></li></ol><h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><h3 id="书籍"><a href="#书籍" class="headerlink" title="书籍"></a>书籍</h3><ul><li><p>《硅谷简史》</p><blockquote><p>前半部对于像晶体三极管这些电子科技发展奠基和应用的先行者们，只能感叹这些人的智商天赋和才能。但对于乔布斯盖茨和埃里森却是能印象深刻的记住，都是“不疯魔不成活”。对于自己所在行业的前瞻性，不光有专业才能还有强大的管理销售才能，坚决果断的魄力，造就了现在如雷贯耳的企业帝国。勇者中原逐鹿，智者商海弄潮。</p></blockquote></li></ul><h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><h3 id="红猪"><a href="#红猪" class="headerlink" title="红猪"></a>红猪</h3><p>宫崎骏的影片总是反复出现一些意象，好比唐诗中的秋叶春红。天空应该是他最钟爱的情感，一睁开眼睛，什么也听不见。那一种平静里，连自己都被忘却。海涛显然是另一种，潜在水底的时候，也是睁开眼睛，什么也听不见。因此水上飞机是最好的连接，有天空，有海涛。其实人类也是水天之间最好的连接，他们可以在白云里看见海面的倒影，也可以在水中仰望蓝天。天空，海，人，当他们在一起的时候，世界就是善良的。</p><p>红猪是自由的！</p><h3 id="接待超哥"><a href="#接待超哥" class="headerlink" title="接待超哥"></a>接待超哥</h3><p>和超哥大学毕业就没有再见了。这次超哥来南京玩，就好好的做了一回地陪。去了中山陵，吃了南京大排档，还去栖霞山那里看了看枫叶。于超哥于我，都是一个闲暇的周末。</p><h2 id="随便看看-amp-听听"><a href="#随便看看-amp-听听" class="headerlink" title="随便看看&amp;听听"></a>随便看看&amp;听听</h2><h3 id="播客"><a href="#播客" class="headerlink" title="播客"></a>播客</h3><ul><li><p><a href="https://podcasts.apple.com/cn/podcast/%E7%AC%AC-9-%E6%9C%9F-%E6%BD%98%E5%B0%91%E7%BB%99-go-%E8%AF%AD%E8%A8%80%E5%81%9A%E8%B4%A1%E7%8C%AE%E7%9A%84%E8%89%B0%E9%9A%BE%E5%8E%86%E7%A8%8B/id1538614001?i=1000637699855">【Go 夜聊】潘少给 go 语言做贡献</a></p><blockquote><p>第一次知道潘少这个名字还是在 ”腾讯KM(腾讯内网)“ 里面拜读了潘少发表的文章，当时顺着潘少的个人主页看完了潘少的所有文章。想不到有一天能在播客中见到潘少的名字哈哈哈哈哈</p></blockquote></li></ul>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>月报</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【技术修养】漫谈定时任务</title>
    <link href="/2023/11/12/scheduled-tasks/"/>
    <url>/2023/11/12/scheduled-tasks/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在很多的业务场景中，我们都会使用到定时任务。这篇文章简单对定时任务的一些原理和业界的方案进行整理和归纳。其中参考和引用的网络资料出处在Reference标注。</p><h2 id="Linux-定时任务"><a href="#Linux-定时任务" class="headerlink" title="Linux 定时任务"></a>Linux 定时任务</h2><h3 id="定时任务调度分类"><a href="#定时任务调度分类" class="headerlink" title="定时任务调度分类"></a>定时任务调度分类</h3><p>Linux 下的定时任务调度分为两类：系统任务调度和用户任务调度。</p><p>系统任务是由 cron (crond) 系统服务来控制的，这个系统服务是默认启动的。用户自己设置的计划任务则使用 crontab 命令。在 velinux 系统中，查看配置文件如下：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs awk">root@i-<span class="hljs-number">2</span>udbbtytcx3gv6bvmhzb:~<span class="hljs-comment"># cat /etc/crontab</span><br><span class="hljs-comment"># /etc/crontab: system-wide crontab</span><br><span class="hljs-comment"># Unlike any other crontab you don&#x27;t have to run the `crontab&#x27;</span><br><span class="hljs-comment"># command to install the new version when you edit this file</span><br><span class="hljs-comment"># and files in /etc/cron.d. These files also have username fields,</span><br><span class="hljs-comment"># that none of the other crontabs do.</span><br><br>SHELL=<span class="hljs-regexp">/bin/</span>sh<br>PATH=<span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/sbin:/u</span>sr<span class="hljs-regexp">/local/</span>bin:<span class="hljs-regexp">/sbin:/</span>bin:<span class="hljs-regexp">/usr/</span>sbin:<span class="hljs-regexp">/usr/</span>bin<br><br><span class="hljs-comment"># Example of job definition:</span><br><span class="hljs-comment"># .---------------- minute (0 - 59)</span><br><span class="hljs-comment"># |  .------------- hour (0 - 23)</span><br><span class="hljs-comment"># |  |  .---------- day of month (1 - 31)</span><br><span class="hljs-comment"># |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...</span><br><span class="hljs-comment"># |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat</span><br><span class="hljs-comment"># |  |  |  |  |</span><br><span class="hljs-comment"># *  *  *  *  * user-name command to be executed</span><br><span class="hljs-number">17</span> *    * * *   root    cd <span class="hljs-regexp">/ &amp;&amp; run-parts --report /</span>etc/cron.hourly<br><span class="hljs-number">25</span> <span class="hljs-number">6</span>    * * *   root    test -x <span class="hljs-regexp">/usr/</span>sbin<span class="hljs-regexp">/anacron || ( cd /</span> &amp;&amp; run-parts --report <span class="hljs-regexp">/etc/</span>cron.daily )<br><span class="hljs-number">47</span> <span class="hljs-number">6</span>    * * <span class="hljs-number">7</span>   root    test -x <span class="hljs-regexp">/usr/</span>sbin<span class="hljs-regexp">/anacron || ( cd /</span> &amp;&amp; run-parts --report <span class="hljs-regexp">/etc/</span>cron.weekly )<br><span class="hljs-number">52</span> <span class="hljs-number">6</span>    <span class="hljs-number">1</span> * *   root    test -x <span class="hljs-regexp">/usr/</span>sbin<span class="hljs-regexp">/anacron || ( cd /</span> &amp;&amp; run-parts --report <span class="hljs-regexp">/etc/</span>cron.monthly )<br></code></pre></td></tr></table></figure><p>第一行 SHELL 变量指定了系统要使用哪个 shell，这里是 sh；第二行 PATH 变量指定了系统执行命令的路径； 用户定期的任务，比如系统信息收集。用户可以使用 crontab 。用户定义的 crontab 文件都被保存在 /var/spool/cron/crontabs 目录中。文件名为用户名。velinux 如下：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs awk">root@i-<span class="hljs-number">2</span>udbbtytcx3gv6bvmhzb:<span class="hljs-regexp">/var/</span>spool<span class="hljs-regexp">/cron/</span>crontabs<span class="hljs-comment"># pwd</span><br><span class="hljs-regexp">/var/</span>spool<span class="hljs-regexp">/cron/</span>crontabs<br>root@i-<span class="hljs-number">2</span>udbbtytcx3gv6bvmhzb:<span class="hljs-regexp">/var/</span>spool<span class="hljs-regexp">/cron/</span>crontabs<span class="hljs-comment"># cat root </span><br><span class="hljs-comment"># DO NOT EDIT THIS FILE - edit the master and reinstall.</span><br><span class="hljs-comment"># (/tmp/crontab.LlqJMX/crontab installed on Thu Mar 24 15:09:50 2022)</span><br><span class="hljs-comment"># (Cron version -- $Id: crontab.c,v 2.13 1994/01/17 03:20:37 vixie Exp $)</span><br><span class="hljs-comment"># Edit this file to introduce tasks to be run by cron.</span><br><span class="hljs-comment"># </span><br><span class="hljs-comment"># Each task to run has to be defined through a single line</span><br><span class="hljs-comment"># indicating with different fields when the task will be run</span><br><span class="hljs-comment"># and what command to run for the task</span><br><span class="hljs-comment"># </span><br><span class="hljs-comment"># To define the time you can provide concrete values for</span><br><span class="hljs-comment"># minute (m), hour (h), day of month (dom), month (mon),</span><br><span class="hljs-comment"># and day of week (dow) or use &#x27;*&#x27; in these fields (for &#x27;any&#x27;).</span><br><span class="hljs-comment"># </span><br><span class="hljs-comment"># Notice that tasks will be started based on the cron&#x27;s system</span><br><span class="hljs-comment"># daemon&#x27;s notion of time and timezones.</span><br><span class="hljs-comment"># </span><br><span class="hljs-comment"># Output of the crontab jobs (including errors) is sent through</span><br><span class="hljs-comment"># email to the user the crontab file belongs to (unless redirected).</span><br><span class="hljs-comment"># </span><br><span class="hljs-comment"># For example, you can run a backup of all your user accounts</span><br><span class="hljs-comment"># at 5 a.m every week with:</span><br><span class="hljs-comment"># 0 5 * * 1 tar -zcf /var/backups/home.tgz /home/</span><br><span class="hljs-comment"># </span><br><span class="hljs-comment"># For more information see the manual pages of crontab(5) and cron(8)</span><br><span class="hljs-comment"># </span><br><span class="hljs-comment"># m h  dom mon dow   command</span><br>* * * * * <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/go/</span>bin<span class="hljs-regexp">/go run /</span>root<span class="hljs-regexp">/go/</span>src<span class="hljs-regexp">/auto/m</span>ain.go &gt;&gt; <span class="hljs-regexp">/root/g</span>o<span class="hljs-regexp">/src/</span>auto/load.log <span class="hljs-number">2</span>&gt;&amp;<span class="hljs-number">1</span> &amp;<br></code></pre></td></tr></table></figure><h3 id="Crontab-的工作原理"><a href="#Crontab-的工作原理" class="headerlink" title="Crontab 的工作原理"></a>Crontab 的工作原理</h3><p>Crontab 由一个名为”Crond”的守护进程负责调度任务，当 Crond 启动的时候，就会从配置文件（路径在 /var/spool/cron 下）加载所有的定时任务。当执行 crontab 命令的时候，会动态的添加新的定时任务，并加入到配置文件中。Crontab 每次执行任务，都会产生执行记录，目录在 /var/log/cron 下。</p><p><img src="/../img/crontab_exec_flow.png" alt="crontab 执行原理"></p><h3 id="Crontab-的痛点问题"><a href="#Crontab-的痛点问题" class="headerlink" title="Crontab 的痛点问题"></a>Crontab 的痛点问题</h3><img src="/../img/crontab_difficult_problem.png" alt style="zoom:50%; div align: center;"><p>使用 crontab 主要有如下痛点：</p><ul><li><strong>无高可用：</strong>为了保证业务幂等执行，需要在不同的机器配置不同的 crontab 任务。crontab 只能调度本机器上的定时任务，如果某一个机器挂了，那上面的定时任务也都不会执行了，有稳定性风险。</li><li><strong>无自动负载均衡：</strong>不同的脚本放在不同的机器上，需要手动负载均衡，如果脚本比较多，运维代价很高。</li><li><strong>无权限隔离：</strong>一般企业生产的机器只有运维才能登陆，但是开发要新增/修改脚本和定时任务，也需要登录到生产的机器上，没法做到权限隔离。</li></ul><h2 id="Quartz"><a href="#Quartz" class="headerlink" title="Quartz"></a>Quartz</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>Quartz是Java领域最著名的开源任务调度工具。Quartz提供了极为广泛的特性如持久化任务，集群和分布式任务等，其特点如下：</p><ul><li>完全由Java写成，方便集成(Spring)</li><li>伸缩性</li><li>负载均衡</li><li>高可用性</li></ul><h3 id="quartz基本原理"><a href="#quartz基本原理" class="headerlink" title="quartz基本原理"></a>quartz基本原理</h3><h4 id="核心元素"><a href="#核心元素" class="headerlink" title="核心元素"></a>核心元素</h4><p>Quartz核心要素有Scheduler、Trigger、Job、JobDetail，其中trigger和job、jobDetail为元数据，而Scheduler为实际进行调度的控制器。</p><ul><li>Trigger</li></ul><p>Trigger用于定义调度任务的时间规则，在Quartz中主要有四种类型的Trigger：SimpleTrigger、CronTrigger、DataIntervalTrigger和NthIncludedTrigger。</p><ul><li>Job&amp;Jodetail</li></ul><p>Quartz将任务分为Job、JobDetail两部分，其中Job用来定义任务的执行逻辑，而JobDetail用来描述Job的定义（例如Job接口的实现类以及其他相关的静态信息）。对Quartz而言，主要有两种类型的Job，StateLessJob、StateFulJob</p><ul><li>Scheduler</li></ul><p>实际执行调度逻辑的控制器，Quartz提供了DirectSchedulerFactory和StdSchedulerFactory等工厂类，用于支持Scheduler相关对象的产生。</p><h4 id="核心元素间关系"><a href="#核心元素间关系" class="headerlink" title="核心元素间关系"></a>核心元素间关系</h4><p><img src="/../img/quartz_job_relation.png"></p><h4 id="主要线程"><a href="#主要线程" class="headerlink" title="主要线程"></a>主要线程</h4><p>在Quartz中，有两类线程，也即执行线程和调度线程，其中执行任务的线程通常用一个线程池维护。线程间关系如图1-2所示。</p><p><img src="/../img/quartz_main_thread.png" alt="img"> </p><p>在quartz中，Scheduler调度线程主要有两个：regular Scheduler Thread（执行常规调度）和Misfire Scheduler Thread（执行错失的任务）。其中Regular Thread 轮询Trigger，如果有将要触发的Trigger，则从任务线程池中获取一个空闲线程，然后执行与改Trigger关联的job；Misfire Thraed则是扫描所有的trigger，查看是否有错失的，如果有的话，根据一定的策略进行处理。</p><h4 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h4><p>Quartz中的trigger和job需要存储下来才能被使用。Quartz中有两种存储方式：RAMJobStore,JobStoreSupport，其中RAMJobStore是将trigger和job存储在内存中，而JobStoreSupport是基于jdbc将trigger和job存储到数据库中。RAMJobStore的存取速度非常快，但是由于其在系统被停止后所有的数据都会丢失，所以在集群应用中，必须使用JobStoreSupport。其中表结构如表1-1所示。</p><table><thead><tr><th>Table name</th><th>Description</th></tr></thead><tbody><tr><td>QRTZ_CALENDARS</td><td>存储Quartz的Calendar信息</td></tr><tr><td>QRTZ_CRON_TRIGGERS</td><td>存储CronTrigger，包括Cron表达式和时区信息</td></tr><tr><td>QRTZ_FIRED_TRIGGERS</td><td>存储与已触发的Trigger相关的状态信息，以及相联Job的执行信息</td></tr><tr><td>QRTZ_PAUSED_TRIGGER_GRPS</td><td>存储已暂停的Trigger组的信息</td></tr><tr><td>QRTZ_SCHEDULER_STATE</td><td>存储少量的有关Scheduler的状态信息，和别的Scheduler实例</td></tr><tr><td>QRTZ_LOCKS</td><td>存储程序的悲观锁的信息</td></tr><tr><td>QRTZ_JOB_DETAILS</td><td>存储每一个已配置的Job的详细信息</td></tr><tr><td>QRTZ_SIMPLE_TRIGGERS</td><td>存储简单的Trigger，包括重复次数、间隔、以及已触的次数</td></tr><tr><td>QRTZ_BLOG_TRIGGERS</td><td>Trigger作为Blob类型存储</td></tr><tr><td>QRTZ_TRIGGERS</td><td>存储已配置的Trigger的信息</td></tr><tr><td>QRTZ_SIMPROP_TRIGGERS</td><td></td></tr></tbody></table><h3 id="quartz集群原理"><a href="#quartz集群原理" class="headerlink" title="quartz集群原理"></a>quartz集群原理</h3><p>一个Quartz集群中的每个节点是一个独立的Quartz应用，它又管理着其他的节点。这就意味着你必须对每个节点分别启动或停止。Quartz集群中，独立的Quartz节点并不与另一其的节点或是管理节点通信，而是通过相同的数据库表来感知到另一Quartz应用的，如图1-3所示。</p><p><img src="/../img/quartz_cluster_1.png" alt="img"></p><h2 id="XXL-Job"><a href="#XXL-Job" class="headerlink" title="XXL Job"></a>XXL Job</h2><h3 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h3><p>XXL-JOB是一个分布式任务调度平台，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。现已开放源代码并接入多家公司线上产品线，开箱即用。</p><h3 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h3><h4 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h4><p><img src="/../img/springboot-xxl-job-8.png" alt="springboot-xxl-job"></p><h4 id="设计思想"><a href="#设计思想" class="headerlink" title="设计思想"></a>设计思想</h4><p>将调度行为抽象形成“调度中心”公共平台，而平台自身并不承担业务逻辑，“调度中心”负责发起调度请求。</p><p>将任务抽象成分散的JobHandler，交由“执行器”统一管理，“执行器”负责接收调度请求并执行对应的JobHandler中业务逻辑。</p><p>因此，“调度”和“任务”两部分可以相互解耦，提高系统整体稳定性和扩展性；</p><h4 id="系统组成"><a href="#系统组成" class="headerlink" title="系统组成"></a>系统组成</h4><ol><li>调度模块（调度中心） <ol><li>负责管理调度信息，按照调度配置发出调度请求，自身不承担业务代码。调度系统与任务解耦，提高了系统可用性和稳定性，同时调度系统性能不再受限于任务模块；</li><li>支持可视化、简单且动态的管理调度信息，包括任务新建，更新，删除，GLUE开发和任务报警等，所有上述操作都会实时生效，同时支持监控调度结果以及执行日志，支持执行器Failover。</li></ol></li><li>执行模块（执行器）： <ol><li>负责接收调度请求并执行任务逻辑。任务模块专注于任务的执行等操作，开发和维护更加简单和高效；</li><li>接收“调度中心”的执行请求、终止请求和日志请求等。</li></ol></li></ol><h3 id="xxl-job与quartz"><a href="#xxl-job与quartz" class="headerlink" title="xxl-job与quartz"></a>xxl-job与quartz</h3><p><img src="/../img/compare_xxljob_quartz.png"></p><p>整体来说，xxl-job就是quartz的一个增强版，其弥补了quartz不支持并行调度，不支持失败处理策略和动态分片的策略等诸多不足，同时其有管理界面，上手比较容易，支持分布式，适用于分布式场景下的使用。两者相同的是都是通过数据库锁来控制任务不能重复执行。</p><h2 id="K8s-Cronjob"><a href="#K8s-Cronjob" class="headerlink" title="K8s Cronjob"></a>K8s Cronjob</h2><h3 id="什么是-K8s-CronJob"><a href="#什么是-K8s-CronJob" class="headerlink" title="什么是 K8s CronJob"></a>什么是 K8s CronJob</h3><p>Job 是 K8s 中的一种资源，用来处理短周期的 Pod，相当于一次性任务，跑完就会把 Pod 销毁，不会一直占用资源，可以节省成本，提高资源利用率。CronJob 也是 K8s 中的资源，用来周期性的重复调度 Job。</p><p>下面是一个 CronJob 的示例，每隔 5 分钟调度脚本 edas/schedulerx-job.sh：</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-symbol">apiVersion:</span> batch/v1<br><span class="hljs-symbol">kind:</span> CronJob<br><span class="hljs-symbol">metadata:</span><br><span class="hljs-symbol">  name:</span> hello<br><span class="hljs-symbol">spec:</span><br><span class="hljs-symbol">  schedule:</span> <span class="hljs-string">&quot;*/5 * * * *&quot;</span><br><span class="hljs-symbol">  jobTemplate:</span><br><span class="hljs-symbol">    spec:</span><br><span class="hljs-symbol">      template:</span><br><span class="hljs-symbol">        spec:</span><br><span class="hljs-symbol">          containers:</span><br>          - name: hello<br><span class="hljs-symbol">            image:</span> busybox:<span class="hljs-number">1.28</span><br><span class="hljs-symbol">            imagePullPolicy:</span> IfNotPresent<br><span class="hljs-symbol">            command:</span> [<span class="hljs-string">&quot;/bin/sh&quot;</span>, <span class="hljs-string">&quot;/root/script/edas/schedulerx-job.sh&quot;</span>]<br><span class="hljs-symbol">          restartPolicy:</span> OnFailure<br></code></pre></td></tr></table></figure><h3 id="K8s-CronJob-的优势"><a href="#K8s-CronJob-的优势" class="headerlink" title="K8s CronJob 的优势"></a>K8s CronJob 的优势</h3><p><img src="/../img/k8s_cronjob_1.png" alt="image"></p><p>与单纯使用 Crontab 相比，使用 K8s CronJob 带来了如下优势：</p><ul><li><strong>高可用：</strong>K8s 会保证集群的高可用，如集群中有节点挂了，都不会影响定时任务的调度。</li><li><strong>自动负载均衡：</strong>Pod 默认选择负载最低的 node 执行，支持 NodeSelector 和亲和性等多种负载均衡策略。</li><li><strong>权限隔离：</strong>只有运维可以登录 master 和 worker 节点，开发通过管控或者 ApiServer 来创建和更新 CronJob，并且支持命名空间隔离，RBAC 权限管理。</li></ul><h3 id="K8s-CronJob-的进阶能力"><a href="#K8s-CronJob-的进阶能力" class="headerlink" title="K8s CronJob 的进阶能力"></a>K8s CronJob 的进阶能力</h3><p>Linux Crontab 只能周期性调度本机的脚本，功能比较简单，K8s 定时任务支持更多的进阶能力：</p><ul><li><p>在 Job 资源上</p></li><li><p><strong>并行执行：</strong>通常一个 Job 只启动一个 Pod，可以通过配置 spec.completions 参数，来决定一个 Job 要执行多少个 Pod。</p></li><li><p><strong>索引任务：</strong>并行执行通常需要和索引任务结合使用，当配置 .spec.completionMode=”Indexed” 时，这个 Job 就是一个索引任务，每个 Pod 会获得一个不同的索引值，介于 0 和 .spec.completions-1 之间，这样就可以让不同的 Pod 根据索引值处理不同的数据。</p></li><li><p><strong>并行限流：</strong>并行执行的时候，通常还需要做限流，可以配置 .spec.parallelism 参数，来控制一个 Job 最多同时跑多少个 Pod。</p></li><li><p><strong>失败自动重试：</strong>可以配置 .spec.backoffLimit，来设置 Job 失败重试次数。</p></li><li><p><strong>超时：</strong>可以配置 .spec.activeDeadlineSeconds，来设置 Job 超时的时间。</p></li><li><p>在 CronJob 资源上</p></li><li><p><strong>时区：</strong>可以通过设置 .spec.timeZone 参数，决定 CronJob 按照哪个时区的时间来调度任务。</p></li><li><p><strong>并发性规则：</strong>当一个 Job 还在执行，下次调度时间到了，是否执行新的 Job，可以通过 .spec.concurrencyPolicy 来配置，取值为 Allow/Forbid/Replace。</p></li><li><p><strong>任务历史限制：</strong>可以通过配置 .spec.successfulJobsHistoryLimit 和 .spec.failedJobsHistoryLimit 来决定保留多少成功和失败的 Job。</p></li></ul><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><p><a href="https://www.quartz-scheduler.org/documentation/">quartz-scheduler 官方文档</a></p></li><li><p><a href="https://tech.meituan.com/2014/08/31/mt-crm-quartz.html">Quartz应用与集群原理分析</a></p></li><li><p><a href="https://juejin.cn/post/6844903760624353293">Quartz原理解密</a></p></li><li><p><a href="https://www.xuxueli.com/xxl-job/">xxl-job 官方开源社区</a></p></li><li><p><a href="https://developer.volcengine.com/articles/7281495167642894395">如何使用Linux crontab实现定时任务</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/341363916">万字长文简单明了的介绍xxl-job以及quartz</a></p></li><li><p><a href="https://developer.aliyun.com/article/1384887">从 Linux Crontab 到 K8s CronJob，定时任务正在经历怎样的变革</a></p></li><li><p><a href="https://yangxikun.com/kubernetes/2020/09/29/kubernetes-cronjob.html">Kubernetes CronJob 完全指南</a></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术修养</tag>
      
      <tag>定时任务</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【月报】2023-10-硅谷之火</title>
    <link href="/2023/11/01/2023-10/"/>
    <url>/2023/11/01/2023-10/</url>
    
    <content type="html"><![CDATA[<p><img src="/../img/guiguzhihuo.png" alt="硅谷之火"></p><blockquote><p>一群天才碰撞出的火花</p></blockquote><h2 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h2><ul><li>开始新的项目 research</li><li>因为项目需要，玩了玩 powershell, 感觉还是设计的挺不错的</li></ul><h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><h3 id="书籍"><a href="#书籍" class="headerlink" title="书籍"></a>书籍</h3><ul><li>《硅谷之火》</li></ul><blockquote><p>能够感受到作者对乔布斯是有偏爱的，花了更多的笔墨来介绍苹果公司的发展史，对windows的故事缺少了一些描述，不过每个人都有各自的喜好，这无可厚非。在我看来，两者都是优秀的操作系统，都是计算机革命的弄潮儿。<br>另外，本书更吸引我的是那些默默无名的计算机发烧友，计算机杂志社，家酿计算机俱乐部，开源文化和分享精神，以及那些能在几个月，几周，几天，甚至一个晚上完成软／硬件设计的计算机前辈先驱们。这些人和事铸就了个人计算机的伟大基座。</p></blockquote><h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><h3 id="回老家"><a href="#回老家" class="headerlink" title="回老家"></a>回老家</h3><p>自从我上大学以后，除了过年和必要的事情，基本很少回老家。这次回老家，感觉老家县城的变化真的很大。广场那边做了重新的装修，入驻了很多新的商户，甚至小县城也能有星巴克了。因为没带充电宝，我在星巴克里点了杯卡布奇诺，一边充电，一边看着这个小县城。像是回到了上学那会。</p><h2 id="随便看看-amp-听听"><a href="#随便看看-amp-听听" class="headerlink" title="随便看看&amp;听听"></a>随便看看&amp;听听</h2><h3 id="播客"><a href="#播客" class="headerlink" title="播客"></a>播客</h3><ul><li><p><a href="https://podcasts.apple.com/cn/podcast/ep17-%E6%9D%8E%E8%BF%9E%E6%B1%9F-%E5%9C%A8%E5%AD%A6%E6%9C%AF%E7%95%8C%E8%B0%8B%E7%94%9F%E5%AD%98/id1551291600?i=1000564935495">【随机游走】 Ep17 李连江：在学术界谋生存</a></p><blockquote><p>先在别人的游戏规则里打败别人，再制定自己的规则</p></blockquote></li></ul><h3 id="闲看一下"><a href="#闲看一下" class="headerlink" title="闲看一下"></a>闲看一下</h3><ul><li><p><a href="https://zh.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%86%E5%8F%B2%E5%8D%9A%E7%89%A9%E9%A6%86">计算机历史博物馆</a></p><blockquote><p>希望有一天能亲自去山景城那看一看</p></blockquote></li></ul>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>月报</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【月报】2023-09-音乐沙龙</title>
    <link href="/2023/10/01/2023-09/"/>
    <url>/2023/10/01/2023-09/</url>
    
    <content type="html"><![CDATA[<p><img src="/../img/yinyueshalong.png" alt="音乐沙龙"></p><blockquote><p>公司音乐俱乐部的音乐沙龙活动</p></blockquote><h2 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h2><ul><li>公司音乐俱乐部办了一个音乐沙龙，挺好玩的。</li></ul><h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><h3 id="书籍"><a href="#书籍" class="headerlink" title="书籍"></a>书籍</h3><ul><li><p>《Linux 内核设计的艺术》</p><blockquote><p>计算机系统里没有魔法，一切都是有迹可循的。</p></blockquote></li><li><p>《献给阿尔吉侬的花束》</p><blockquote><p>第 n 遍看了。再见纪尼安小姐，再见斯特劳斯先生，再见大家。阿尔吉侬的坟山会有大家的鲜花，幸运兔脚也一定会给查理带来好运。</p></blockquote></li></ul><h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><h3 id="随便骑骑"><a href="#随便骑骑" class="headerlink" title="随便骑骑"></a>随便骑骑</h3><p>周末骑着单车，从下午一点到晚上九点，在南京的大街小巷上无目的的穿梭。放松的一天。</p><h2 id="随便看看-amp-听听"><a href="#随便看看-amp-听听" class="headerlink" title="随便看看&amp;听听"></a>随便看看&amp;听听</h2><h3 id="播客"><a href="#播客" class="headerlink" title="播客"></a>播客</h3><ul><li><p><a href="https://podcasts.apple.com/cn/podcast/%E7%A6%81%E6%AD%A2%E6%90%BA%E5%B8%A6/id1642054238?i=1000620646202">禁止携带：太原日记</a></p><blockquote><p>希望有一天能去太原看一看</p></blockquote></li></ul><h3 id="献给阿尔吉侬的花束"><a href="#献给阿尔吉侬的花束" class="headerlink" title="献给阿尔吉侬的花束"></a>献给阿尔吉侬的花束</h3><p>第一集：<a href="https://www.bilibili.com/video/BV1mL411b7ek/?spm_id_from=333.788&vd_source=af5b17760a20bb0e435ef05c825f2f19">请问视频里有多少错别字？《献给阿尔吉侬的花束》近步抱告1：我要变匆名</a><br>第二集：<a href="https://www.bilibili.com/video/BV1Yy4y1G7Ea/?spm_id_from=333.788&vd_source=af5b17760a20bb0e435ef05c825f2f19">我变聪明了，你会喜欢我吗？《献给阿尔吉侬的花束》进步报告2：智慧让我更孤独</a><br>第三集：<a href="https://www.bilibili.com/video/BV1Mg411V7Xg/?spm_id_from=333.788&vd_source=af5b17760a20bb0e435ef05c825f2f19">我达到了人类智力巅峰，但时间不多了《献给阿尔吉侬的花束》进步报告3：也许我的时间不多了</a><br>第四集：<a href="https://www.bilibili.com/video/BV1bQ4y1a7Es/?spm_id_from=333.788&vd_source=af5b17760a20bb0e435ef05c825f2f19">抱歉，最后带着泪录完的《献给阿尔吉侬的花束》进步报告4：我本可以容忍黑暗，如果我不曾见过光明</a></p>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>月报</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【技术修养】如何学习一门新技术/领域</title>
    <link href="/2023/09/13/How-to-learn-a-new-technology-or-field/"/>
    <url>/2023/09/13/How-to-learn-a-new-technology-or-field/</url>
    
    <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>作为一个软件工程师，时刻都面临着新的技术，新的领域。做新的需求，需要用到不曾学过的技术，换了公司，业务方向有了大的改变。如何快速的了解一个新的技术/领域，是我们经常面对的难题。这里我简单聊聊我自己的一些想法和实践。</p><p>总的来说，我将如何快速学习一门新技术/领域的过程分为三步。</p><p><img src="/../img/enter_new_tech_or_territory.png" alt="enter new tech or territory"></p><h2 id="Research"><a href="#Research" class="headerlink" title="Research"></a>Research</h2><p>Research 即学习资料的获取，好的资料是学习效果的第一前提。于我而言，我一般倾向于下面这几种渠道来获取资料。</p><ul><li><p>google 搜索</p><blockquote><p>一般来说 Google 搜索的结果的质量会高一些。</p><p>google + 英文搜索 &gt; google + 中文搜索 &gt; Baidu + 中文搜索</p></blockquote></li><li><p>github</p><blockquote><p>打个比方，如果你想学习 java，你可以直接在 github 上检索 awesome java，这样你会找一个别人整理好的 repo, 里面是关于 java 学习的资料汇总。对 golang, python 等同理</p><p>另外，如果你想学习某个技术栈，你可以直接搜索这个技术栈的 git 仓库，一方面，你可以研读这个技术的代码实现，同时，你也可以从这个 wiki 中找到相关的指引。</p><p>另外，从官方的一些 repo 中，你可以关注一下里面的 PMC，commiter, 一般来说，这些都是对这个技术有过深入理解的人，你可以关注下这些人是否有写什么博客，是不是和你想学的技术相关。</p></blockquote></li><li><p>官方文档</p><blockquote><p>官方文档是学习技术的第一手资料。</p></blockquote></li><li><p>经典书籍</p><blockquote><p>我一般会在知乎和豆瓣上搜索相关的书籍，根据图书的评价来决定是否值得一读。另外，一般你在知乎上搜索如何某个领域的图书推荐，一些知乎的用户也会给出自己的推荐。</p></blockquote></li><li><p>极客时间</p><blockquote><p>极客时间里面的有些课程还是挺好的，值得学习。</p></blockquote></li><li><p>开源博客或文档</p><blockquote><p>就像我现在维护的自己的小站，网上也有很多开源的博客和开源文档。其中不乏高质量的。当然，一般你可以通过 google 来找到这些网站。</p></blockquote></li><li><p>YouTube</p><blockquote><p>youtube 上有很多技术博主和技术教程，而且对于有些技术来说，先看一遍视频，感受一下技术最终的落地效果会加快你的学习进度和你对技术的理解。</p></blockquote></li></ul><h2 id="Learning-amp-Practice"><a href="#Learning-amp-Practice" class="headerlink" title="Learning&amp;Practice"></a>Learning&amp;Practice</h2><p>当检索好资料后，就进入了学习阶段。一般来说，如果是工程性质比较强的技术，光阅读资料是不够的，还得动手实践才行。</p><p>我个人的实践是，先看一遍资料。有了一个基本的理解之后，我会开始做一个小的 demo 项目，先跑起来。感觉只有这样，这个技术才算是初步的技术落地了。跑 demo 是我个人认为学习技术栈和组件最重要的一步。</p><p>至于学习计划的执行，这个就看每个人的自制力和时间安排了。</p><h2 id="Summarize"><a href="#Summarize" class="headerlink" title="Summarize"></a>Summarize</h2><p>学习的总结是很有必要的。</p><p>在上一步学习和练习的过程中，最好是有做笔记的习惯。好记性不如烂笔头，在记笔记的过程中，也会加深你的理解，并且方便你日后复习和总结。</p><p>另外，在学习完一门技术/领域之后，可以做一个简单的归纳或者脑图，梳理成一个知识框架，加入到你原先的知识框架之内。这样方便我们站在一个全局的维度去理解。</p><p>笔记软件来说，我个人是采用 markdown + git repo 的形式来进行管理的。当然有些人习惯用 notion 或者其他的笔记软件也都 OK。重要是合适自己的习惯就行。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术修养</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【技术转载】分布式事务和系统底层原理揭秘</title>
    <link href="/2023/09/12/distributed-transactions/"/>
    <url>/2023/09/12/distributed-transactions/</url>
    
    <content type="html"><![CDATA[<blockquote><p>这篇是转载潘少的文章。</p><p>原文地址：<a href="https://mp.weixin.qq.com/s/qyL9XzEUNpOfpwQbASKPiQ">link</a></p><p>潘少的博客:  <a href="https://strikefreedom.top/">https://strikefreedom.top/</a></p></blockquote><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>分布式事务是分布式系统必不可少的组成部分，基本上只要实现一个分布式系统就逃不开对分布式事务的支持。本文从分布式事务这个概念切入，尝试对分布式事务以及分布式系统最核心的底层原理逐一进行剖析，内容包括但不限于 <strong>BASE 原则</strong>、<strong>两阶段原子提交协议</strong>、<strong>三阶段原子提交协议</strong>、<strong>Paxos/Multi-Paxos 分布式共识算法的原理与证明</strong>、<strong>Raft 分布式共识算法</strong>和<strong>分布式事务的并发控制</strong>等内容。</p><p><em><strong>事务</strong></em>是访问并可能更新各种数据项的一个程序执行<strong>单元</strong>(unit)。事务由一个或多个步骤组成，一般使用形如 <code>begin transaction</code> 和 <code>end transaction</code> 语句或者函数调用作为事务界限，事务内的所有步骤必须作为一个单一的、不可分割的单元去执行，因此事务的结果只有两种：1. 全部步骤都执行完成，2. 任一步骤执行失败则整个事务回滚。</p><p>事务最早由数据库管理系统(<strong>database management system</strong>，<strong>DBMS</strong>)引入并实现，<strong>数据库事务</strong>是数据库管理系统执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成。数据库事务严格遵循 <code>ACID</code> 原则，属于刚性事务，一开始数据库事务仅限于对单一数据库资源对象的访问控制，这一类事务称之为<strong>本地事务</strong> (Local Transaction)，后来随着分布式系统的出现，数据的存储也不可避免地走向了分布式，<strong>分布式事务</strong>（Distributed Transaction）便应运而生。</p><h2 id="刚性事务"><a href="#刚性事务" class="headerlink" title="刚性事务"></a>刚性事务</h2><p><a href="https://res.strikefreedom.top/static_res/blog/figures/properties-of-hard-transaction.png"><img src="https://res.strikefreedom.top/static_res/blog/figures/properties-of-hard-transaction.png" alt="img"></a></p><p>刚性事务（如单一数据库事务）完全遵循 <code>ACID</code> 规范，即数据库事务的四大基本特性：</p><ul><li>Atomicity（原子性）：一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。</li><li>Consistency（一致性）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器、级联回滚等。</li><li>Isolation（隔离性）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括未提交读（Read uncommitted）、提交读（read committed）、可重复读（repeatable read）和串行化（Serializable）。</li><li>Durability（持久性）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</li></ul><p><strong>刚性事务也能够以分布式 CAP 理论中的 CP 事务来作为定义</strong>。</p><h2 id="柔性事务"><a href="#柔性事务" class="headerlink" title="柔性事务"></a>柔性事务</h2><p><a href="https://res.strikefreedom.top/static_res/blog/figures/properties-of-soft-transaction.png"><img src="https://res.strikefreedom.top/static_res/blog/figures/properties-of-soft-transaction.png" alt="img"></a></p><p>在电商领域等互联网场景下，传统的事务在数据库性能和处理能力上都遇到了瓶颈。因此，柔性事务被提了出来，柔性事务基于分布式 <code>CAP</code> 理论以及延伸出来的 <code>BASE</code> 理论，相较于数据库事务这一类完全遵循 <code>ACID</code> 的刚性事务来说，柔性事务保证的是 “基本可用，最终一致”，<code>CAP</code> 原理相信大家都很熟悉了，这里我们讲一下 <code>BASE</code> 原则：</p><ul><li>基本可用（<strong>B</strong>asically <strong>A</strong>vailable）：系统能够基本运行、一直提供服务。</li><li>软状态（<strong>S</strong>oft-state）：系统不要求一直保持强一致状态。</li><li>最终一致性（<strong>E</strong>ventual consistency）：系统需要在某一时刻后达到一致性要求。</li></ul><p>柔性事务（如分布式事务）为了满足可用性、性能与降级服务的需要，降低一致性（Consistency）与隔离性（Isolation）的要求，遵循 <code>BASE</code> 理论，传统的 <code>ACID</code> 事务对隔离性的要求非常高，在事务执行过程中，必须将所有的资源对象锁定，因此对并发事务的执行极度不友好，柔性事务（比如分布式事务）的理念则是将锁资源对象操作从本地资源对象层面上移至业务逻辑层面，再通过放宽对强一致性要求，以换取系统吞吐量的提升。</p><p>此外，虽然柔性事务遵循的是 <code>BASE</code> 理论，但是还需要遵循部分 <code>ACID</code> 规范：</p><ul><li>原子性：严格遵循。</li><li>一致性：事务完成后的一致性严格遵循；事务中的一致性可适当放宽。</li><li>隔离性：并行事务间不可影响；事务中间结果可见性允许安全放宽。</li><li>持久性：严格遵循。</li></ul><h2 id="本地事务"><a href="#本地事务" class="headerlink" title="本地事务"></a>本地事务</h2><p><strong>本地事务</strong>（Local Transaction）指的是仅仅对单一节点/数据库资源对象进行访问/更新的事务，在这种事务模式下，<code>BASE</code> 理论派不上用场，事务完全遵循 <code>ACID</code> 规范，确保事务为刚性事务。</p><h2 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h2><p>在分布式架构成为主流的当下，系统对资源对象的访问不能还局限于单节点，多服务器、多节点的资源对象访问成为刚需，因此，本地事务无法满足分布式架构的系统的要求，分布式事务应运而生。</p><p>访问/更新由多个服务器管理的资源对象的<strong>平面事务</strong>或者<strong>嵌套事务</strong>称之为<strong>分布式事务</strong>（Distributed Transaction），分布式事务是相对于本地事务来说的。</p><p>平面事务：单一事务，访问多个服务器节点的资源对象，一个平面事务完成一次请求之后才能发起下一个请求。</p><p>嵌套事务：多事务组成，顶层事务可以不断创建子事务，子事务又可以进一步地以任意深度嵌套子事务。</p><p><a href="https://res.strikefreedom.top/static_res/blog/figures/flat-and-nested-transactions.png"><img src="https://res.strikefreedom.top/static_res/blog/figures/flat-and-nested-transactions.png" alt="img"></a></p><p>对于分布式事务来说，有两个最核心的问题：</p><ol><li>如何管理分布式事务的提交/放弃决定？如果事务中的一个节点在执行自己的本地事务过程中遇到错误，希望放弃整个分布式事务，与此同时其他节点则在事务执行过程中一切顺利，希望提交这个分布式事务，此时我们应该如何做决策？</li><li>如何保证并发事务在涉及多个节点上资源对象访问的可串行性（规避分布式死锁）？如果事务 T 对某一个服务器节点上的资源对象 S 的并发访问在事务 U 之前，那么我们需要保证在所有服务器节点上对 S 和其他资源对象的冲突访问，T 始终在 U 之前。</li></ol><p>问题 1 的解决需要引入一类分布式原子提交协议的算法如两阶段提交协议等，来对分布式事务过程中的提交或放弃决策进行管理，并确保分布式提交的原子性。而问题 2 则由分布式事务的并发控制机制来处理。</p><blockquote><p>原子性是分布式事务的前置性约束，没有原子性则分布式事务毫无意义。</p></blockquote><p>原子性约束要求在分布式事务结束之时，它的所有操作要么全部执行，要么全部不执行。以分布式事务的原子性来分析，客户端请求访问/更新多个服务器节点上的资源对象，在客户端提交或放弃该事务从而结束事务之后，多个服务器节点的最终状态要么是该事务里的所有步骤都执行成功之后的状态，要么恢复到事务开始前的状态，不存在中间状态。满足这种约束的分布式事务协议则称之为原子提交协议。</p><p>当一个分布式事务结束时，事务的原子特性要求所有参与该事务的服务器节点必须全部提交或者全部放弃该事务，为了实现这一点，必须引入一个协调者（Coordinator）的角色，从参与事务的所有服务器节点中挑选一个作为协调者，由它来保证在所有服务器节点上最终获得同样的结果。协调者的工作原理取决于分布式事务选用的协议。</p><p>一般来说，分布式事务中包含的两个最基础的角色就是：</p><ul><li>Coordinator – 协调者</li><li>Participants – 参与者</li></ul><p><a href="https://res.strikefreedom.top/static_res/blog/figures/coordinator-participants.png"><img src="https://res.strikefreedom.top/static_res/blog/figures/coordinator-participants.png" alt="img"></a></p><h2 id="单阶段原子提交协议"><a href="#单阶段原子提交协议" class="headerlink" title="单阶段原子提交协议"></a>单阶段原子提交协议</h2><p><strong>单阶段原子提交协议</strong>（one-phase atomic commit protocol, 1APC）是最简单的一种原子提交协议，它通过设置一个协调者并让它不断地向所有参与者发送提交（commit）或放弃（abort）事务的请求，直到所有参与者确认已执行完相应的操作。</p><p>1APC 协议的优点是简单易用，对一些事务不复杂的场景比较合适，但在复杂事务场景则显得捉襟见肘，因为该协议不允许任何服务器节点单方面放弃事务，事务的放弃必须由协调者来发起，这个设计会导致很多问题：首先因为只有一次通信，协调者并不会收集所有参与者的本地事务执行的情况，所以协调者决定提交还是放弃事务只基于自己的判断，在参与者执行事务期间可能会遇到错误从而导致最终事务未能真正提交，错误一般与事务的并发控制有关，比如事务执行期间对资源对象加锁，遇到死锁，需要放弃事务从而解开死锁，而协调者并不知道，因此在发起下一个请求之前，客户端完全不知道事务已被放弃。另一种情况就是利用乐观并发控制机制访问资源对象，某一个服务器节点的验证失败将导致事务被放弃，而协调者完全不知情。</p><h2 id="两阶段提交协议"><a href="#两阶段提交协议" class="headerlink" title="两阶段提交协议"></a>两阶段提交协议</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p><strong>两阶段提交协议</strong>（two-phase commit protocol, 2PC）的设计初衷是为了解决 1APC 不允许任意一个服务器节点自行放弃它自己的那部分本地事务的痛点，2PC 允许任何一个参与者自行决定要不要放弃它的本地事务，而由于原子提交协议的约束，任意一个本地事务被放弃将导致整个分布式事务也必须放弃掉。</p><p>两阶段提交协议基于以下几个假设：</p><ul><li>存在一个节点作为协调者（Coordinator），分布式事务通常由协调者发起（当然也可以由参与者发起），其余节点作为参与者（Participants），且节点之间可以自由地进行网络通信，协调者负责启动两阶段提交流程以及决定事务最终是被提交还是放弃。</li><li>每个节点会记录该节点上的本地操作日志（op logs），日志必须持久化在可靠的存储设备上（比如磁盘），以便在节点重启之后需要恢复操作日志。另外，不记录全局操作日志。</li><li>所有节点不能发生永久性损坏，也就是说节点就算是损坏了也必须能通过可靠性存储恢复如初，不允许出现数据永久丢失的情况。</li><li>参与者对协调者的回复必须要去除掉那些受损和重复的消息。</li><li>整个集群不会出现拜占庭故障（Byzantine Fault）– 服务器要么崩溃，要么服从其发送的消息。</li></ul><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>两阶段提交协议，顾名思义整个过程需要分为两个阶段：</p><ol><li>准备阶段（Prepare Phase）</li><li>提交阶段（Commit Phase）</li></ol><p>在进行两阶段提交的过程中，协调者会在以下四种状态间流转：</p><ol><li><code>init</code></li><li><code>preparing</code></li><li><code>committed</code></li><li><code>aborted</code></li></ol><p>而参与者则会在以下三种状态间流转：</p><ol><li><code>working</code></li><li><code>prepared</code></li><li><code>committed</code></li></ol><p><strong>阶段 I</strong>（投票表决阶段）</p><ol><li>任意一个参与者发起分布式事务 T 并执行本地事务成功，接着将一条 <code>&lt;ready T&gt;</code> 记录追加到本地日志 buffer 中并 flush 到可靠性存储设备如磁盘上，从 <code>working</code> 状态进入 <code>prepared</code> 状态，然后向协调者发送 <code>prepare T</code> 消息；</li><li>收到参与者发来的 <code>prepare T</code> 消息后，协调者将一条 <code>&lt;prepare T&gt;</code> 记录追加到日志中，然后从 <code>init</code> 状态进入 <code>preparing</code> 状态，紧接着向分布式事务的其他参与者发出 <code>canCommit?</code> 消息，发起事务表决过程；</li><li>当参与者收到 <code>canCommit?</code> 请求后，除了发起事务的那一个之外，其他还在 <code>working</code> 状态的参与者会先尝试执行本地事务，如果本地事务执行成功，则会往本地日志 buffer 写入一条 <code>&lt;ready T&gt;</code> 记录并 flush 到可靠性存储中，但不提交事务，进入 <code>prepared</code> 状态，然后回复一条 <code>ready T</code> 消息对此事务投 YES 票；如果本地事务执行失败，则参与者会往本地日志 buffer 写入一条 <code>&lt;don&#39;t commit T&gt;</code> 记录并 flush 到可靠性存储中，然后回复一条 <code>don&#39;t commit T</code> 消息投 NO 票。</li></ol><p><strong>阶段 II</strong>（收集投票结果完成事务）</p><ol><li><p>协调者收集所有的投票（包括它自己的投票）；</p><p>(a) 如果所有的投票都是 <code>ready T</code>，则表示没有故障发生，那么协调者决定提交该事务，首先它会在其本地日志中追加一条 <code>&lt;commit T&gt;</code> 记录，从 <code>preparing</code> 状态进入 <code>committed</code> 状态，然后向所有的参与者发送 <code>doCommit</code> 请求消息，要求参与者提交它们的本地事务；</p><p>(b) 如果有任一个投票是 No，则协调者决定放弃掉该事务，首先它会往本地日志中追加一条 记录，从 <code>preparing</code> 状态进入 <code>aborted</code> 状态，然后发送 <code>doAbort</code> 请求消息给所有的参与者，通知它们回滚各自的本地事务。</p></li><li><p>投了 YES 票的参与者阻塞等待协调者给它发来 <code>doCommit</code> 或 <code>doAbort</code> 消息，如果接收到的是 <code>doCommit</code> 消息则提交本地事务并在此过程中记录日志 <code>&lt;commit T&gt;</code>，然后进入 <code>committed</code> 状态，最后回复一个 <code>haveCommitted</code> 的消息通知协调者本地事务已经成功提交；反之，如果收到的是 <code>doAbort</code> 消息则回滚本地事务并写入日志 <code>&lt;abort T&gt;</code>，然后进入 <code>aborted</code>状态。</p></li></ol><p>上面的过程是一种更通用的流程，即由任意的参与者发起一个分布式事务，而在实践中一般把分布式事务的发起交给协调者来做，减少事务发起者确认该事务已被提交所需等待的网络消息延迟：</p><p><a href="https://res.strikefreedom.top/static_res/blog/figures/communication-in-two-phase-commit-protocol.png"><img src="https://res.strikefreedom.top/static_res/blog/figures/communication-in-two-phase-commit-protocol.png" alt="img"></a></p><h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><h4 id="网络-I-O-开销"><a href="#网络-I-O-开销" class="headerlink" title="网络 I/O 开销"></a>网络 I/O 开销</h4><p>假设两阶段提交过程一切运行正常，即协调者和参与者都不出现崩溃和重启，网络通信也都正常。那么假设有一个协调者和 N 个参与者，两阶段提交过程中将会发送如下的消息：</p><ul><li>任意一个参与者从 <code>working</code> 状态进入 <code>prepared</code> 状态并发送 <code>Prepared</code> 消息给协调者，1 条消息。</li><li>协调者收到消息后，向其他参与者发送 <code>canCommit?</code> 请求消息，N - 1 条消息。</li><li>收到 <code>canCommit?</code> 消息的参与者各自回复协调者投票消息，N - 1 条消息。</li><li>协调者统计投票情况之后，发送 <code>doCommit</code> 消息给其他参与者，N 条消息。</li></ul><p>所以，事务发起者在经过 4 条网络消息延迟之后确认该分布式事务已被提交，而整个过程共计发送 3N - 1 条网络消息（因为 <code>haveCommitted</code> 在 2PC 仅仅是用于最后通知协调者而已，属于可有可无的一次网络消息，2PC 在该消息缺省的情况下也能正常运行，因此 <code>haveCommitted</code> 一般不计入网络延迟成本中）。</p><p>前面我们提到，在实践中一般是由协调者来发起事务，如果考虑这种情况的话，事务发起者 – 协调者在经过 3 条网络消息延迟之后确认该分布式事务已经被提交，而整个过程实际发送的网络消息则变成 3N 条。</p><p>总而言之，两阶段提交协议的网络通信开销和集群节点的数量成 3 倍正比。</p><h4 id="本地存储设备-I-O-开销"><a href="#本地存储设备-I-O-开销" class="headerlink" title="本地存储设备 I/O 开销"></a>本地存储设备 I/O 开销</h4><p>基于前文中叙述的两阶段提交协议的基本假设之一：每个节点会通过日志来记录在本地执行的操作，以便在节点发生故障并重启节点之后能利用日志恢复到故障前的状态，因此两阶段提交过程中除了网络 I/O 的开销之外，还有本地存储设备 I/O 的开销：</p><ul><li>发起事务的参与者执行本地事务，1 次写操作。</li><li>其余参与者执行各自的本地事务，N - 1 次写操作。</li><li>协调者统计投票结果并决定提交事务，1 次写操作。</li></ul><p>所以事务发起者在经过 3 次本地存储设备 I/O 延迟之后确认该事务已被提交，整个过程总计有 N + 1 次本地存储设备 I/O，而如果由协调者来发起事务的话，则还是需要 N + 1 次本地存储设备 I/O，但是只需要经过 2 次本地存储设备 I/O 延迟即可确认事务已被提交。</p><h3 id="恢复"><a href="#恢复" class="headerlink" title="恢复"></a>恢复</h3><p>在分布式事务中，所有的参与者节点都可能发生故障，所以我们需要保证在该故障节点恢复时发生的一切都和分布式事务 T 的全局决策保持一致。节点在恢复的时候会读取 T 的最后一个本地日志记录并作出相应的操作：</p><ol><li>如果 T 的最后一条日志记录是 <code>&lt;commit T&gt;</code>，那么说明协调者在节点发生故障时的全局决策是提交 T，根据本地事务所使用的日志方式，在该节点上可能需要执行 <code>redo T</code>。</li><li>如果 T 的最后一条日志记录是 <code>&lt;abort T&gt;</code>，那么说明协调者在节点发生故障时的全局决策是中止 T，根据本地事务所使用的日志方式，在该节点上可能需要执行 <code>undo T</code>。</li><li>如果 T 的最后一条日志记录是 <code>&lt;don&#39;t commit T&gt;</code>，则和第 2 中情况类似，执行 <code>undo T</code>。</li><li>如果 T 的最后一条日志记录是 <code>&lt;ready T&gt;</code>，这种情况比较麻烦，因为恢复节点无法确认在它故障之后协调者发出的最终全局决策是什么，因此它必须要和集群中其余至少一个节点取得联系，询问 T 的最终结果是什么：恢复节点先尝试询问协调者，如果此时协调者正在工作，则告知恢复节点 T 的最终结果，如果是提交就执行 <code>redo T</code>，中止就执行 <code>undo T</code>；如果协调者因故不在工作，则恢复节点可以要求其他某一个参与者节点去查看本地日志以找出 T 的最终结果并告知恢复节点。在最坏的情况下，恢复节点无法和集群中其他所有节点取得联系，这时恢复节点只能阻塞等待，直至得知 T 的最终结果是提交还是中止。</li><li>如果本地日志中没有记录任何关于 T 在两阶段提交过程中的操作，那么根据前面的两阶段提交流程可知恢复节点还没来得及回复协调者的 <code>canCommit?</code> 请求消息就发生了故障，因此根据两阶段算法，恢复节点只能执行 <code>undo T</code>。</li></ol><h3 id="缺陷"><a href="#缺陷" class="headerlink" title="缺陷"></a>缺陷</h3><ol><li><strong>同步阻塞</strong>：两阶段提交协议是一个阻塞的协议，在第二阶段期间，参与者在事务未提交之前会一直锁定其占有的本地资源对象，直到接收到来自协调者的 <code>doCommit</code> 或 <code>doAbort</code> 消息。</li><li><strong>单点故障</strong>：两阶段提交协议中只有一个协调者，而由于在第二阶段中参与者在收到协调者的进一步指示之前会一直锁住本地资源对象，如果唯一的协调者此时出现故障而崩溃掉之后，那么所有参与者都将无限期地阻塞下去，也就是一直锁住本地资源对象而导致其他进程无法使用。</li><li><strong>数据不一致</strong>：如果在两阶段提交协议的第二阶段中，协调者向所有参与者发送 <code>doCommit</code> 消息之后，发生了局部网络抖动或者异常，抑或是协调者在只发送了部分消息之后就崩溃了，那么就只会有部分参与者接收到了 <code>doCommit</code> 消息并提交了本地事务；其他未收到 <code>doCommit</code> 消息的参与者则不会提交本地事务，因而导致了数据不一致问题。</li></ol><h3 id="XA-标准接口"><a href="#XA-标准接口" class="headerlink" title="XA 标准接口"></a>XA 标准接口</h3><p>2PC 两阶段提交协议本身只是一个通用协议，不提供具体的工程实现的规范和标准，在工程实践中为了统一标准，减少行业内不必要的对接成本，需要制定标准化的处理模型及接口标准，国际开放标准组织 Open Group 定义了分布式事务处理模型 <strong>DTP</strong>（Distributed Transaction Processing）Model，现在 XA 已经成为 2PC 分布式事务提交的事实标准，很多主流数据库如 Oracle、MySQL 等都已经实现 XA。</p><p>两阶段事务提交采用的是 X/OPEN 组织所定义的 <a href="http://pubs.opengroup.org/onlinepubs/009680699/toc.pdf">DTP Model</a> 所抽象的 AP（应用程序）, TM（事务管理器）和 RM（资源管理器） 概念来保证分布式事务的强一致性。 其中 TM 与 RM 间采用 XA 的协议进行双向通信。 与传统的本地事务相比，XA 事务增加了准备阶段，数据库除了被动接受提交指令外，还可以反向通知调用方事务是否可以被提交。 <code>TM</code> 可以收集所有分支事务的准备结果，并于最后进行原子提交，以保证事务的强一致性。</p><p><a href="https://res.strikefreedom.top/static_res/blog/figures/2pc-xa-tansaction-model.png"><img src="https://res.strikefreedom.top/static_res/blog/figures/2pc-xa-tansaction-model.png" alt="img"></a></p><p>Java 通过定义 JTA 接口实现了 XA 模型，JTA 接口中的 <code>ResourceManager</code> 需要数据库厂商提供 XA 驱动实现， <code>TransactionManager</code> 则需要事务管理器的厂商实现，传统的事务管理器需要同应用服务器绑定，因此使用的成本很高。 而嵌入式的事务管器可以以 jar 包的形式提供服务，同 Apache ShardingSphere 集成后，可保证分片后跨库事务强一致性。</p><p>通常，只有使用了事务管理器厂商所提供的 XA 事务连接池，才能支持 XA 的事务。Apache ShardingSphere 在整合 XA 事务时，采用分离 XA 事务管理和连接池管理的方式，做到对应用程序的零侵入。</p><h3 id="三阶段提交协议"><a href="#三阶段提交协议" class="headerlink" title="三阶段提交协议"></a>三阶段提交协议</h3><p>由于前文提到的两阶段提交协议的种种弊端，研究者们后来又提出了一种新的分布式原子提交协议：三阶段提交协议（three-phase commit protocol, 3PC）。</p><p>三阶段提交协议是对两阶段提交协议的扩展，它在特定假设下避免了同步阻塞的问题。该协议基于以下两个假设：</p><ol><li>集群不发生网络分区；</li><li>故障节点数不超过 K 个（K 是预先设定的一个数值）。</li></ol><p>基于这两个假设，三阶段提交协议通过引入<em><strong>超时机制</strong></em>和一个<em><strong>额外的阶段</strong></em>来解决阻塞问题，三阶段提交协议把两阶段提交协议的第一个阶段拆分成了两步：1) 评估，2) 资源对象加锁，最后才真正提交：</p><ol><li><strong>CanCommit 阶段</strong>：协调者发送 <code>CanCommit</code> 请求消息，询问各个参与者节点，参与者节点各自评估本地事务是否可以执行并回复消息（可以执行则回复 YES，否则回复 NO），此阶段不执行事务，只做判断；</li><li><strong>PreCommit 阶段</strong>：协调者根据上一阶段收集的反馈决定通知各个参与者节点执行（但不提交）或中止本地事务；有两种可能：1) 所有回复都是 YES，则发送 <code>PreCommit</code> 请求消息，要求所有参与者执行事务并追加记录到 undo 和 redo 日志，如果事务执行成功则参与者回复 ACK 响应消息，并等待下一阶段的指令；2) 反馈消息中只要有一个 NO，或者等待超时之后协调者都没有收到参与者的回复，那么协调者会中止事务，发送 <code>Abort</code> 请求消息给所有参与者，参与者收到该请求后中止本地事务，或者参与者超时等待仍未收到协调者的消息，同样也中止当前本地事务。</li><li><strong>DoCommit 阶段</strong>：协调者根据上一阶段收集到的反馈决定通知各个参与者节点提交或回滚本地事务，分三种情况：1) 协调者收到全部参与者回复的 ACK，则向所有参与者节点广播 <code>DoCommit</code> 请求消息，各个参与者节点收到协调者的消息之后决定提交事务，然后释放资源对象上的锁，成功之后向协调者回复 ACK，协调者接收到所有参与者的 ACK 之后，将该分布式事务标记为 <code>committed</code>；2) 协调者没有收到全部参与者回复的 ACK（可能参与者回复的不是 ACK，也可能是消息丢失导致超时），那么协调者就会中止事务，首先向所有参与者节点广播 <code>Abort</code> 请求消息，各个参与者收到该消息后利用上一阶段的 undo 日志进行事务的回滚，释放占用的资源对象，然后回复协调者 ACK 消息，协调者收到参与者的 ACK 消息后将该分布式事务标记为 <code>aborted</code>；3) 参与者一直没有收到协调者的消息，等待超时之后会直接提交事务。</li></ol><p><a href="https://res.strikefreedom.top/static_res/blog/figures/communication-in-three-phase-commit-protocol.png"><img src="https://res.strikefreedom.top/static_res/blog/figures/communication-in-three-phase-commit-protocol.png" alt="img"></a></p><p>事实上，在最后阶段，协调者不是通过追加本地日志的方式记录提交决定的，而是首先保证让至少 K 个参与者节点知道它决定提交该分布式事务。如果协调者发生故障了，那么剩下的参与者节点会重新选举一个新的协调者，这个新的协调者就可以在集群中不超过 K 个参与者节点故障的情况下学习到旧协调者之前是否已经决定要提交分布式事务，若是，则重新开始协议的第三阶段，否则就中止该事务，重新发起分布式事务。</p><p><strong>在最后的 DoCommit 阶段，如果参与者一直没有收到协调者的 <code>DoCommit</code> 或者 <code>Abort</code> 请求消息时，会在等待超时之后，直接提交事务。这个决策机制是基于概率学的：当已经进入第三阶段之后，说明参与者在第二阶段已经收到了 <code>PreCommit</code> 请求消息，而协调者发出 <code>PreCommit</code> 请求的前提条件是它在第二阶段开头收集到的第一阶段向所有参与者发出的 <code>CanCommit</code> 请求消息的反馈消息都是 YES。所以参与者可以根据自己收到了 <code>PreCommit</code> 请求消息这一既定事实得出这样的一个结论：其他所有参与者都同意了进行这次的事务执行，因此当前的参与者节点有理由相信，进入第三阶段后，其他参与者节点的本地事务最后成功提交的概率很大，而自己迟迟没有收到 <code>DoCommit</code> 或 <code>Abort</code> 消息可能仅仅是因为网络抖动或异常，因此直接提交自己的本地事务是一个比较合理的选择</strong>。</p><p>三阶段提交协议主要着重于解决两阶段提交协议中因为协调者单点故障而引发的同步阻塞问题，虽然相较于两阶段提交协议有所优化，但还是没解决可能发生的数据不一致问题，比如由于网络异常导致部分参与者节点没有收到协调者的 <code>Abort</code> 请求消息，超时之后这部分参与者会直接提交事务，从而导致集群中的数据不一致，另外三阶段提交协议也无法解决脑裂问题，同时也因为这个协议的网络开销问题，导致它并没有被广泛地使用，有关该协议的具体细节可以参阅本文最后的延伸阅读一节中的文献进一步了解，这里不再深入。</p><p><a href="https://res.strikefreedom.top/static_res/blog/figures/distributed-system.jpg"><img src="https://res.strikefreedom.top/static_res/blog/figures/distributed-system.jpg" alt="img"></a></p><p>共识（Consensus），很多时候会见到与一致性（Consistency）术语放在一起讨论。严谨地讲，两者的含义并不完全相同。</p><p>一致性的含义比共识宽泛，在不同场景（基于事务的数据库、分布式系统等）下意义不同。具体到分布式系统场景下，一致性指的是多个副本对外呈现的状态。如前面提到的顺序一致性、线性一致性，描述了多节点对数据状态的共同维护能力。而共识，则特指在分布式系统中多个节点之间对某个事情（例如多个事务请求，先执行谁？）达成一致意见的过程。因此，达成某种共识并不意味着就保障了一致性。</p><p>实践中，要保证系统满足不同程度的一致性，往往需要通过共识算法来达成。</p><p>共识算法解决的是分布式系统对某个提案（Proposal），大部分节点达成一致意见的过程。提案的含义在分布式系统中十分宽泛，如多个事件发生的顺序、某个键对应的值、谁是主节点……等等。可以认为任何可以达成一致的信息都是一个提案。</p><p>对于分布式系统来讲，各个节点通常都是相同的确定性状态机模型（又称为状态机复制问题，State-Machine Replication），从相同初始状态开始接收相同顺序的指令，则可以保证相同的结果状态。因此，系统中多个节点最关键的是对多个事件的顺序进行共识，即排序。</p><p>算法共识/一致性算法有两个最核心的约束：1) 安全性（Safety），2) 存活性（Liveness）：</p><ul><li>Safety：保证决议（Value）结果是对的，无歧义的，不会出现错误情况。<ul><li>只有是被提案者提出的提案才可能被最终批准；</li><li>在一次执行中，只批准（chosen）一个最终决议。被多数接受（accept）的结果成为决议；</li></ul></li><li>Liveness：保证决议过程能在有限时间内完成。<ul><li>决议总会产生，并且学习者最终能获得被批准的决议。</li></ul></li></ul><h2 id="Paxos"><a href="#Paxos" class="headerlink" title="Paxos"></a>Paxos</h2><p><a href="https://res.strikefreedom.top/static_res/blog/figures/paxos-algorithm.png"><img src="https://res.strikefreedom.top/static_res/blog/figures/paxos-algorithm.png" alt="img"></a></p><p>Google Chubby 的作者 Mike Burrows 说过， <code>there is only one consensus protocol, and that’s Paxos” – all other approaches are just broken versions of Paxos.</code></p><p>意即<strong>世上只有一种共识算法，那就是 Paxos，其他所有的共识算法都只是 Paxos 算法的残缺版本</strong>。虽然有点武断，但是自从 Paxos 问世以来，它便几乎成为了分布式共识算法的代名词，后来的许多应用广泛的分布式共识算法如 Raft、Zab 等的原理和思想都可以溯源至 Paxos 算法。</p><p>Paxos 是由 Leslie Lamport (LaTeX 发明者，图灵奖得主，分布式领域的世界级大师) 在 1990 年的论文<a href="https://lamport.azurewebsites.net/pubs/lamport-paxos.pdf">《The PartTime Parliament》</a>里提出的，Lamport 在论文中以一个古希腊的 Paxos 小岛上的议会制订法律的故事切入，引出了 Paxos 分布式共识算法。</p><h3 id="Basic-Paxos"><a href="#Basic-Paxos" class="headerlink" title="Basic Paxos"></a>Basic Paxos</h3><p>业界一般将 Lamport 论文里最初提出分布式算法称之为 Basic Paxos，这是 Paxos 最基础的算法思想。</p><p><strong>Basic Paxos 算法的最终目标是通过严谨和可靠的流程来使得集群基于某个提案（Proposal）达到最终的共识</strong>。</p><h4 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h4><ul><li><strong>Value</strong>：提案值，是一个抽象的概念，在工程实践中可以是任何操作，如『更新数据库某一行的某一列』、『选择 xxx 服务器节点作为集群中的主节点』。</li><li><strong>Number</strong>：提案编号，全局唯一，单调递增。</li><li><strong>Proposal</strong>：集群需要达成共识的提案，提案 = 编号 + 值。</li></ul><p>Proposal 中的 Value 就是在 Paxos 算法完成之后需要达成共识的值。</p><p>Paxos 算法中有三个核心角色：</p><p><a href="https://res.strikefreedom.top/static_res/blog/figures/three-roles-in-paxos.png"><img src="https://res.strikefreedom.top/static_res/blog/figures/three-roles-in-paxos.png" alt="img"></a></p><ul><li><strong>Proposer</strong>：生成提案编号 <code>n</code> 和值 <code>v</code>，然后向 Acceptors 广播该提案，接收 Acceptors 的回复，如果有超过半数的 Acceptors 同意该提案，则选定该提案，否则放弃此次提案并生成更新的提案重新发起流程，提案被选定之后则通知所有 Learners 学习该最终选定的提案值（也可以由 Acceptor 来通知，看具体实现）。Basic Paxos 中允许有多个 Proposers。</li><li><strong>Acceptor</strong>：接收 Proposer 的提案并参与提案决策过程，把各自的决定回复给 Proposer 进行统计。Acceptor 可以接受来自多个 proposers 的多个提案。</li><li><strong>Learner</strong>：不参与决策过程，只学习最终选定的提案值。</li></ul><p><strong>在具体的工程实践中，一个节点往往会充当多种角色，比如一个节点可以既是 Proposer 又是 Acceptor，甚至还是 Learner。</strong></p><h4 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h4><p>相较于直接给出 Paxos 算法的流程，我想沿袭 Lamport 大师的经典 Paxos 论文<a href="https://lamport.azurewebsites.net/pubs/paxos-simple.pdf">《Paxos Made Simple》</a>中的思路：通过循序渐进的方式推导出 Paxos 算法。</p><p>首先需要了解 Paxos 算法中的两个重要的约束：</p><blockquote><p>C1. 一个 Acceptor 必须接受它收到的第一个提案。</p></blockquote><blockquote><p>C2. 只有当<strong>超过半数</strong>的 Acceptors 接受某一个提案，才能最终选定该提案。</p></blockquote><p>C2 其实有一个隐含的推论：一个 Acceptor 可以接受多个提案，这也是为什么我们需要给每一个提案生成一个编号的原因，用来给提案排序。</p><p>我们前面提到过 Paxos 的最终目标是通过严谨和可靠的流程来使得集群基于某个提案（Proposal）达到最终的共识，也就是说基于某一个提案发起的一次 Paxos 流程，最终目的是希望集群对该提案达成一致的意见，而为了实现并维持集群中的这种一致性，前提是 Paxos 算法必须具有幂等性：一旦提案（Proposal）中的值（Value）被选定（Chosen），那么只要还在此次 Paxos 流程中，就算不断按照 Paxos 的规则重复步骤，未来被 Chosen 的 Value 都会是同一个。如果不满足这种幂等性，将可能导致不一致的问题。</p><p>因此，我们可以把 Paxos 的基本命题提炼出来：</p><blockquote><p>P1. 在一次 Paxos 流程中，如果一个值（Value）为 <code>v</code> 的提案（Proposal）被选定（Chosen）了，那么后续任何被最终选定的带有更大编号（Number）的提案中的 Value 也必须是 <code>v</code>。</p></blockquote><p>提案在被最终选定之前必须先被 Acceptor 接受，于是我们可以再进一步总结一个具有更强约束的命题：</p><blockquote><p>P2. 在一次 Paxos 流程中，如果一个值（Value）为 <code>v</code> 的提案（Proposal）被选定（Chosen）了，那么后续任何被 Acceptor 接受的带有更大编号（Number）的提案中的 Value 也必须是 <code>v</code>。</p></blockquote><p>这还不是具备最强约束的命题，因为提案在被 Acceptor 接受之前必须先由 Proposer 提出，因此还可以继续强化命题：</p><blockquote><p>P3. 在一次 Paxos 流程中，如果一个值（Value）为 <code>v</code> 的提案（Proposal）被选定（Chosen）了，那么后续任何 Proposer 提议的带有更大编号（Number）的提案中的 Value 也必须是 <code>v</code>。</p></blockquote><p>从上述的三个命题，我们可以很容易地看出来，P3 可以推导出 P2，进而推导出 P1，也就是说这是一个<a href="https://zh.wikipedia.org/wiki/%E6%AD%B8%E7%B4%84">归约</a>的过程，因此只要 P3 成立则 P1 成立，也就是 Paxos 算法的正确性得到保证。</p><p>那么要如何实现呢 P3 呢？只需满足如下约束：</p><blockquote><p>C3. 对于一个被 Proposer 提议的提案中任意的 <code>v</code> 和 <code>n</code>，存在一个数量超过半数 Acceptors 的集合 S，满足以下两个条件中的任意一个：</p><ul><li>S 中的任何一个 Acceptor 都没有接受过编号小于 <code>n</code> 的提案。</li><li>S 中所有的 Acceptors 接受过的最大编号的提案的 Value 为 <code>v</code>。</li></ul></blockquote><p>为了满足 C3 从而实现 P3，需要引入一条约束：Proposer 每次生成自己的 <code>n</code> 之后，发起提案之前，必须要先去『学习』那个已经被选定或者将要被选定的小于 <code>n</code> 的提案，如果有这个提案的话则把那个提案的 <code>v</code> 作为自己的此次提案的 Value，没有的话才可以自己指定一个 Value，这样的话 Proposer 侧就可以保证更高编号的提案的值只会是已选定的 <code>v</code> 了，但是 Acceptor 侧还无法保证，因为 Acceptor 有可能还会接受其他的 Proposers 的提案值，于是我们需要对 Acceptor 也加一条约束，让它承诺在收到编号为 <code>n</code> 的 <code>v</code> 之后，不会再接受新的编号小于 <code>n</code> 的提案值。</p><p>所以我们可以得到一个 Paxos 在 Proposer 侧的算法流程：</p><ol><li><p>Proposer 生成一个新的提案编号 <code>n</code> 然后发送一个 <em><strong>prepare</strong></em> 请求给<strong>超过半数</strong>的 Acceptors 集合，要求集合中的每一个 Acceptor 做出如下响应：</p><p>(a) 向 Proposer 承诺在收到该消息之后就不再接受编号小于 <code>n</code> 的提案。</p><p>(b) 如果 Acceptor 在收到该消息之前已经接受过其他提案，则把当前接受的编号最大的提案回复给 Proposer。</p></li><li><p>如果 Proposer 收到了<strong>超过半数</strong>的 Acceptors 的回复，那么就可以生成 <code>(n, v)</code> 的提案，这里 <code>v</code> 是所有 Acceptors 回复中编号最大的那个提案里的值，如果所有 Acceptors 回复中都没有附带上提案的话，则可以由 Proposer 自己选择一个 <code>v</code>。</p></li><li><p>Proposer 将上面生成的提案通过一个 <em><strong>accept</strong></em> 请求发送给一个<strong>超过半数</strong>的 Acceptors 集合。（需要注意的是这个集合不一定和第二步中的那个集合是同一个。）</p></li></ol><p>Paxos 在 Proposer 侧的算法流程已经确定了，接下来我们需要从 Acceptor 的视角来完成剩下的算法推导。前面我们提到过，Acceptor 是可以接受多个 Proposers 的多个提案的，但是在收到一个 Proposer 的 <em><strong>prepare</strong></em> 消息后会承诺不再接受编号小于 <code>n</code> 的新提案，也就是说 Acceptor 也是可以忽略掉其他 Proposers 消息（包括 <em><strong>prepare</strong></em> 和 <em><strong>accept</strong></em>）而不会破坏算法的<strong>安全性</strong>，当然了，在工程实践中也可以直接回复一个错误，让 Proposer 更早知道提案被拒绝然后生成提案重新开始流程。这里我们应该重点思考的场景是一个 Acceptor 接受一个提案请求的时候，根据前面 Proposer 要求 Acceptor 的承诺，我们可以给 Acceptor 设置一个这样的约束：</p><blockquote><p>C4. 如果一个 Proposer 发出了带 <code>n</code> 的 <em><strong>prepare</strong></em> 请求，只要 Acceptor 还没有回复过任何其他编号大于 <code>n</code> 的<em><strong>prepare</strong></em> 请求，则该 Acceptor 可以接受这个提案。</p></blockquote><p>因为 Acceptor 需要对 Proposer 做出不接受编号小于 <code>n</code> 的提案的承诺，因此它需要做持久化记录，那么它就必须是有状态的，也因此每个 Acceptor 都需要利用可靠性存储（日志）来保存两个对象：</p><ol><li>Acceptor 接受过的编号最大的提案；</li><li>Acceptor 回复过的最大的 <em><strong>prepare</strong></em> 请求提案编号。</li></ol><p>以上这就是 Acceptor 侧的约束。接下来我们就可以得到 Paxos 的整个算法流程了。</p><p>Paxos 算法可以归纳为两大基本过程：</p><ol><li>选择过程；</li><li>学习过程。</li></ol><h5 id="选择过程"><a href="#选择过程" class="headerlink" title="选择过程"></a>选择过程</h5><p>选择过程分为两个阶段：</p><ul><li><p><strong>阶段一（Phase 1）：</strong></p><p>(a) Proposer 生成一个全局唯一且单调递增的提案编号 <code>n</code>，然后发送编号为 <code>n</code> 的 <em><strong>prepare</strong></em> 请求（P1a msg）给<strong>超过半数</strong>的 Acceptors 集合。</p><p>(b) 当一个 Acceptor 收到一个编号为 <code>n</code> 的 <em><strong>prepare</strong></em> 请求，如果 <code>n</code> 比它此前接受过其他的提案编号（如果有）都要大的话，那么将这个提案编号 <code>n</code> 写入本地日志，这里记为 <code>max_n</code>，然后作出『两个承诺，一个回复』:</p><ul><li>两个承诺：<ul><li>不再接受编号小于等于 <code>n</code> 的 <em><strong>prepare</strong></em> 请求</li><li>不再接受编号小于等于 <code>n</code> 的 <em><strong>accept</strong></em> 请求</li></ul></li><li>一个回复：<ul><li>在不违背以前作出的承诺下，回复消息（P1b msg），附带上自己已经接受过的提案中编号最大的那个提案的 <code>v</code> 和 <code>n</code>，没有则返回空值。</li></ul></li></ul><p>否则就忽略该 <em><strong>prepare</strong></em> 消息或者回复一个错误。</p></li><li><p><strong>阶段二（Phase 2）：</strong></p><p>(a) 当 Proposer 收到<strong>超过半数</strong>的 Acceptors 回复它的编号为 <code>n</code> 的 <em><strong>prepare</strong></em> 请求的响应，此时有两种可能：</p><ul><li><strong>Free</strong>：没有任何一个 Acceptor 的回复消息中附带已被接受的提案，意味着当前流程中还没有提案值被最终接受，此时 Proposer 可以自由地选择提案值 Value，最后发送一个包含 <code>(n, v)</code> 提案的 <em><strong>accept</strong></em> 请求消息（P2a msg）给 Acceptors 集合。</li><li><strong>Forced</strong>：某些 Acceptors 的回复消息中附带已被接受的提案，那么 Proposer 必须强制使用这些回复消息中编号最大的提案 Value 作为自己的提案值，最后发送一个包含 <code>(n, v)</code> 提案的 <em><strong>accept</strong></em> 请求消息（P2a msg）给 Acceptors 集合。</li></ul><p>(b) 当 Acceptor 收到一个编号为 <code>n</code> 的提案的 <em><strong>accept</strong></em> 请求消息，需要分两种情况处理：</p><ul><li>如果 <code>n</code> &gt;= <code>max_n</code>（通常情况下这两个值是相等的），则接受该提案并回复消息（P2b msg）。</li><li>如果 <code>n</code> &lt; <code>max_n</code>，则忽略该 <em><strong>accept</strong></em> 消息或者回复一个错误（P2b error）。</li></ul></li></ul><h5 id="学习过程"><a href="#学习过程" class="headerlink" title="学习过程"></a>学习过程</h5><p>选择过程结束之后，我们得到了一个提案值，接下来就是要让集群中的所有 Learner 『学习』到这个值了，以求达到集群的共识。</p><p>Learner 学习提案值的方式可以分成三种：</p><ol><li>任意一个 Acceptor 接受了一个提案后就立刻将该提案发送给<strong>所有 Learner</strong>。优点：Learner 能实时学习到被 Paxos 流程选定的 Value；缺点：网络通信次数太多，如果有 N 个 Acceptors 和 M 个 Learner，则需要的网络通信是 N*M 次。</li><li>设置一个主 Learner，Acceptor 接受了一个提案后只将该提案发送给主 Learner，主 Learner 再转发给剩下的 Learners。优点：网络通信次数只需 N+M-1 次；缺点：主 Learner 有单点故障的风险。</li><li>Acceptor 接受了一个提案后将该提案发送给一个 Learner 集合，由这个集合去通知剩下的 Learners。优点：用集合替代单点，可靠性更高；缺点：增加系统复杂度，需要维护一个 Learner 小集群。</li></ol><p>至此，我们就推导出了整个 Paxos 算法的流程：</p><p><a href="https://res.strikefreedom.top/static_res/blog/figures/message-flow-for-paxos.png"><img src="https://res.strikefreedom.top/static_res/blog/figures/message-flow-for-paxos.png" alt="img"></a></p><h4 id="算法证明"><a href="#算法证明" class="headerlink" title="算法证明"></a>算法证明</h4><p>这一节我们来证明 Paxos 算法的正确性。</p><p>上一节我们已经提炼出来了 Paxos 的基本命题 P1，并通过归约 P1 得到了约束性更强的另外两个命题 P2 和 P3，根据归约的原理，我们知道 P3 可以最终推导出 P1，也就是说如果要证明 Paxos 的基本命题 P1，只需要证明 P3 即可。为什么之前我们要不断强化 Paxos 的命题呢？因为从数学的层面来讲，一个具有更强约束（更多假设）的命题一般会更容易证明。</p><p>现在我们把 P1, P2 和 P3 用更严格的数学语言来描述：</p><blockquote><p>P1. 在一次 Paxos 流程中，如果一个包含 (n, v) 的提案被选定（Chosen），那么存在未来被选定的提案 (k, v1)，必然满足 k &gt; n，v1 = v。</p><p>P2. 在一次 Paxos 流程中，如果一个包含 (n, v) 的提案被选定（Chosen），那么存在未来被超过半数的 Acceptors 接受的提案 (k, v1)，必然满足 k &gt; n，v1 = v。</p><p>P3. 在一次 Paxos 流程中，如果一个包含 (n, v) 的提案被选定（Chosen），那么存在未来由 Proposer 提议的提案 (k, v1)，必然满足 k &gt; n，v1 = v。</p></blockquote><p>现在我们利用数学归纳法来证明 P3：</p><p><strong>假设 k = m 时 P3 成立，由于 (n, v) 已经是被选定的提案，因此 Proposer 发起的从 n 到 k 的提案中的 Value 都会是 v，其中 m &gt;= n，那么根据归约的原理可证 k = m 时 P1 也成立</strong>。</p><p>现在令 k = m+1，Proposer 发送带编号 k 的 <em><strong>prepare</strong></em> 请求消息到 Acceptors 集合。</p><p>由于此前已经有了选定的提案，那么根据 Paxos 的约束 C2 可知参与这一个提案投票的 Acceptors 集合必定和上一个集合有重合。</p><p>根据 Acceptors 集合重叠和 Paxos 的 P1b 阶段可知，回复的消息中必定附带有已被大多数 Acceptors 接受的提案 (i, v0)。</p><p>然后根据 P2a 阶段，Proposer 提案 (k, v1)，其中 v1 = v0。</p><p>还是根据 P1b，可知 i 是所有回复消息里编号最大的，可得 i &gt;= m，又根据 P1a 可知 i &lt; k，因此可以得出提案 (i, v0) 中有 v0 = v。</p><p>可知当 k = m+1 时，提案 (k, v1) 中的 v1 = v。</p><p>根据数学归纳法的原理，我们还需要找到一个特例来使得命题成立，然后由特例推广到普遍，我们这里选择 k = 1 作为特例，证明 k = 1 时 P3 成立：根据 Paxos 的约束 C1 易知在 n = 0，k = 1 的场景下，P3 成立。</p><p>因此可根据数学归纳法基于 k = 1 进行推广至 k = m（m 代表任意自然数），最后 P3 命题得证。</p><p>再由归约的原理可知，P3 可推导出 P2，最后 P2 推导出 P1。至此， Paxos 算法原理正确性的证明完成。</p><p><strong>上述的证明只是一种比较简单且粗浅的证明方法，但是对于工程师理解 Paxos 原理来说已经足够了，如果希望进一步学习 Paxos 原理的严格数学证明，可以参阅 Leslie Lamport 的原始论文<a href="https://lamport.azurewebsites.net/pubs/lamport-paxos.pdf">《The PartTime Parliament》</a>，里面给出了 Paxos 算法的严格数学证明。</strong></p><h3 id="Multi-Paxos"><a href="#Multi-Paxos" class="headerlink" title="Multi-Paxos"></a>Multi-Paxos</h3><p>自 Lamport 于 1990 年在论文<a href="https://lamport.azurewebsites.net/pubs/lamport-paxos.pdf">《The PartTime Parliament》</a>中提出 Paxos 算法之后，这个算法一直被评价为难以理解和实现，这篇论文中运用了大量的数学对 Paxos 的原理进行证明，而又由于 Lamport 在论文里用讲故事的形式解释 Paxos，进一步增大了人们彻底理解 Paxos 的难度，事实上 Lamport 的这篇论文也因此在发表过程中一波三折，这里不展开，有兴趣的读者可以自行去了解这段这段背景故事。</p><p>因为业界在理解 Paxos 算法上持续的怨声载道，Lamport 在 2001 年发表了论文<a href="https://lamport.azurewebsites.net/pubs/paxos-simple.pdf">《Paxos Made Simple》</a>，对原论文进行精简，以更通俗易懂的语言和形式阐述 Paxos 算法，并在其中提出了更加具备工程实践性的 Multi-Paxos 的思想。</p><p>关于 Paxos 难以理解的问题上，我个人的一点愚见是：Paxos 算法的思想其实并不难理解，真正难的地方是：</p><ol><li>Paxos 背后那一套完整的数学原理和证明</li><li>在复杂分布式环境将 Paxos 进行工程落地</li></ol><p>我个人建议的 Paxos 学习资料是：<a href="https://lamport.azurewebsites.net/pubs/paxos-simple.pdf">《Paxos Made Simple》</a>，<a href="https://read.seas.harvard.edu/~kohler/class/08w-dsi/chandra07paxos.pdf">《Paxos Made Live - An Engineering Perspective》</a>以及 <a href="https://www.youtube.com/watch?v=JEpsBg0AO6o">Paxos lecture (Raft user study)</a>。第一篇论文可以说是 Lamport 1990 年那篇最初的论文的精简版，可读性提高了很多，论文里也没有使用任何数学公式，只需一点英文基础就可以通读，第二篇论文讲的则是 Google 介绍利用 Paxos 共识算法建立容错数据库的经验，其中涉及的 Chubby 是业界较早的成功实现了 Multi-Paxos 的大规模线上系统，十分具有参考性，最后的 Youtube 视频则是 Raft 的作者 Diego Ongaro 为了对比 Raft 和 Multi-Paxos 的学习的难易程度而做的，非常适合作为学习 Paxos 和 Raft 的入门资料。</p><p>从上一节可知 Basic Paxos 算法有几个天然缺陷：</p><ul><li>只能就单个值（Value）达成共识，不支持多值共识。在实际的工程实践中往往是需要对一系列的操作达成共识，比如分布式事务，由很多执行命令组成。</li><li>至少需要 2 轮往返 4 次 <em><strong>prepare</strong></em> 和 <em><strong>accept</strong></em> 网络通信才能基于一项提案达成共识。对于一个分布式系统来说，网络通信是最影响性能的因素之一，过多的网络通信往往会导致系统的性能瓶颈。</li><li>不限制 Proposer 数量导致非常容易发生提案冲突。极端情况下，多 Proposer 会导致系统出现『活锁』，破坏分布式共识算法的两大约束之一的活性（liveness）。</li></ul><p>关于第三点，前文提到分布式共识算法必须满足两个最核心的约束：安全性（safety）和活性（liveness），从上一节我们可以看出 Basic Paxos 主要着重于 safety，而对 liveness 并没有进行强约束，让我们设想一种场景：两个 Proposers (记为 P1 和 P2) 轮替着发起提案，导致两个 Paxos 流程重叠了：</p><ol><li>首先，P1 发送编号 N1 的 <em><strong>prepare</strong></em> 请求到 Acceptors 集合，收到了过半的回复，完成阶段一。</li><li>紧接着 P2 也进入阶段一，发送编号 N2 的 <em><strong>prepare</strong></em> 请求到过半的 Acceptors 集合，也收到了过半的回复，Acceptors 集合承诺不再接受编号小于 N2 的提案。</li><li>然后 P1 进入阶段二，发送编号 N1 的 <em><strong>accept</strong></em> 请求被 Acceptors 忽略，于是 P1 重新进入阶段一发送编号 N3 的 <em><strong>prepare</strong></em> 请求到 Acceptors 集合，Acceptors 又承诺不再接受编号小于 N3 的提案。</li><li>紧接着 P2 进入阶段二，发送编号 N2 的 <em><strong>accept</strong></em> 请求，又被 Acceptors 忽略。</li><li>不断重复上面的过程…</li></ol><p>在极端情况下，这个过程会永远持续，导致所谓的『活锁』，永远无法选定一个提案，也就是 liveness 约束无法满足。</p><p>为了解决这些问题，Lamport 在<a href="https://lamport.azurewebsites.net/pubs/paxos-simple.pdf">《Paxos Made Simple》</a>论文中提出了一种基于 Basic Paxos 的 Multi-Paxos 算法思想，并基于该算法引出了一个分布式银行系统状态机的实现方案，感兴趣的读者不妨看一下。</p><p>Multi-Paxos 算法在 Basic Paxos 的基础上做了两点改进：</p><ol><li><strong>多 Paxos 实例</strong>：针对每一个需要达成共识的单值都运行一次 Basic Paxos 算法的实例，并使用 Instance ID 做标识，最后汇总完成多值共识。</li><li><strong>选举单一的 Leader Proposer</strong>：选举出一个 Leader Proposer，所有提案只能由 Leader Proposer 来发起并决策，Leader Proposer 作为 Paxos 算法流程中唯一的提案发起者，『活锁』将不复存在。此外，由于单一 Proposer 不存在提案竞争的问题，Paxos 算法流程中的阶段一中的 <em><strong>prepare</strong></em> 步骤也可以省略掉，从而将两阶段流程变成一阶段，大大减少网络通信次数。</li></ol><p>关于多值共识的优化，如果每一个 Basic Paxos 算法实例都设置一个 Leader Proposer 来工作，还是会产生大量的网络通信开销，因此，多个 Paxos 实例可以共享同一个 Leader Proposer，这要求该 Leader Proposer 必须是稳定的，也即 Leader 不应该在 Paxos 流程中崩溃或改变。</p><p>由于 Lamport 在论文中提出的 Multi-Paxos 只是一种思想而非一个具体算法，因此关于 Multi-Paxos 的很多细节他并没有给出具体的实现方案，有些即便给出了方案也描述得不是很清楚，比如他在论文中最后一节提出的基于银行系统的状态机中的多 Paxos 实例处理，虽然给了具体的论述，但是在很多关键地方还是没有指明，这也导致了后续业界里的 Multi-Paxos 实现各不相同。</p><p>我们这里用 Google Chubby 的 Multi-Paxos 实现来分析这个算法。</p><p>首先，Chubby 通过引入 Master 节点，实现了 Lamport 在论文中提到的 single distinguished proposer，也就是 Leader Proposer，Leader Proposer 作为 Paxos 算法流程中唯一的提案发起者，规避了多 Proposers 同时发起提案的场景，也就不存在提案冲突的情况了，从而解决了『活锁』的问题，保证了算法的活性（liveness）。</p><p>Lamport 在论文中指出，选择 Leader Proposer 的过程必须是可靠的，那么具体如何选择一个 Leader Proposer 呢？在 Chubby 中，集群利用 Basic Paxos 算法的共识功能来完成对 Leader Proposer 的选举，这个实现是具有天然合理性的，因为 Basic Paxos 本身就是一个非常可靠而且经过严格数学证明的共识算法，用来作为选举算法再合适不过了，在 Multi-Paxos 流程期间，Master 会通过不断续租的方式来延长租期（Lease）。比如在实际场景中，一般在长达几天的时期内都是同一个服务器节点作为 Master。万一 Master 故障了，那么剩下的 Slaves 节点会重新发起 Paxos 流程票选出新的 Master，也就是说主节点是一直存在的，而且是唯一的。</p><p>此外，Lamport 在论文中提到的过一种优化网络通信的方法：“当 Leader Proposer 处于稳定状态时，可以跳过阶段一，直接进入阶段二”，在 Chubby 中也实现了这个优化机制，Leader Proposer 在为多个 Paxos 算法实例服务的时候直接跳过阶段一进入阶段二，只发送 <em><strong>accept</strong></em> 请求消息给 Acceptors 集合，将算法从两阶段优化成了一阶段，大大节省网络带宽和提升系统性能。</p><p>最后，Multi-Paxos 是一个”脑裂”容错的算法思想，就是说当 Multi-Paxos 流程中因为网络问题而出现多 Leaders 的情况下，该算法的安全性（safety ）约束依然能得到保证，因为在这种情况下，Multi-Paxos 实际上是退化成了 Basic Paxos，而 Basic Paxos 天然就支持多 Proposers。</p><p><strong>在分布式事务中，Paxos 算法能够提供比两阶段提交协议更加可靠的一致性提交：通过将提交/放弃事务的决定从原来两阶段协议中单一的协调者转移到一个由 Proposer + Acceptors 组成的集群中。Lamport 曾经发表过一篇<a href="https://lamport.azurewebsites.net/video/consensus-on-transaction-commit.pdf">《Consensus on Transaction Commit》</a>的论文，通过将两阶段提交协议和基于 Paxos 实现的分布式提交协议做对比，对基于 Paxos 实现的提交协议有非常精彩的论述，感兴趣的读者不妨一读</strong>。</p><h2 id="Raft"><a href="#Raft" class="headerlink" title="Raft"></a>Raft</h2><p>Raft 算法实际上是 Multi-Paxos 的一个变种，通过新增两个约束：</p><ol><li><strong>追加日志约束</strong>：Raft 中追加节点的日志必须是串行连续的，而 Multi-Paxos 中则可以并发追加日志（实际上 Multi-Paxos 的并发也只是针对日志追加，最后应用到内部 State Machine 的时候还是必须保证顺序）。</li><li><strong>选主限制</strong>：Raft 中只有那些拥有最新、最全日志的节点才能当选 Leader 节点，而 Multi-Paxos 由于允许并发写日志，因此无法确定一个拥有最新、最全日志的节点，因此可以选择任意一个节点作为 Leader，但是选主之后必须要把 Leader 节点的日志补全。</li></ol><p>基于这两个限制，Raft 算法的实现比 Multi-Paxos 更加简单易懂，不过由于 Multi-Paxos 的并发度更高，因此从理论上来说 Multi-Paxos 的性能会更好一些，但是到现在为止业界也没有一份权威的测试报告来支撑这一观点。</p><p>对比一下 Multi-Paxos 和 Raft 下集群中可能存在的日志顺序：</p><p><a href="https://res.strikefreedom.top/static_res/blog/figures/multi-paxos-vs-raft.png"><img src="https://res.strikefreedom.top/static_res/blog/figures/multi-paxos-vs-raft.png" alt="img"></a></p><p>可以看出，Raft 中永远满足这样一个约束：follower log 一定会是 leader log 的子集并且顺序一定是连续的，而 Multi-Paxos 则不一定满足这个约束，日志记录通常是乱序的。</p><p>由于 Raft 的核心思想源自 Multi-Paxos，在实现过程中做了很多改进优化，然而万变不离其宗，我相信理解了 Multi-Paxos 之后再去学习 Raft 会事半功倍（Raft 在诞生之初也是打着”容易理解”的旗号来对标 Paxos 的），由于前面已经深度剖析过 Paxos 算法的流程和原理了，碍于本文的篇幅所限，这里就不再对 Raft 算法的细节进行深入探讨了，如果有意深入学习 Raft，可以从 <a href="https://raft.github.io/">The Raft Consensus Algorithm</a> 处找到相关的论文、源码等资料进行全面的学习。</p><p>最后有一些概念要澄清一下，Basic Paxos 是一个经过了严格数学证明的分布式共识算法，但是由于前文提到的 Basic Paxos 算法应用在实际工程落地中的种种问题，现实中几乎没有直接基于 Basic Paxos 算法实现的分布式系统，绝大多数都是基于 Multi-Paxos，然而 Multi-Paxos 仅仅是一种对 Basic Paxos 的延伸思想而非一个具体算法，问题在于目前业界并没有一个统一的 Multi-Paxos 实现标准，因此 Multi-Paxos 的工程实现是建立在一个未经严格证明的前提之上的，工程实现最终的正确性只能靠实现方自己去验证，而 Raft 则是一个具有统一标准实现的、正确性已经过严格证明的<strong>具体算法</strong>，因此在分布式系统的工程实践中大多数人往往还是会选择 Raft 作为底层的共识算法。</p><h2 id="算法类型"><a href="#算法类型" class="headerlink" title="算法类型"></a>算法类型</h2><p>需要特别指出的一点是，根据解决的场景是否允许拜占庭（Byzantine）错误，共识算法可以分为 Crash Fault Tolerance (CFT) 和 Byzantine Fault Tolerance（BFT）两类。</p><p>对于非拜占庭错误的情况，已经存在不少经典的算法，包括 Paxos（1990 年）、Raft（2014 年）及其变种等。这类容错算法往往性能比较好，处理较快，容忍不超过一半的故障节点。</p><p>对于要能容忍拜占庭错误的情况，包括 PBFT（Practical Byzantine Fault Tolerance，1999 年）为代表的确定性系列算法、PoW（1997 年）为代表的概率算法等。确定性算法一旦达成共识就不可逆转，即共识是最终结果；而概率类算法的共识结果则是临时的，随着时间推移或某种强化，共识结果被推翻的概率越来越小，最终成为事实上结果。拜占庭类容错算法往往性能较差，容忍不超过 1/3 的故障节点。</p><p>本文主要讨论的分布式共识算法是 CFT 类算法，毕竟对于大多数分布式系统来说，集群节点和网络消息一般都是可控的，系统只会出现节点故障而不会出现像拜占庭错误那样伪造的、欺骗性的网络消息，在这种场景下，CFT 类算法更具有现实意义；BFT/PBFT 类算法更多是用在系统被恶意入侵，故意伪造网络消息的场景里。</p><p>在分布式事务中，集群中的每个服务器节点要管理很多资源对象，每个节点必须保证在并发事务访问这些资源对象时，它们能够始终保持一致性。因此，每个服务器节点需要对自己的管理的资源对象应用一定的并发控制机制。分布式事务中需要所有服务器节点共同保证事务以串行等价的的方式执行。</p><p>也就是说，如果事务 T 对某一个服务器节点上的资源对象 S 的并发访问在事务 U 之前，那么我们需要保证在所有服务器节点上对 S 和其他资源对象的冲突访问，T 始终在 U 之前。</p><h2 id="锁并发控制"><a href="#锁并发控制" class="headerlink" title="锁并发控制"></a>锁并发控制</h2><p>在分布式事务中，某个对象的锁总是本地持有的（在同一个服务器节点上）。是否加锁是由本地锁管理器（Local Lock Manager，LLM）决定的。LLM 决定是满足客户端持锁的请求，还是阻塞客户端发起的分布式事务。但是，事务在所有服务器节点上被提交或者放弃之前，LLM 不能释放任何锁。在使用加锁机制的并发控制中，原子提交协议在进行的过程中资源对象始终被锁住，并且是排他锁，其他事务无法染指这些资源对象。但如果事务在两阶段提交协议的阶段一就被放弃，则互斥锁可以提前释放。</p><p>由于不同服务器节点上的 LLM 独立设置资源对象锁，因此，对于不同的事务，它们加锁的顺序也可能出现不一致。考虑一个场景：事务 T 和 U在服务器 X 和 Y 之间的交错执行：</p><p><a href="https://res.strikefreedom.top/static_res/blog/figures/distributed-dead-locking.png"><img src="https://res.strikefreedom.top/static_res/blog/figures/distributed-dead-locking.png" alt="img"></a></p><ol><li>事务 T 锁住了服务器节点 X 上的资源对象 A，做写入操作；</li><li>事务 U 锁住了服务器节点 Y 上的资源对象 B，做写入操作；</li><li>事务 T 试图读取服务器节点 Y 上的资源对象 B，此时 B 被事务 U 锁住，因此 T 等待锁释放；</li><li>事务 U 试图读取服务器节点 X 上的资源对象 A，此时 A 被事务 T 锁住，因此 U 等待锁释放。</li></ol><p>在服务器节点 X 上，事务 T 在事务 U 之前；而在服务器节点 Y 上，事务 U 在事务 T 之前。这种不一致的事务次序导致了事务之间的循环依赖，从而引起分布式死锁。分布式死锁需要通过特定的方法/算法来检测并解除，一旦检测到死锁，则必须放弃其中的某个事务来解除死锁，然后通知事务协调者，它将会放弃该事务所涉及的所有参与者上的事务。</p><h2 id="时间戳并发控制"><a href="#时间戳并发控制" class="headerlink" title="时间戳并发控制"></a>时间戳并发控制</h2><p>对于单一服务器节点的事务来说，协调者在每个事务启动时会为其分配一个全局唯一的时间戳。通过按照访问资源对象的事务时间戳顺序提交资源对象的版本来强制保证以事务执行的串行等价性。在分布式事务中，协调者必须保证每个事务都会附带全局唯一的时间戳。全局唯一的时间戳由事务访问的第一个协调者发给客户端。如果任意一个服务器节点上的资源对象执行了事务中的一个操作，那么事务时间戳会被发送给该服务器节点上的协调者。</p><p>分布式事务中的所有服务器节点共同保证事务以串行等价的方式执行。例如，如果在某服务器节点上，由事务 U 访问的资源对象版本在事务 T 访问之后提交；而在另一个服务器节点上，事务 T 和事务 U 又访问了同一个资源对象，那么它们也必须按照相同的次序提交资源对象。为了保证所有服务器节点上的事务执行的相同顺序，协调者必须就时间戳排序达成一致。时间戳是一个二元组 &lt; 本地时间戳，服务器 ID &gt; 对。在时间戳的比较排序过程中，首先比较本地时间戳，然后再比较服务器 ID。</p><p>一个可靠的时间戳并发控制应该保证即使各个服务器节点之间的本地时间不同步，也能保证事务之间的相同顺序。但是考虑到效率，各个协调者之间的时间戳还是最好还是要求大致同步。这样的话，事务之间的顺序通常与它们实际开始的时间顺序相一致。可以利用一些本地物理时钟同步方法来保证时间戳的大致同步。</p><p>如果决定利用时间戳机制进行分布式事务的并发控制，那么还需要通过某些方法来解决事务冲突问题。如果为了解决冲突需要放弃某个事务时，相应的协调者会收到通知，并且它将在所有的参与者上放弃该事务。这样，如果事务能够坚持到客户端发起提交请求命令的那个时候，那么这个事务就总能被提交。因此在两阶段提交协议中，正常情况下参与者都会同意提交，唯一一种不同意提交的情况是参与者在事务执行过程中曾经崩溃过。</p><h2 id="乐观并发控制"><a href="#乐观并发控制" class="headerlink" title="乐观并发控制"></a>乐观并发控制</h2><p>加锁机制这一类悲观并发控制有许多明显的缺陷：</p><ul><li><strong>锁的维护带来了很多新的开销</strong>。这些开销在不支持对共享数据并发访问的系统中是不存在的。即使是只读事务（如查询），就算这一类事务不会改变数据的完整性，却仍然需要利用锁来保证数据在读取过程中不会被其他事务修改，然而锁却只在最极端的情况下才会发挥作用。</li><li><strong>锁机制非常容易引发死锁</strong>。预防死锁会严重降低并发度，因此必须利用超时或者死锁检测来解除死锁，但这些死锁解除方案对于交互式的程序来说并不是很理想。</li><li><strong>锁周期过长</strong>。为了避免事务的连锁（雪崩）放弃，锁必须保留到事务结束之时才能释放，这再一次严重降低了系统的并发度。</li></ul><p>由于锁这一类的悲观并发控制有上述的种种弊端，因此研究者们提出了另一种乐观并发控制的机制，以求规避锁机制的天然缺陷，研究者们发现这样的一个现象：在大多数应用中两个客户端事务访问同一个资源对象的可能性其实很低，事务总是能够成功执行，就好像事务之间不存在冲突一样。</p><p>所以事务的乐观并发控制的基本思路就是：各个并发事务只有在执行完成之后并且发出 <code>closeTransaction</code> 请求时，再去检测是否有冲突，如果确实存在冲突，那么就放弃一些事务，然后让客户端重新启动这些事务进行重试。</p><p>在乐观并发控制中，每个事务在提交之前都必须进行验证。事务在验证开始时首先要附加一个事务号，事务的串行化就是根据这些事务号的顺序实现的。分布式事务的验证由一组独立的服务器节点共同完成，每个服务器节点验证访问自己资源对象的事务。这些验证在两阶段提交协议的第一个阶段进行。</p><p><strong>关于分布式事务的并发控制就暂时介绍到这里，如果想要继续深入学习更多并发控制的细节，可以深入阅读《分布式系统：概念与设计》、《数据库系统实现》和《数据库系统概念》等书籍或者其他资料。</strong></p><p>本文通过讲解 <strong>BASE 原则</strong>、<strong>两阶段原子提交协议</strong>、<strong>三阶段原子提交协议</strong>、<strong>Paxos/Multi-Paxos 分布式共识算法的原理与证明</strong>、<strong>Raft 分布式共识算法</strong>和<strong>分布式事务的并发控制</strong>等内容，为读者全面而又深入地讲解分析了分布式事务以及分布式系统的底层核心原理，特别是通过对原子提交协议中的 2PC/3PC 的阐述和分析，以及对分布式共识算法 Paxos 的原理剖析和正确性的证明，最后还有对分布式事务中几种并发控制的介绍，相信能够让读者对分布式事务和分布式系统底层的一致性和并发控制原理有一个深刻的认知，对以后学习和理解分布式系统大有裨益。</p><p>本文不仅仅是简单地介绍分布式事务和分布式系统的底层原理，更是在介绍原理的同时，通过层层递进的方式引导读者去真正地理解分布式系统的底层原理和设计思路，而非让读者死记硬背一些概念，所以希望通过这篇抛砖引玉的文章，能够对本文读者在以后学习、操作甚至是设计分布式系统以及分布式事务时的思路有所开拓。</p><ul><li><a href="https://en.wikipedia.org/wiki/ACID">ACID</a></li><li><a href="https://en.wikipedia.org/wiki/Eventual_consistency">Eventual consistency</a></li><li><a href="https://en.wikipedia.org/wiki/Atomic_commit">Atomic commit</a></li><li><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=558282">A Two-Phase Commit Protocol and its Performance</a></li><li><a href="https://lamport.azurewebsites.net/pubs/lamport-paxos.pdf">The PartTime Parliament</a></li><li><a href="https://lamport.azurewebsites.net/pubs/paxos-simple.pdf">Paxos Made Simple</a></li><li><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2005-112.pdf">Fast Paxos</a></li><li><a href="https://arxiv.org/pdf/1308.1358.pdf">The Performance of Paxos and Fast Paxos</a></li><li><a href="https://read.seas.harvard.edu/~kohler/class/08w-dsi/chandra07paxos.pdf">Paxos Made Live - An Engineering Perspective</a></li><li><a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos (computer science)</a></li><li><a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/chubby-osdi06.pdf">The Chubby lock service for loosely-coupled distributed systems</a></li><li><a href="https://lamport.azurewebsites.net/video/consensus-on-transaction-commit.pdf">Consensus on Transaction Commit</a></li><li><a href="https://www.ics.uci.edu/~cs223/papers/cidr07p15.pdf">Life beyond Distributed Transactions: an Apostate’s Opinion</a></li><li><a href="https://raft.github.io/raft.pdf">In Search of an Understandable Consensus Algorithm</a></li><li><a href="https://www.youtube.com/watch?v=JEpsBg0AO6o">Paxos lecture (Raft user study)</a></li><li><a href="https://ce.guilan.ac.ir/images/other/soft/distribdystems.pdf">Distributed Systems: Concepts and Design</a></li><li><a href="https://www.microsoft.com/en-us/research/uploads/prod/1996/10/Acrobat-58-Copy.pdf">How to Build a Highly Available System Using Consensus</a></li><li><a href="https://zh.wikipedia.org/wiki/%E6%95%B0%E5%AD%A6%E5%BD%92%E7%BA%B3%E6%B3%95">数学归纳法</a></li><li><a href="https://yeasy.gitbook.io/blockchain_guide/04_distributed_system/algorithms">共识算法</a></li><li><a href="https://pubs.opengroup.org/onlinepubs/009680699/toc.pdf">Distributed Transaction Processing: The XA Specification</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术修养</tag>
      
      <tag>分布式事务</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【月报】2023-08-断桥残雪</title>
    <link href="/2023/09/01/2023-08/"/>
    <url>/2023/09/01/2023-08/</url>
    
    <content type="html"><![CDATA[<p><img src="/../img/xihu.jpg" alt="断桥残雪"></p><blockquote><p>断桥之生命不能承受之轻，晚上的西湖人真的很多。</p></blockquote><h2 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h2><ul><li>设计了一个比较重要的新需求的方案和技术实现</li><li>团队维护的一个历史遗漏项目是 C++ 技术栈的，团队中没有人对 C++ 是比较熟悉的，并且与该项目相关的人都跑路了，可以说是烫手山芋一个。之前大师在的时候，大师还能顶一顶，现在没人顶了。在处理一个 case 中发现其中存在的代码错误，花了一些功夫熟悉了下整个项目的结构和 C++ 的基础知识，最后把问题给解决了。C++ 真好玩😭 </li></ul><h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><h3 id="书籍"><a href="#书籍" class="headerlink" title="书籍"></a>书籍</h3><ul><li><p>《冬牧场》</p><blockquote><p>应该是出于农耕文明对游牧文化的向往吧，我一直对草原上的生活抱有很大的兴趣。冬牧场里，李娟展示了他们的生活，既有白雪铺满大地的美景，也有终日驱赶牛羊的艰辛劳顿。如果是三个月，我不清楚我是否能够忍受那份孤寂。</p></blockquote></li><li><p>《阿勒泰的角落》</p><blockquote><p>顺着冬牧场的余温，又连着通读了阿勒泰的角落。富蕴县上的小镇生活和我记忆中的小镇生活虽然一个远在北疆，一个在江西中部，却依然拥有共鸣。或许，每一处小镇都是一样的。</p></blockquote></li></ul><h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><h3 id="杭州行"><a href="#杭州行" class="headerlink" title="杭州行"></a>杭州行</h3><p>去杭州和道文、文杰小聚了一天。当天晚上围着西湖，走了好几个小时。路过断桥，桥上挤满了人，人头攒动。不过离开断桥后，人流就少了不少，晚上西湖的风吹的很舒服，走了几个小时也不觉得累。</p><p>第二天和刘总一起绕着九溪小径走了好一段路。山中的空气清新，有很多小孩在嬉水，并且时不时迎面有清风吹拂，是个周末休闲的好去处。</p><h3 id="男篮世界杯-amp-阿联退役"><a href="#男篮世界杯-amp-阿联退役" class="headerlink" title="男篮世界杯&amp;阿联退役"></a>男篮世界杯&amp;阿联退役</h3><p>很是怀念阿联，之前阿联在的时候，虽然想赢球也很难，但是至少还能有一个进攻强点。现在这个队，周琦比四年前进步有限，大王一直原地踏步，规划的凯尔同志在进攻端也乏善可陈，最难受的是后卫运球过个半场都得费老大劲。</p><p>中国篮球，何日出头？</p><h3 id="骑行将军山"><a href="#骑行将军山" class="headerlink" title="骑行将军山"></a>骑行将军山</h3><p>和几个同事晚上下班后绕将军山骑行了一圈，好久没有骑这么远了。除开其中一小段有点坑坑洼洼的路段，其他路段晚上骑行真的很舒服，车辆很少。而且当天晚上清风吹拂，很是舒适。</p><h2 id="随便看看-amp-听听"><a href="#随便看看-amp-听听" class="headerlink" title="随便看看&amp;听听"></a>随便看看&amp;听听</h2><h3 id="播客"><a href="#播客" class="headerlink" title="播客"></a>播客</h3><ul><li><p><a href="https://podcasts.apple.com/cn/podcast/%E6%9E%AB%E8%A8%80%E6%9E%AB%E8%AF%AD/id1069600190?i=1000564633803">枫言枫语 图拉鼎：在杭州工作和生活是什么体验？</a></p><blockquote><p>想当良渚村村民了！</p></blockquote></li></ul>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>月报</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【月报】2023-07-吉他初体验</title>
    <link href="/2023/08/01/2023-07/"/>
    <url>/2023/08/01/2023-07/</url>
    
    <content type="html"><![CDATA[<p><img src="/../img/jita.jpg" alt="一把新吉他"></p><blockquote><p>买了一把新吉他，手感不错～</p></blockquote><h2 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h2><ol><li>MDM 成功上线 ！！！！</li><li>大师离职了。来到 TrendMicro 这边后挺受大师照顾的，希望大师一切顺利～</li></ol><h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><h3 id="书籍"><a href="#书籍" class="headerlink" title="书籍"></a>书籍</h3><ul><li><p>《AI 3.0》</p><blockquote><p>我不是担忧人工智能变得太聪明、太有侵略性、太恶意，甚至是太有用。相反，我担心我们最为珍视的这些人性特征——智慧、创造力、情感，甚至意识本身都太容易产生了。它们最终不过是一堆“小把戏”，仅仅用一套肤浅而粗暴的算法就可以解释的人类精神。AI 还没有到来。</p></blockquote></li></ul><h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><h3 id="吉他初体验"><a href="#吉他初体验" class="headerlink" title="吉他初体验"></a>吉他初体验</h3><p>因为组内同事的邀请，也报名参加了公司的吉他培训班。买了一把入门的雅马哈 F310，跟着老师每两周上一次课。我比较懒，每次都要到上课前一天晚上疯狂练习，像是回到了开学前狂补作业的学生时代。不过马马虎虎的练习倒也有些收获，现在也能大差不差的跟着五线谱弹上那么一小段，当然，只能弹入门的小曲，各种和弦的快速切换还是手忙脚乱。</p><h3 id="腰痛"><a href="#腰痛" class="headerlink" title="腰痛"></a>腰痛</h3><p>这个月感觉自己的腰是在不行了，在工位上稍微坐久一点，腰部就感受深深的疼痛，只有蹲下来的时候才能疏解。为此我还买了一个护腰，这样在工位坐的之后，可以给腰部一个支撑。不过作用不大，最终还是去体验拍了一个 CT检查了一下。医生让我多锻炼😂</p><h2 id="随便看看-amp-听听"><a href="#随便看看-amp-听听" class="headerlink" title="随便看看&amp;听听"></a>随便看看&amp;听听</h2><h3 id="播客"><a href="#播客" class="headerlink" title="播客"></a>播客</h3><ul><li><p><a href="https://podcasts.apple.com/cn/podcast/004-%E4%B8%8E%E8%BF%9F%E5%85%88%E7%94%9F%E8%81%8A-rust-%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/id1602908129?i=1000567020350">【RustTalk 】与迟先生聊 Rust 与数据库系统</a></p><blockquote><p>成功人士迟先生</p></blockquote></li></ul>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>月报</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【月报】2023-06-登上庐山</title>
    <link href="/2023/07/01/2023-06/"/>
    <url>/2023/07/01/2023-06/</url>
    
    <content type="html"><![CDATA[<p><img src="/../img/lushan.jpg" alt="登上庐山"></p><blockquote><p>终于一睹庐山真面目</p></blockquote><h2 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h2><ol><li>MDM 的工作进入了提测阶段，这个月的工作压力相对来说少了不少。</li><li>帮助 iOS 的同学做了一个需求的改动，改动上比较简单吧，沟通上花了不少时间。</li></ol><h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><h3 id="书籍"><a href="#书籍" class="headerlink" title="书籍"></a>书籍</h3><ul><li><p>《智慧的疆界》</p><blockquote><p><strong>达特矛斯夏季人工智能研究计划</strong>（英语：Dartmouth Summer Research Project on Artificial Intelligence）由<a href="https://zh.wikipedia.org/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E9%BA%A6%E5%8D%A1%E9%94%A1">约翰·麦卡锡</a>等人于1956年8月31日发起，旨在召集志同道合的人共同讨论“<a href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD">人工智能</a>”（此定义正是在那时提出的）。会议持续了一个月，基本上以大范围的<a href="https://zh.wikipedia.org/wiki/%E5%A4%B4%E8%84%91%E9%A3%8E%E6%9A%B4">集思广益</a>为主。这催生了后来人所共知的人工智能革命。</p></blockquote></li></ul><h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><h3 id="庐山真面目"><a href="#庐山真面目" class="headerlink" title="庐山真面目"></a>庐山真面目</h3><p>南京去南昌小宿一晚后和小胖一起自驾去庐山，在山上玩了两天。</p><p>山上的牯岭小镇真的很漂亮，东线和西线景色各异，山风清凉。还废了老大劲去看了三叠泉瀑布，可惜水流不大，但是那三千多个台阶至今回想起来还是后怕。另外，五老峰的云海和庐山的日出也是别样的美景。</p><h3 id="老友记"><a href="#老友记" class="headerlink" title="老友记"></a>老友记</h3><p>这周霞姐的弟弟妹妹来南京玩，大衣也来了，就请他们一起吃了个饭，顺带到处玩了玩，人多的感觉还不错～</p><h2 id="随便看看-amp-听听"><a href="#随便看看-amp-听听" class="headerlink" title="随便看看&amp;听听"></a>随便看看&amp;听听</h2><h3 id="跑者日历"><a href="#跑者日历" class="headerlink" title="跑者日历"></a>跑者日历</h3><ul><li><a href="https://podcasts.apple.com/cn/podcast/%E8%B7%91%E8%80%85%E6%97%A5%E5%8E%86/id1503299913?i=1000611646002">EP177: 首马即巅峰？大满贯赛事——伦敦马拉松初体验</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>月报</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【月报】2023-05-去魔都玩</title>
    <link href="/2023/06/07/2023-05/"/>
    <url>/2023/06/07/2023-05/</url>
    
    <content type="html"><![CDATA[<p><img src="/../img/shanghai.jpg" alt="外滩"></p><blockquote><p>拍摄于上海外滩</p></blockquote><h2 id="工作与学习"><a href="#工作与学习" class="headerlink" title="工作与学习"></a>工作与学习</h2><h3 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h3><ul><li>着手研发 MDM 里面关于分组管理的实现，完成的差不多了。</li></ul><h3 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h3><h4 id="英语"><a href="#英语" class="headerlink" title="英语"></a>英语</h4><ul><li>这个月开始刻意的练习英语的听力，主要是通过听英文的播客<a href="https://changelog.com/">changelog</a>和看美剧<a href="https://www.bilibili.com/bangumi/media/md28234419">老友记</a>。我一般在早上开始工作前，或者下午三四点的时候，一边听着<a href="https://changelog.com/">changelog</a>一边敲代码，感觉还不错。另外，我挪移了大部分的下班休闲时间来看老友记，每天躺在床上，闲适的看剧，会让我感觉很放松，我很喜欢。</li></ul><h4 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h4><ul><li>这个月的技术有些荒废了，除了日常看下别人的开源博客和一些技术周报，似乎并没有刻意地进行技术学习。简单来说，就是懒了。六月份要重拾起来！</li></ul><h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><h3 id="魔都之旅"><a href="#魔都之旅" class="headerlink" title="魔都之旅"></a>魔都之旅</h3><p>可能从小生活在乡镇吧，我一直对大城市抱有憧憬。大学的时候最想去的城市的是北京，从北京实习离职回南昌时，我留了不少的行李在北京，放在朋友租的地方。那时候我想，七月份我一定还会回来的。只因后来深圳有更好的工作机会，转而投向深圳。</p><p>在深圳工作的时候，我又一直谋划着哪一天可以到上海去。是的，那时候我开始想去上海了。想着深圳回上饶那么远，那么耗时，北京和上饶的南北之别，而且又没啥朋友在北京（我的大部分同学朋友都在上海），似乎并不是一个那么好的去处。所以如果有的选，上海似乎是最好的归宿。然后在离开深圳的时候，我却来到了南京。又是一个因为生存的决定。</p><p>好在南京离开上海不远，高铁两个小时不到，即可到达。</p><p>一下虹桥站，我就直奔景点去了。武康路，武康大厦，静安寺，豫园，城隍庙广场，南京路步行街，外滩，世博会博物馆，梵高展，中共一大遗址。也算是特种兵了一回。现在回想起来，脑海里弥漫着的是现代都市的繁华霓虹和民国时代的小资格调。可能是时间还是太短暂了吧，很多景点都是走马观花，并没有好好的感受，希望以后能在上海住上一段时间，半年或者一年。</p><p>我和泽锋在一个不知名公园歇脚的时候，还帮忙拍了一家四兄妹的老照片复刻（老照片上，年长的姐姐坐在公园的座椅上看当日的报刊，些许年幼的妹妹坐在姐姐旁边，半弓着腰看向姐姐一侧，看着最小的一个弟弟和妹妹则站在座椅后面，身体前倾着看着报刊，一脸认真的模样）。时间总是不知觉的被偷走，老照片上四兄妹到现在已经是两鬓些许斑白的年纪。很幸运能与他们偶遇，为他们拍照，希望他们可以身体健康。</p><h3 id="《老友记》"><a href="#《老友记》" class="headerlink" title="《老友记》"></a>《老友记》</h3><p>我一直在很多地方看到别人推荐《老友记》，但是一直未曾亲自刷过。出于休闲和英文学习的目的吧，开始刷这部剧。人类终究是群居动物，有朋友的感觉真好。</p><h2 id="推荐"><a href="#推荐" class="headerlink" title="推荐"></a>推荐</h2><h3 id="播客"><a href="#播客" class="headerlink" title="播客"></a>播客</h3><p>国外的的一个技术播客站点: <a href="https://changelog.com/">changelog</a> 。里面主要是关于各种技术的一些杂谈，并且根据了不同领域进行了分类，适合想练习英语听力的程序员食用～</p><p>下月见～</p>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>月报</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【技术修养】关于 MySQL 的基础知识整理</title>
    <link href="/2023/05/12/mysql-literacy/"/>
    <url>/2023/05/12/mysql-literacy/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>作为一个后端开发工程师，数据库是非常重要的知识。对于国内大多数互联网公司来说，MySQL 无疑是最常见也是最多使用的数据库。这篇文章，简单聊聊 MySQL 的一些原理知识和使用经验(里面有些内容来自网络，这里做了归纳整理，相关引用来源放在 reference 中)</p><h2 id="如何设计合理的表结构？"><a href="#如何设计合理的表结构？" class="headerlink" title="如何设计合理的表结构？"></a>如何设计合理的表结构？</h2><p>在后端业务场景中，我们需要对数据库的表结构进行设计，以方便我们更合理的存储和管理业务数据。那我们应该如何设计出简洁的、结构清晰、不冗余、易管理、易查询的数据表？</p><p>众多的实践总结出了一套可复用的方法论。这里主要包含表的设计范式，合理的设计索引</p><h3 id="设计范式-amp-反范式"><a href="#设计范式-amp-反范式" class="headerlink" title="设计范式&amp;反范式"></a>设计范式&amp;反范式</h3><p>数据库主要包含三大范式和逆范式的设计理念。（当然，也存在第四范式，第五范式等等，但是一般满足三大范式就足够应付绝大多数业务场景）</p><h4 id="三大范式"><a href="#三大范式" class="headerlink" title="三大范式"></a>三大范式</h4><p>第一范式</p><ul><li>所谓第一范式(1NF) 是指数据库表的每一列都是不可分割的基本数据项，同一列中不能有多个值。若某一列有多个值，可以将该列单独拆分成一个实体，新实体和原实体间是一对多的关系。</li></ul><p>第二范式</p><ul><li><p>第二范式(2NF) 在第一范式的基础上更进一步，目标是确保表中的每列都和主键相关，即：非主属性必须完全依赖于主键。</p><p>如果一个关系满足第一范式，并且除了主键之外的其他列，都依赖于该主键，则满足第二范式。</p></li></ul><p>第三范式</p><ul><li>第三范式(3NF) 是指实体中的属性不能是其他实体中的非主属性。因为这样会出现冗余。即：属性不依赖于其他非主属性。<br>如果一个实体中出现其他实体的非主属性，可以将这两个实体用外键关联，而不是将另一张表的非主属性直接写在当前表中。</li></ul><h4 id="逆范式"><a href="#逆范式" class="headerlink" title="逆范式"></a>逆范式</h4><p>为什么在有三大范式之后，还会出现逆范式呢？这主要是归结于业务的场景的复杂性和业务对查询速度较高的要求。举个例子，一个业务场景下涉及多张表结构数据，包含一张主题表和多扩展表和属性表。这样的业务需求往往需要多表查询，或者连表 join. 为了降低查询的复杂度和提高查询的响应速度，有时候我们会在主题表里冗余存储扩展表和属性表里面的字段数据，这样可以提供我们的查询效率。</p><blockquote><p>不过在出现需要逆范式的场景时，需要仔细斟酌一下是否有必要。或者之前的表结构是否设计合理。又或者考虑我们是否可以将多表数据旁路汇总到 NoSQL(比如 es, mongoDB) 中，以更好的提高我们的查询效率。</p></blockquote><h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><p>什么是索引？简单来说，索引就像是书的目录，当我们想要查询某个知识的时候，我们会先查询目录，找到对应知识点的页面，再到指定页面进行翻阅，而不需要从头开始一页一页去找。</p><h4 id="索引的原理"><a href="#索引的原理" class="headerlink" title="索引的原理"></a>索引的原理</h4><h5 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h5><p>不同索引的设计会使用的数据结构。对于 MySQL 来说，我们需要重点了解 B+树，B 树，Hash。</p><p>关于 B+ 树、B 树、hash 的介绍可以参考如下 Wikipedia。</p><blockquote><p><a href="https://zh.wikipedia.org/wiki/B%2B%E6%A0%91">Wikipedia: B+树</a></p><p><a href="https://zh.wikipedia.org/wiki/B%E6%A0%91">Wikipedia: B树</a></p><p><a href="https://zh.wikipedia.org/wiki/%E5%93%88%E5%B8%8C%E8%A1%A8">Wikipedia: hash</a></p></blockquote><p>B+ 树中的<strong>每个节点都是一个数据页</strong>，其结构示意图如下</p><p><img src="/../img/B+tree-index.png"></p><p>B 树的结构示意图如下：</p><p><img src="/../img/BTree-index.png"></p><p>Hash 的结构示意图如下：</p><p><img src="/../img/hash-index.png"></p><h5 id="索引分类"><a href="#索引分类" class="headerlink" title="索引分类"></a>索引分类</h5><p><strong>主键索引:</strong> 数据列不允许重复，不允许为NULL，一个表只能有一个主键。</p><p><strong>唯一索引:</strong> 数据列不允许重复，允许为NULL值，一个表允许多个列创建唯一索引。</p><ul><li>可以通过 <code>ALTER TABLE table_name ADD UNIQUE (column);</code> 创建唯一索引</li><li>可以通过 <code>ALTER TABLE table_name ADD UNIQUE (column1,column2);</code> 创建唯一组合索引</li></ul><p><strong>普通索引:</strong> 基本的索引类型，没有唯一性的限制，允许为NULL值。</p><ul><li>可以通过<code>ALTER TABLE table_name ADD INDEX index_name (column);</code>创建普通索引</li><li>可以通过<code>ALTER TABLE table_name ADD INDEX index_name(column1, column2, column3);</code>创建组合索引</li></ul><p><strong>全文索引：</strong> 是目前搜索引擎使用的一种关键技术。</p><p><strong>联合索引：</strong> 通过将多个字段组合成一个索引，该索引就被称为联合索引。</p><blockquote><p>⚠️：在 MySQL B+ 树的索引之下，主键索引的叶子结点存储数据，其他的索引的叶子结点存储的是主键索引的是位置。除非是覆盖索引，不然都需要回表查询。</p></blockquote><h4 id="索引的设计"><a href="#索引的设计" class="headerlink" title="索引的设计"></a>索引的设计</h4><h5 id="索引设计的原则"><a href="#索引设计的原则" class="headerlink" title="索引设计的原则"></a>索引设计的原则</h5><p>1.最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。</p><p>2.=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。</p><p>3.尽量选择区分度高的列作为索引，区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录。</p><p>4.索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’)。</p><p>5.尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。</p><h5 id="设计覆盖索引以避免回表查询"><a href="#设计覆盖索引以避免回表查询" class="headerlink" title="设计覆盖索引以避免回表查询"></a>设计覆盖索引以避免回表查询</h5><p>在 MySQL B+ 树的索引之下，主键索引的叶子结点存储数据，其他的索引的叶子结点存储的是主键索引的是位置。除非是覆盖索引，不然都需要回表查询。</p><p>覆盖索引是指 SQL 中 query 的所有字段，在索引 B+Tree 的叶子节点上都能找得到，这样就不需要回表查询了。</p><blockquote><p>在B+树的索引中，叶子节点可能存储了当前的key值，也可能存储了当前的key值以及整行的数据，这就是聚簇索引和非聚簇索引。 在InnoDB中，只有主键索引是聚簇索引，如果没有主键，则挑选一个唯一键建立聚簇索引。如果没有唯一键，则隐式的生成一个键来建立聚簇索引。</p></blockquote><h5 id="最左前缀原则"><a href="#最左前缀原则" class="headerlink" title="最左前缀原则"></a>最左前缀原则</h5><p>创建联合索引时，我们需要注意创建时的顺序问题，因为联合索引 (a, b, c) 和 (c, b, a) 在使用的时候会存在差别。</p><p>联合索引要能正确使用需要遵循<strong>最左匹配原则</strong>，也就是按照最左优先的方式进行索引的匹配。</p><p>比如，如果创建了一个 <code>(a, b, c)</code> 联合索引，如果查询条件是以下这几种，就可以匹配上联合索引：</p><ul><li>where a=1；</li><li>where a=1 and b=2 and c=3；</li><li>where a=1 and b=2；</li></ul><p>需要注意的是，因为有查询优化器，所以 a 字段在 where 子句的顺序并不重要。</p><p>但是，如果查询条件是以下这几种，因为不符合最左匹配原则，所以就无法匹配上联合索引，联合索引就会失效:</p><ul><li>where b=2；</li><li>where c=3；</li><li>where b=2 and c=3；</li></ul><p>有一个比较特殊的查询条件：where a = 1 and c = 3 ，符合最左匹配吗？</p><p>这种其实严格意义上来说是属于索引截断，不同版本处理方式也不一样。</p><p>MySQL 5.5 的话，前面 a 会走索引，在联合索引找到主键值后，开始回表，到主键索引读取数据行，Server 层从存储引擎层获取到数据行后，然后在 Server 层再比对 c 字段的值。</p><p>从 MySQL 5.6 之后，有一个<strong>索引下推功能</strong>，可以在存储引擎层进行索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，再返还给 Server 层，从而减少回表次数。</p><p>索引下推的大概原理是：截断的字段不会在 Server 层进行条件判断，而是会被下推到「存储引擎层」进行条件判断（因为 c 字段的值是在 <code>(a, b, c)</code> 联合索引里的），然后过滤出符合条件的数据后再返回给 Server 层。由于在引擎层就过滤掉大量的数据，无需再回表读取数据来进行判断，减少回表次数，从而提升了性能。</p><p>比如下面这条 where a = 1 and c = 0 语句，我们可以从执行计划中的 Extra=Using index condition 使用了索引下推功能。</p><p><img src="/../img/Using_index_condition.png" alt="Extra=Using index condition"></p><blockquote><p>为什么联合索引不遵循最左匹配原则就会失效？</p><p>原因是，在联合索引的情况下，数据是按照索引第一列排序，第一列数据相同时才会按照第二列排序。</p><p>也就是说，如果我们想使用联合索引中尽可能多的列，查询条件中的各个列必须是联合索引中从最左边开始连续的列。如果我们仅仅按照第二列搜索，肯定无法走索引。</p></blockquote><h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><h3 id="锁的分类"><a href="#锁的分类" class="headerlink" title="锁的分类"></a>锁的分类</h3><h4 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h4><p>要使用全局锁，则要执行这条命令：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">flush tables <span class="hljs-keyword">with</span> read lock<br></code></pre></td></tr></table></figure><p>执行后，<strong>整个数据库就处于只读状态了</strong>，这时其他线程执行以下操作，都会被阻塞：</p><ul><li>对数据的增删改操作，比如 insert、delete、update等语句；</li><li>对表结构的更改操作，比如 alter table、drop table 等语句。</li></ul><p>如果要释放全局锁，则要执行这条命令：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">unlock tables<br></code></pre></td></tr></table></figure><p>当然，当会话断开了，全局锁会被自动释放。</p><h4 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h4><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">//</span>表级别的共享锁，也就是读锁；<br>lock tables t_student read;<br><br><span class="hljs-regexp">//</span>表级别的独占锁，也就是写锁；<br>lock tables t_stuent write;<br><br><span class="hljs-regexp">//</span> 释放锁<br>unlock tables  <span class="hljs-regexp">//</span> 另外，当会话退出后，也会释放所有表锁。<br></code></pre></td></tr></table></figure><blockquote><p>不过尽量避免在使用 InnoDB 引擎的表使用表锁，因为表锁的颗粒度太大，会影响并发性能，<strong>InnoDB 牛逼的地方在于实现了颗粒度更细的行级锁</strong>。</p></blockquote><p>MySQL 里面表级别的锁有这几种：</p><ul><li>表锁；</li><li>元数据锁（MDL）;</li><li>意向锁；</li><li>AUTO-INC 锁；</li></ul><h4 id="行锁"><a href="#行锁" class="headerlink" title="行锁"></a>行锁</h4><p>InnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁。</p><p>行级锁的类型主要有三类：</p><ul><li>Record Lock，记录锁，也就是仅仅把一条记录锁上；</li><li>Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；</li><li>Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。</li></ul><h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><h3 id="事务的基本要素（ACID）"><a href="#事务的基本要素（ACID）" class="headerlink" title="事务的基本要素（ACID）"></a>事务的基本要素（ACID）</h3><p>1、原子性（Atomicity）：事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像没有发生一样。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位。</p><p>2、一致性（Consistency）：事务开始前和结束后，数据库的完整性约束没有被破坏 。比如A向B转账，不可能A扣了钱，B却没收到。</p><p>3、隔离性（Isolation）：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。</p><p>4、持久性（Durability）：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。</p><h3 id="事务的并发问题"><a href="#事务的并发问题" class="headerlink" title="事务的并发问题"></a>事务的并发问题</h3><p>1、脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据</p><p>2、不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果 不一致。</p><p>3、幻读：系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级，但是系统管理员B就在这个时候插入了一条具体分数的记录，当系统管理员A改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。</p><blockquote><p>小结：不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表</p></blockquote><h3 id="MySQL事务隔离级别"><a href="#MySQL事务隔离级别" class="headerlink" title="MySQL事务隔离级别"></a>MySQL事务隔离级别</h3><table><thead><tr><th>事务隔离级别</th><th>脏读</th><th>不可重复读</th><th>幻读</th></tr></thead><tbody><tr><td>读未提交（read-uncommitted）</td><td>是</td><td>是</td><td>是</td></tr><tr><td>读已提交（read-committed）</td><td>否</td><td>是</td><td>是</td></tr><tr><td>可重复读（repeatable-read）</td><td>否</td><td>否</td><td>是</td></tr><tr><td>串行化（serializable）</td><td>否</td><td>否</td><td>否</td></tr></tbody></table><p>mysql默认的事务隔离级别为repeatable-read</p><h3 id="事务的实现原理"><a href="#事务的实现原理" class="headerlink" title="事务的实现原理"></a>事务的实现原理</h3><p><a href="https://xiaolincoding.com/mysql/transaction/mvcc.html">事务隔离级别是怎么实现的？</a></p><p><a href="https://my.oschina.net/u/4090830/blog/10149386">MYSQL 事务的底层原理</a></p><h2 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h2><h3 id="引擎是什么？"><a href="#引擎是什么？" class="headerlink" title="引擎是什么？"></a>引擎是什么？</h3><p>MySQL中的数据用各种不同的技术存储在文件(或者内存)中。这些技术中的每一种技术都使用不同的存储机制、索引技巧、锁定水平并且最终提供广泛的不同的功能和能力。通过选择不同的技术，你能够获得额外的速度或者功能，从而改善你的应用的整体功能。</p><p>在文件系统中，MySQL将每个数据库（也可以称之为schema）保存为数据目录下的一个子目录。创建表时，MySQL会在数据库子目录下创建一个和表同名的.frm文件保存表的定义。例如创建一个名为 MyTable的表，MySQL会在MyTable.frm文件中保存该表的定义。</p><p>因为MySQL使用文件系统的目录和文件来保存数据库和表的定义，大小写敏感性和具体的平台密切相关。在Windows中，大小写是不敏感的；而在类Unix中则是敏感的。不同的存储引擎保存数据和索引的方式是不同的，但表的定义则是在MySQL服务层统一处理的。</p><h3 id="查看支持的引擎"><a href="#查看支持的引擎" class="headerlink" title="查看支持的引擎"></a>查看支持的引擎</h3><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs abnf">show engines<span class="hljs-comment">;</span><br></code></pre></td></tr></table></figure><p><img src="/../img/show_mysql_engines.png"></p><h3 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h3><p>InnoDB是MySQL默认的事务型引擎，也是最重要、最广泛的存储引擎。它的设计是用来处理大量短期事务，短期事务大部分是正常提交的，很少回滚。InnoDB的性能和自动崩溃恢复特性，使得它在非事务型存储的需求中，也很流行。除了非常特别的原因需要使用其他引擎，InnoDB也是非常好值得花时间研究的对象。</p><p>InnoDB的数据存储在表空间中，表空间是由InnoDB管理的黑盒文件系统，由一系列系统文件组成。InnoDB可以将每个表的数据和索引存放在单独的文件中。InnoDB也可以使用裸设备作为表空间存储介质。</p><p>InnoDB通过间隙锁（next-key locking）防止幻读的出现。InnoDB是基于聚簇索引建立，与其他存储引擎有很大的区别，聚簇索引对主键查询有很高的性能，不过它的二级索引（secondary index，非主键索引）必须包含主键列。所以如果主键列很大的话，索引会很大。</p><h3 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h3><p>在5.1之前，MyISAM是默认的引擎，MyISAM有大量的特心态，包括全文索引、压缩、空间函数。但是MyISAM不支持事务和行级锁，而且在崩溃后无法安全恢复。即使后续版本中MyISAM支持了事务，但是很多人的概念中依然是不支持事务的引擎。</p><p>MyISAM并不是无所事处。对于一些只读数据，或者表空间较小，可以忍受恢复操作，可以使用MyISAM。MyISAM会将表存储在两个文件中：数据文件、索引文件。分别是.MYD、.MYI扩展名。MyISAM表可以包含动态或者静态行。MySQL会根据表定义选择那种行格式。MyISAM表的行记录数，取决于磁盘空间和操作系统中的单个文件最大尺寸。</p><p>在MySQL中，默认配置只能存储256TB的数据。因为指向数据记录的指针长度是6字节。需要修改可以修改表的MAX_ROWS和AVG_ROW_LENGTH选项。两个相乘是最大的大小。会导致重建索引。</p><p>MyISAM是对整个表加锁，而不是行锁，读取的时候对表加共享锁，写入的时候加排他锁。但是在表有读取查询的同时，也可以往表内写入记录。</p><p>对于MyISAM，即使是Blob，Text等等长字段，也可以基于前500字符创建索引，MyISAM支持全文索引，这是一个基于分词创建的索引，也可以支持复杂的查询。</p><p>MyISAM可以选择延迟更新索引键，在创建表的时候指定delay_key_write选项，在每次修改执行完成时，不会立刻将修改的索引数据写入磁盘，而是写到缓存区，只有在清理缓存区或者关闭表的时候才会将索引写入磁盘。这可以极大的提升写入性能，但是在主机崩溃时会造成索引损坏，需要执行修复操作。</p><p>MyISAM另一个特性是支持压缩表。如果数据在写入后不会修改，那么这个表适合MyISAM压缩表。可以使用myisampack对MyISAM表进行打包，压缩表是不可以修改数据的。压缩表可以极大的减少磁盘占用，因此可以减少磁盘IO，提升性能，压缩表也支持索引，但是索引也是只读的。</p><p>整体来说MyISAM并没有那么不堪，但是由于没有行锁机制，所以在海量写入的时候，会导致所有查询处于Locked状态。</p><h3 id="其他存储引擎"><a href="#其他存储引擎" class="headerlink" title="其他存储引擎"></a>其他存储引擎</h3><p>MySQL还有一些其他特殊用途的引擎，有些可能不再支持，具体支持情况参考数据库支持引擎。</p><blockquote><p>这个简单了解即可，实现中基本上用不上这些</p></blockquote><h4 id="Archive"><a href="#Archive" class="headerlink" title="Archive"></a>Archive</h4><p>Archive引擎支持是Insert，Select操作，现在支持索引，Archive引擎会缓存所有的写，并利用zlib对写入行进行压缩，所以比MyISAM表的磁盘IO更少。但是在每次Select查询都需要执行全表扫描。所以在Archive适合日志和数据采集应用。这类应用在分析时往往需要全表扫描忙活着更快的Insert操作场景中也可以使用。</p><p>Archive引擎支持行级锁和专用的缓存区，所以可以实现高并发写入，在查询开始到返回表存在的所有行数之前，Archive会阻止其他Select执行，用来实现一致性读。另外也实现了批量写入结束前批量写入数据对读操作不可见，这种机制模仿了事务和MVCC的特性，但是Archive不是一个事务型引擎，而是针对高写入压缩做了优化的简单引擎。</p><h4 id="Blackhole"><a href="#Blackhole" class="headerlink" title="Blackhole"></a>Blackhole</h4><p>Blackhole没有实现任何存储机制，它会舍弃所有写入数据，不做任何保存，但是服务器会记录Blackhole表的日志，用于复制数据到备库，或者只是简单的记录到日志，这种特殊的存储引擎可以在一些特俗的复制架构和日志审核时发挥作用。但是不推荐。</p><h4 id="CSV"><a href="#CSV" class="headerlink" title="CSV"></a>CSV</h4><p>CSV引擎可以将普通的CSV文件作为MySQL表来处理，但是这种表不支持索引，CSV可以在数据库运行时拷贝或者拷出文件，可以将Excel等电子表格中的数据存储未CSV文件，然后复制到MySQL中，就能在MySQL中打开使用。同样，如果将数据写入到一个CSV引擎表，其他外部程序也可以从表的数据文件中读取CSV的数据。因此CSV可以作为数据交换机制。非常好用。</p><h4 id="Federated"><a href="#Federated" class="headerlink" title="Federated"></a>Federated</h4><p>Federated引擎是访问其他MySQL服务器的一个代理，它会创建一个到远程MySQL服务器的客户端连接，并将查询传输到远程服务器执行，然后提取或者发送需要的数据。最初设计该存储引擎是为了和企业级数据库如MicrosoftSQLServer和Oracle的类似特性竞争的，可以说更多的是一种市场行为。尽管该引擎看起来提供了一种很好的跨服务器的灵活性，但也经常带来问题，因此默认是禁用的。</p><h4 id="Memroy"><a href="#Memroy" class="headerlink" title="Memroy"></a>Memroy</h4><p>如果需要快速地访问数据，并且这些数据不会被修改，重启以后丢失也没有关系，那么使用Memory表（以前也叫做HEAP表）是非常有用的。Memory表至少比MyISAM表要快一个数量级，因为所有的数据都保存在内存中，不需要进行磁盘I/O。Memory表的结构在重启以后还会保留，但数据会丢失。</p><p>Memroy表在很多场景可以发挥好的作用：</p><ol><li>用于查找（lookup）或者映射（mapping）表，例如将邮编和州名映射的表。</li><li>用于缓存周期性聚合数据（periodicallyaggregateddata）的结果。</li><li>用于保存数据分析中产生的中间数据。</li></ol><p>Memory表支持Hash索引，因此查找操作非常快。虽然Memory表的速度非常快，但还是无法取代传统的基于磁盘的表。Memroy表是表级锁，因此并发写入的性能较低。它不支持BLOB或TEXT类型的列，并且每行的长度是固定的，所以即使指定了VARCHAR列，实际存储时也会转换成CHAR，这可能导致部分内存的浪费。如果MySQL在执行查询的过程中需要使用临时表来保存中间结果，内部使用的临时表就是Memory表。如果中间结果太大超出了Memory表的限制，或者含有BLOB或TEXT字段，则临时表会转换成MyISAM表。</p><h4 id="Merge"><a href="#Merge" class="headerlink" title="Merge"></a>Merge</h4><p>Merge引擎是My ISAM引擎的一个变种。Merge表是由多个MyISAM表合并而来的虚拟表。如果将MySQL用于日志或者数据仓库类应用，该引擎可以发挥作用。但是引入分区功能后，该引擎已经被放弃</p><h4 id="NDB-集群-引擎"><a href="#NDB-集群-引擎" class="headerlink" title="NDB 集群 引擎"></a>NDB 集群 引擎</h4><p>NDB集群存储引擎，作为SQL和NDB原生协议之间的接口。MySQL服务器、NDB集群存储引擎，以及分布式的、share-nothing的、容灾的、高可用的NDB数据库的组合，被称为MySQL集群（MySQLCluster）。</p><h3 id="慢-SQL-排查"><a href="#慢-SQL-排查" class="headerlink" title="慢 SQL 排查"></a>慢 SQL 排查</h3><h4 id="查询优化神器-explain命令"><a href="#查询优化神器-explain命令" class="headerlink" title="查询优化神器 - explain命令"></a>查询优化神器 - explain命令</h4><p>关于explain命令相信大家并不陌生，具体用法和字段含义可以参考官网<a href="http://dev.mysql.com/doc/refman/5.5/en/explain-output.html">explain-output</a>，这里需要强调rows是核心指标，绝大部分rows小的语句执行一定很快（有例外，下面会讲到）。所以优化语句基本上都是在优化rows。</p><h4 id="慢查询优化基本步骤"><a href="#慢查询优化基本步骤" class="headerlink" title="慢查询优化基本步骤"></a>慢查询优化基本步骤</h4><ol><li>先运行看看是否真的很慢，注意设置SQL_NO_CACHE</li><li>where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高</li><li>explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询）</li><li>order by limit 形式的sql语句让排序的表优先查</li><li>了解业务方使用场景</li><li>加索引时参照建索引的几大原则</li><li>观察结果，不符合预期继续从0分析</li></ol><h4 id="开启慢查询"><a href="#开启慢查询" class="headerlink" title="开启慢查询"></a>开启慢查询</h4><p>有两种方式可以开启慢查询</p><ol><li>修改配置文件</li><li>设置全局变量</li></ol><p>方式一需要修改配置文件 my.ini，在[mysqld]段落中加入如下参数：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-section">[mysqld]</span><span class="hljs-attr">log_output</span>=<span class="hljs-string">&#x27;FILE,TABLE&#x27;</span>slow_query_log=<span class="hljs-string">&#x27;ON&#x27;</span>long_query_time=<span class="hljs-number">0.001</span><br></code></pre></td></tr></table></figure><p>然后需要重启 MySQL 才可以生效，命令为 <code>service mysqld restart</code></p><p>方式二无需重启即可生效，但是重启会导致设置失效，设置的命令如下所示：</p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stata"><span class="hljs-keyword">SET</span> <span class="hljs-keyword">GLOBAL</span> slow_query_log = &#x27;<span class="hljs-keyword">ON</span>&#x27;;<span class="hljs-keyword">SET</span> <span class="hljs-keyword">GLOBAL</span> log_output = &#x27;<span class="hljs-keyword">FILE</span>,<span class="hljs-keyword">TABLE</span>&#x27;;<span class="hljs-keyword">SET</span> <span class="hljs-keyword">GLOBAL</span> long_query_time = 0.001;<br></code></pre></td></tr></table></figure><p>这样就可以将慢查询日志同时记录在文件以及 mysql.slow_log 表中。</p><p>通过第二种方式开启慢查询日志，然后使用全表查询语句 <code>SELECT * FROM user</code></p><p>然后再查询慢查询日志：<code>SELECT * FROM mysql.slow_log</code>，可以发现其中有这样一条记录：</p><p><img src="/../img/slow_log_1.png" alt="slow log"></p><p>其中，<code>start_time</code> 为执行时间，<code>user_host</code> 为用户的主机名，<code>query_time</code> 为查询所花费的时间，<code>lock_time</code> 为该查询使用锁的时间，<code>rows_sent</code> 为这条查询返回了多少数据给客户端，<code>rows_examined</code> 表示这条语句扫描了多少行，<code>db</code> 为数据库，<code>sql_text</code> 为这条 SQL，<code>thread_id</code> 为执行这条查询的线程 id。</p><p>这样我们就可以通过 slow_log 表的数据进行分析，然后对 SQL 进行调优了。</p><p>以上是通过 Table 来进行分析的，下面来通过文件的慢查询是怎么样的。</p><p>如果不知道文件保存在哪里，可以使用 <code>SHOW VARIABLES LIKE &#39;%slow_query_log_file%&#39;</code> 来查看文件保存位置，打开慢查询日志文件，可以看出每五行表示一个慢 SQL，这样查看比较费事，可以使用一些工具来查看。</p><p><img src="/../img/slow_query_log_file.png" alt="slow_query_log_file">慢查询日志文件</p><h4 id="mysqldumpslow"><a href="#mysqldumpslow" class="headerlink" title="mysqldumpslow"></a>mysqldumpslow</h4><p>MySQL 内置了 <strong>mysqldumpslow</strong> 这个工具来帮助我们分析慢查询日志文件，Windows 环境下使用该工具需要安装 Perl 环境。</p><p>可以通过 <code>-help</code> 来查看它的命令参数：</p><p><img src="/../img/mysqldumpslow_help.png" alt="mysqldumpslow help"></p><p>比如我们可以通过 <code>mysqldumpslow -s t 10 LAPTOP-8817LKVE-slow.log</code> 命令得到按照查询时间排序的 10 条 SQL 。</p><p><img src="/../img/mysqldumpslow_result.png" alt="mysqldumpslow result"></p><h4 id="pt-query-digest"><a href="#pt-query-digest" class="headerlink" title="pt-query-digest"></a>pt-query-digest</h4><p>除此之外还有 <strong>pt-query-digest</strong>，这个是 Percona Toolkit 中的工具之一，下载地址：<code>https://www.percona.com/downloads/percona-toolkit/LATEST/</code>，如果是 Windows 系统，可以在安装 Perl 的环境下，把脚本下载下来：<code>https://raw.githubusercontent.com/percona/percona-toolkit/3.x/bin/pt-query-digest</code></p><p>下面先对 <strong>pt-query-digest</strong> 进行简单的介绍：</p><p><strong>pt-query-digest</strong> 是用于分析 MySQL 慢查询的一个第三方工具，可以分析 binlog、General log 和 slowlog，也可以通过 showprocesslist 或者通过 tcpdump 抓取的 MySQL 协议数据来进行分析，可以把分析结果输出到文件中，分析过程是先对查询语句的条件进行参数化，然后对参数化以后的查询进行分组统计，统计出各查询的执行时间、次数、占比等，可以借助分析结果找出问题进行优化。</p><p>有兴趣的可以先下载下来自己玩玩，将在后续的文章中对 <strong>pt-query-digest</strong> 工具进行详细介绍。</p><h4 id="show-processlist"><a href="#show-processlist" class="headerlink" title="show processlist"></a>show processlist</h4><p>还有种情况是慢查询还在执行中，慢查询日志里是找不到慢 SQL 呢，这个时候可以用 <code>show processlist</code> 命令来寻找慢查询，该命令可以显示正在运行的线程，执行结果如下图所示，可以根据 <code>Time</code> 的大小来判断是否为慢查询。</p><p><img src="/../img/show_processlist.png" alt="show processlist"></p><h2 id="经验之谈"><a href="#经验之谈" class="headerlink" title="经验之谈"></a>经验之谈</h2><ul><li>设计表的时候要考虑范式，避免不合理的表结构设计</li><li>创建表字段的时候一定要考虑好字段的大小，避免过大或过小</li><li>善用索引</li><li>学会慢查询的一些技巧</li><li>学会 MySQL dump 的技巧<ul><li><a href="https://www.cnblogs.com/chenmh/p/5300370.html">MySQL mysqldump数据导出详解</a></li><li><a href="https://garywu520.github.io/2018/07/02/mysqldump%E5%A4%87%E4%BB%BD%E9%81%BF%E5%85%8D%E9%94%81%E8%A1%A8/">mysqldump备份避免表锁</a></li><li><a href="https://juejin.cn/post/7023171050619797540">mysqldump备份时导致所有数据表锁定，无法提供服务</a></li></ul></li></ul><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://awesome-programming-books.github.io/mysql/MySQL%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%EF%BC%9AInnoDB%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E.pdf">MySQL技术内幕：InnoDB存储引擎</a></li><li><a href="https://zhuanlan.zhihu.com/p/356216273">知乎：彻底搞清楚数据库 E-R 模型设计</a></li><li><a href="https://www.dbvis.com/thetable/mysqls-utf-8-is-it-real/">MySQL’s UTF-8: Is It Real?</a></li><li><a href="https://xiaolincoding.com/mysql/lock/mysql_lock.html#%E5%85%A8%E5%B1%80%E9%94%81">MySQL 有哪些锁？</a></li><li><a href="https://xiaolincoding.com/mysql/transaction/mvcc.html">事务隔离级别是怎么实现的？</a></li><li><a href="https://my.oschina.net/u/4090830/blog/10149386">MYSQL 事务的底层原理</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术修养</tag>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【月报】2023-04-湘北军团</title>
    <link href="/2023/05/07/2023-04/"/>
    <url>/2023/05/07/2023-04/</url>
    
    <content type="html"><![CDATA[<p><img src="/../img/xiangbeijuntuan.jpg" alt="湘北军团"></p><blockquote><p>久违了，湘北军团。迟到了二十多年的全国大赛终究没有缺席。</p></blockquote><h2 id="工作与学习"><a href="#工作与学习" class="headerlink" title="工作与学习"></a>工作与学习</h2><h3 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h3><p>因为工作的需求，这个月花了较多的时间投入到 GRPC 框架的学习和使用上。包括 GRPC 项目结构的搭建，跨 GRPC 服务中 context 的传递，GRPC interceptor 的使用，接口测试， 以及关于 protobuf 文件的管理。因为之前有 RPC 框架使用经验，所以上手还算是比较快的。</p><p>但是关于 GRPC IDL 文件的管理还是花了不少心思去研究了一下。之前在腾讯的时候，有一个独立的平台来对 protobuf 文件进行管理，可以直接在平台上进行 protobuf 文件的定义和修改，并且平台会帮你生成桩代码，且提供版本管理的功能。因为目前所在公司并没有提供这个的平台，所以 protobuf 文件的管理需要另寻它法。经过调研，大体上有三种方法。</p><p>第一种：存放在代码仓库，直接将项目所依赖到的所有 Proto 文件都存放在 <code>proto/</code> 目录下，不经过开发工具的自动拉取和发布。但是这种一份 proto 文件需要多处维护，容易造成不一致。并且每次都需要程序员手动去介入 复制粘贴。基本都是不采纳的。只建议自己学习练习的时候可以这样使用。</p><p>第二种：独立仓库，即用一个独立的仓库来管理所有的 protobuf 文件。提前提供好生成桩代码的脚本文件，将生成的桩代码作为 sdk 引入使用。</p><p>第三种：镜像仓库，也是用一个独立的仓库来管理所有的 protobuf 文件。通过 ci 生成桩代码，并将桩代码同步到镜像仓库中(可以是一个 api 大仓，或者是多个子项目的小仓)。主要目的是将 protobuf 文件和桩代码文件分开管理。</p><p>同时对于第二种和第三种方法，在使用上，也有不同选择。用户可以选择用 submodule 的方法，也可以使用  se mantic version。</p><p>基于一些对比思考，我最终采用了镜像仓库 + api 大仓(通过结构来划分领域) + semantic version.</p><p>理由如下：镜像仓库将 protobuf 文件和桩代码分开管理，满足接口定义与实现划分的抽象理念，后续如果有其他语言的服务，方便扩展(修改 ci 即可)。根据 <a href="https://github.com/googleapis/googleapis">googleapis</a> 的设计，以及我们服务的规模(体量小，微服务划分不算太多)，我们倾向于对于 protobuf 的统一管理，即 api 大仓。同时采用 semantic version 来进行版本管理, 没有选择 submodule 的方式主要是因为 semantic version 这种方式更容易理解和使用，submodule 更多是用在 go 语言项目中，并且基于分支的使用方式不利于后续的管理，且在出现错误的时候，需要回滚代码。</p><p>Reference：</p><ul><li><p><a href="https://grpc.io/">GRPC 官方文档</a></p></li><li><p><a href="https://github.com/golang-standards/project-layout">Standard Go Project Layout</a></p></li><li><p><a href="https://laiye.com/news/post/2585.html">来也科技 Protobuf 最佳工程实践</a></p></li><li><p><a href="https://yuyy.info/?p=1980">Gitlab CI/CD 实践六：统一管理 protocol buffer，API 大仓设计与实现</a></p></li><li><p><a href="https://github.com/googleapis/googleapis">googleapis</a></p></li></ul><h3 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h3><h4 id="英语"><a href="#英语" class="headerlink" title="英语"></a>英语</h4><p>最近开始了早晨背英语。因为我个人习惯早上醒来后会赖床再躺一会，想着躺着刷手机不如拿来背单词。这样把之前规划的晚上背单词的计划提前到早上，似乎更好一些，一来早上精力更足，很多时候，一天的工作足以消耗你绝大部分的精力，晚上背单词的时候特别容易无精打采，效果不佳。二来减少了一些早上无意义的刷手机的行为，同时让自己更快的进入到良好的状态(刷手机真的很消耗工作的精力)。贵在坚持，希望自己的英语能力能够猪突猛进！</p><h4 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h4><ul><li>《kuberetes 权威指南》时常翻翻</li><li>发现并看了较多的开源博客。主要是关于大数据方面的博客。(发现自己对于数据平台仍旧抱有热情)</li><li>开始学习<a href="https://www.bilibili.com/video/BV1Cm4y1d7Ur/?spm_id_from=333.999.0.0&vd_source=af5b17760a20bb0e435ef05c825f2f19">B站南京大学 jyy 的操作系统课程</a> ，操作系统知识永远是程序员的立身之本。</li></ul><h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><h3 id="无法离地的飞行"><a href="#无法离地的飞行" class="headerlink" title="无法离地的飞行"></a>无法离地的飞行</h3><p>这个月开始比较频繁的开始骑单车上下班了，感觉大概有三分之二左右的时间是骑单车上下班的吧。骑车的感觉很不错，特别是在晚风吹拂的时候。我很喜欢电影《四海》的主题曲《无法离地的飞行》，骑单车会给我那种感觉。</p><h3 id="蒙古草原，天气晴"><a href="#蒙古草原，天气晴" class="headerlink" title="蒙古草原，天气晴"></a>蒙古草原，天气晴</h3><p>B站播放链接：<a href="https://www.bilibili.com/video/BV12P4y1p7FG/?spm_id_from=333.999.0.0&vd_source=af5b17760a20bb0e435ef05c825f2f19">蒙古草原，天气晴（2006）</a></p><blockquote><p>关野：</p><p>​        你好吗？我们一家都很好。你平安回家了吗？</p><p>​        我们这里已经入冬了，最近在渐渐地变冷，你的茶色斑点白马也非常精神地度过了寒冬。我们还是打算去找那些被偷走的马。</p><p>​        普洁今年进了学校，她经常提起你哦。</p><p>​        值此辞旧迎新之际，祝你的家人、朋友以及你本人身体健康。</p><p>​        再见，在再次见面之前。</p><p>​                                                                                                                                 普洁的母亲，艾鲁蒂内琪美古</p></blockquote><p>我为普洁和她的母亲感到深深的难过。希望他们在另一个世界可以幸福。</p><h2 id="推荐播客"><a href="#推荐播客" class="headerlink" title="推荐播客"></a>推荐播客</h2><p>【枫言枫语&amp;梁杰】<a href="https://www.xiaoyuzhoufm.com/episode/61c0dc5c874a732463bf77df">在加拿大工作和生活是什么体验</a></p><p>这个月听的较多的是 <a href="https://talk.swift.gg/">ggtalk 程序员的闲聊节目</a>, 在家里无事的时候，听着梁杰讲他在加拿大的生活也挺有意思的。</p><p>下月见～</p>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>月报</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【工程实践】如何对 GRPC Protobuf 文件进行管理？</title>
    <link href="/2023/04/22/protobuf_management/"/>
    <url>/2023/04/22/protobuf_management/</url>
    
    <content type="html"><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>因为工作的需求，这个月花了较多的时间投入到 GRPC 框架的学习和使用上。包括 GRPC 项目结构的搭建，跨 GRPC 服务中 context 的传递，GRPC interceptor 的使用，接口测试， 以及关于 protobuf 文件的管理。因为之前有 RPC 框架使用经验，所以上手还算是比较快的。</p><p>但是关于 GRPC IDL 文件的管理还是花了不少心思去研究了一下。之前在腾讯的时候，有一个独立的平台来对 protobuf 文件进行管理，可以直接在平台上进行 protobuf 文件的定义和修改，并且平台会帮你生成桩代码，且提供版本管理的功能。因为目前所在公司并没有提供这个的平台，所以 protobuf 文件的管理需要另寻它法。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>经过调研，大体上有三种方法。</p><p>第一种：存放在代码仓库，直接将项目所依赖到的所有 Proto 文件都存放在 <code>proto/</code> 目录下，不经过开发工具的自动拉取和发布。但是这种一份 proto 文件需要多处维护，容易造成不一致。并且每次都需要程序员手动去介入 复制粘贴。基本都是不采纳的。只建议自己学习练习的时候可以这样使用。</p><p>第二种：独立仓库，即用一个独立的仓库来管理所有的 protobuf 文件。提前提供好生成桩代码的脚本文件，将生成的桩代码作为 sdk 引入使用。</p><p>第三种：镜像仓库，也是用一个独立的仓库来管理所有的 protobuf 文件。通过 ci 生成桩代码，并将桩代码同步到镜像仓库中(可以是一个 api 大仓，或者是多个子项目的小仓)。主要目的是将 protobuf 文件和桩代码文件分开管理。</p><p>同时对于第二种和第三种方法，在使用上，也有不同选择。用户可以选择用 submodule 的方法，也可以使用  se mantic version。</p><p>基于一些对比思考，我最终采用了镜像仓库 + api 大仓(通过结构来划分领域) + semantic version. </p><blockquote><p>其中 repo flow 如下：</p><p><img src="/../img/image-20240223223253237.png" alt="protobuf management gitaction work flow"></p><p>版本号管理如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">tag</span> template: v&#123;MAJOR&#125;.&#123;MINOR&#125;.&#123;PATCH&#125;<br><span class="hljs-attribute">for</span> example: v<span class="hljs-number">1</span>.<span class="hljs-number">0</span>.<span class="hljs-number">11</span><br></code></pre></td></tr></table></figure><p>reference: <a href="https://semver.org/">Semantic Versioning 2.0.0</a></p></blockquote><p>理由如下：镜像仓库将 protobuf 文件和桩代码分开管理，满足接口定义与实现划分的抽象理念，后续如果有其他语言的服务，方便扩展(修改 ci 即可)。根据 <a href="https://github.com/googleapis/googleapis">googleapis</a> 的设计，以及我们服务的规模(体量小，微服务划分不算太多)，我们倾向于对于 protobuf 的统一管理，即 api 大仓。同时采用 semantic version 来进行版本管理, 没有选择 submodule 的方式主要是因为 semantic version 这种方式更容易理解和使用，submodule 更多是用在 go 语言项目中，并且基于分支的使用方式不利于后续的管理，且在出现错误的时候，需要回滚代码。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><p><a href="https://grpc.io/">GRPC 官方文档</a></p></li><li><p><a href="https://github.com/golang-standards/project-layout">Standard Go Project Layout</a></p></li><li><p><a href="https://laiye.com/news/post/2585.html">来也科技 Protobuf 最佳工程实践</a></p></li><li><p><a href="https://yuyy.info/?p=1980">Gitlab CI/CD 实践六：统一管理 protocol buffer，API 大仓设计与实现</a></p></li><li><p><a href="https://github.com/googleapis/googleapis">googleapis</a> </p></li></ul>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工程实践</tag>
      
      <tag>protobuf</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【月报】2023-03-大教堂与集市</title>
    <link href="/2023/03/31/2023-03/"/>
    <url>/2023/03/31/2023-03/</url>
    
    <content type="html"><![CDATA[<p><img src="/../img/cathedral_and_market.png" alt="cathedral and market"></p><blockquote><p>这个月拜读了大教堂与集市。开源运动是黑客文化的终极浪漫～</p></blockquote><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>故人西辞黄鹤楼，烟花下月下扬州。李白的千古绝唱平添了扬州这座古城的无限风韵。在我的新年旅行计划中，扬州是里面必不可少的一站，然而我却食言了。事情的缘由是我身份证又又又遗失了，缺少了身份证，出行和住旅都不是很方便，三月出南京旅游的计划也不得不暂时搁置。明天就是四月了，那就四月份再去扬州吧～</p><h2 id="工作与学习"><a href="#工作与学习" class="headerlink" title="工作与学习"></a>工作与学习</h2><ul><li><p>之前一直在做的关于 openTelemetry 的 research 的有了第一阶段的进展。搭建好了生产标准的环境，同时利用团队里面的一个 python 项目作为示例，在团队内部做了一次关于云原生下可观测性的分享。因为被安排了其他方面的任务，这个事项暂时被 pendding，后续再跟进。</p></li><li><p>其二，因为项目需求的缘故，对市场上的 golang 的规则引擎和 sql builder 方案进行了一次 research, 研究了不少开源库，比如 gendry, govaluate 等等，甚有收获。</p></li><li><p>持续对计算机基础和相关技术栈进行学习和巩固</p><ul><li>《网络是怎样连接的》 done</li><li>《linux 内核设计的艺术》 in process</li><li>《kubernetes 权威指南》in process</li></ul></li><li><p>科技读物</p><ul><li>《大教堂与集市》done</li><li>《与开源同行，揭秘PingCAP七年创业实践》done</li></ul></li><li><p>英语</p><ul><li>背单词三天打鱼两天晒网……</li><li>开口说英语（因为有菲律宾的同事来南京出差，待在我们组里。所以每天的 sync 被要求用英文，这下是没得选了，不得不说英文）</li><li>个人感觉自己的英语水平是有一点点提升的，再接再厉！</li></ul></li></ul><h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><ul><li>阅读<ul><li>《当我谈论跑步时，我在谈论什么》done</li><li>《中国历史十五讲》看到第八章</li></ul></li><li>篮球<ul><li>这个月只打了一次篮球，惭愧。</li></ul></li><li>锻炼<ul><li>开始尝试晚上下班后进行室内锻炼，虽然频次不多，一周两三次，似乎精神状态有提升，继续保持～</li></ul></li><li>电影<ul><li>《铃芽之旅》还可以，画面和音乐都挺不错的。个人感觉剧情方面有一些单薄。</li></ul></li><li>动漫<ul><li>花了一个周末的时间，补番《画江湖之不良人》，一步步看着画江湖的剧情越来越好。想着第一次看不良人的时候我还在上高中，真是时光荏苒。</li></ul></li></ul><h2 id="推荐播客"><a href="#推荐播客" class="headerlink" title="推荐播客"></a>推荐播客</h2><p><a href="https://podcasts.apple.com/cn/podcast/%E5%BC%80%E6%BA%90%E9%9D%A2%E5%AF%B9%E9%9D%A2/id1587487089?i=1000554056927">S01E07 面对开放的大门，技术小白可以怎样开始参与开源</a></p><p>下月见～</p>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>月报</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【月报】2023-02-秦淮河畔</title>
    <link href="/2023/02/28/2023-02/"/>
    <url>/2023/02/28/2023-02/</url>
    
    <content type="html"><![CDATA[<p><img src="/../img/WechatIMG46.jpeg" alt="秦淮河畔"></p><blockquote><p>从老门东走到夫子庙，会路过秦淮河畔，晚上的灯光很美，游船也很有意境。</p></blockquote><p>在南京度过的第一个二月，也是玩的最开心的二月，二月有太多的事情值得回忆了。</p><p>因为我在南京的缘故，一些朋友开始来南京游玩，一般会来我这边住宿。一来我租的房子有两个小房间，有一个客卧可以空出来，住宿不成问题，亦可省下一笔不小的酒店开销；二来自从离开学校之后，大家基本都是聚少离多，很多时候，只是依托于互联网来维系联系，可以线下见一面，聚一次，自然是不易错过的机会。</p><p>二月份共是招待了三波朋友。一是星哥和佳乐，二是小胖和谭总，三是霞姐和大衣。有高中的同学，亦有大学的室友，很多都已经算是多年的老友。老友见面自是不免追忆往昔，聊起以前的一些共同记忆，感慨时光飞逝，物是人非。人总是会变的，年龄上每日按部就班的增加，性格和见解上也会随工作，读研，感情，生活的经历而改变，或好或坏。好在有些东西是不会改变的，就像记忆，南京的相逢让我们的记忆得以重现、延续和补充。</p><p>因为陪同游玩的缘故，去了一些暂时还未涉足的南京景区。老门东、夫子庙、玄武湖、鸡鸣寺、秦淮河畔……南京展示了它作为金陵城的一面，给所有到访金陵的客人，让他们不得不感叹金陵的美好，折服于这个六朝古都的景色和文化底蕴之下。南京城如果是一位君子，我想那也必是温润如玉的一位。</p><p>我会怀念二月的相逢，会怀念2023年二月的南京城。</p><p>除去故人和金陵。二月里，工作依旧是生活的主旋律。</p><p>因为一月做 <a href="https://opentelemetry.io/">openTelemetry</a> 的 research 的缘故，我开始更多的接触和学习关于云原生下服务的可观测性。二月里，我开始尝试在 int 环境上搭建生产环境下 jaeger。在早先的 research 中，更多是学习里面的概念，借助 all in one 的 module 搭一个简单的可供测试的环境。当开始正式考虑后续的正式环境的实践的时候，需要更多的思考架构的设计，服务的安全性，服务的可用性，服务的稳定性，甚至服务的成本和收益。目前来说，自己搭建的 jaeger 很多需要改进和优化的点。线上服务的接入也还需要我去实践具体的 code，道阻且长，希望三月份可以把这个 feature 成功完成。</p><p>同时，因为更多的接触云原生的内容。我也越发觉得自己计算机基础、网络知识的匮乏。它们的重要性自是不必多说，虽然之前也会定时去翻阅一二，但始终不是很深入。所以二月份也给自己定下了一个恶补计算机基础和网络的计划。目前在执行中，我个人的期望是在上半年结束之后可以有较大的提高。</p><p>目前在看的几本书：</p><ul><li>《网络是咋样连接的》</li><li>《TCP-IP协议及其应用》</li><li>《深入浅出HTTPS》</li><li>《Linux 环境编程：从应用到内核》</li><li>《程序是怎么跑起来的》</li><li>《CSAPP》</li><li>《Linux内核设计的艺术》</li></ul><p>另一方面，因为被《万历十五年》勾起的对于历史的盎然兴趣在二月仍旧存有余温。二月份开始看《中国历史十五讲》，这本书主要是从十五个不同的维度来对中国的历史进行不同的阐述。目前已看了六章有余，三月份应该可以看完。想着即使不能读史以明智，了解些前朝逸闻趣事也是一种乐趣，挺好～</p><p>二月份的背单词计划进行的并不是顺利，我的单词计划安排在晚上下班后，但一般我下班，回家，吃饭，洗漱，一套生活琐事下来，时间也将近八点了。很多时候，我会选择躺在床上，看会书，然后背单词。但是总是感觉收效甚微，可能是待在放有厚被子的温床上，人会丧失斗志吧。三月份会每天背完单词后再躺平～</p><p>二月播客时间，推荐播客: <a href="https://podcasts.apple.com/cn/podcast/s3e5-vue-js%E4%BD%9C%E8%80%85%E5%B0%A4%E9%9B%A8%E6%BA%AA-%E6%A1%86%E6%9E%B6%E8%AE%BE%E8%AE%A1%E5%B0%B1%E6%98%AF%E4%B8%8D%E6%96%AD%E5%9C%B0%E8%88%8D%E5%8F%96/id1241589761?i=1000561879795">S3E5|Vue.js 作者尤雨溪: 框架设计就是不断地取舍</a></p><p>就写这么多了，三月见！</p>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>月报</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【月报】2023-01-新年伊始</title>
    <link href="/2023/01/31/2022-01/"/>
    <url>/2023/01/31/2022-01/</url>
    
    <content type="html"><![CDATA[<blockquote><p>去年的时候，我开始经常看一些开源博客和推特。受 @<a href="https://ichn.xyz/blog">ichn-hu</a> 的影响，有不少人开始在互联网上公开自己的周报。我一直有想尝试的想法，一方面记录下生活，一方面也是对自己的督促。但我深知自己生活的寡淡和技术的浅薄，以周为期限对于我来说，似乎还是有些过于短暂了。所以我想着把周报进行时间维度的拉伸，于是有了这篇月报。</p><p>尝试公开写月报，尝试新的生活方式。</p></blockquote><p>工作上，新年的第一个月我开始为团队做 <a href="https://opentelemetry.io/">openTelemetry</a> 的 research。基于团队已有的项目，做了一次简单的 POC。基于opentelemetry官方提供的 go SDK，和我们已有的服务进行集成，采用OTLP Exporter，并最终使用 Jaeger 作为前端可视化的方案进行 trace 调用链路的展示。这也是目前业界内比较通用的方案。整个流程走下来，算是初窥门径。其他方面的工作内容，这里也不便多说，就此作罢。</p><p>生活上，一年一度的农历新年，让我拥有了长达八天的假期，一段清闲的时光。但是我今年却更深地体会到了年味的消失。除夕夜当天到家，没赶上祠堂祭拜。大年初一，零下三度的温度让我不舍起床，也就没去村里的庙里拜菩萨。原本大年初二是大家去外婆家拜年的日子，因为外婆的离世，大家也不约而同的丧失了这个默契。年味在消失吗？我看着路边那群手拿炮仗的小孩们，在窗外的延绵不绝的烟火和鞭炮声中，度过了农历新年。</p><p>也是因为过于清闲，我在过年的时候，开始翻弄起微信读书的书架。因为想多了解些历史，于是翻阅了《万历十五年》。《万历十五年》不算是传统的编年体历史书，黄仁宇先生对于历史考究却不同于一般正史里对历史人物事迹的编撰记录，他更侧重于对人物内心、时代政治环境、人民、经济、社会、封建治国之道、儒家文化的辩证和思考。每个章节似乎自成一体，像是一本人物纪传体小说。也是这本书，又让我激起了对于历史的兴趣，书架中众多的技术书中有了一些历史文学的点缀。</p><p>另外，因为一月份还听了很多的播客，这里推荐一集：<a href="https://podcasts.apple.com/cn/podcast/s3e1-pingcap-cto-%E9%BB%84%E4%B8%9C%E6%97%AD-%E6%8E%A2%E7%B4%A2%E5%BC%80%E6%BA%90%E5%88%9B%E4%B8%9A%E7%9A%84%E5%BA%95%E5%B1%82%E9%80%BB%E8%BE%91-%E4%BB%8Ebasic%E5%88%B0%E6%95%B0%E6%8D%AE%E5%BA%93tidb/id1241589761?i=1000561879687"><strong>S3E1 | PingCAP CTO 黄东旭 - 探索开源创业的底层逻辑, 从Basic到数据库TiDB</strong></a>。以后这个推荐播客就作为保留节目吧～</p><p>就写这么多了，二月见！</p>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>月报</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2022年终总结--平和的面对一切</title>
    <link href="/2022/12/31/2022-year-end-summary/"/>
    <url>/2022/12/31/2022-year-end-summary/</url>
    
    <content type="html"><![CDATA[<h1 id="2022年终总结–平和的面对一切"><a href="#2022年终总结–平和的面对一切" class="headerlink" title="2022年终总结–平和的面对一切"></a>2022年终总结–平和的面对一切</h1><p>该怎么形容我的2022年呢？我想了很久，我没有确切的答案。</p><p>如果一定要用一个词来总结我2022年，我会选择平和，平和的面对的一切，不论是工作还是生活。</p><p>2022算是我正式进入职场的第一个完整年份。如果说2021年我尚且留着一半学生的稚气，那2022年，我已经是身锤百炼的打工人了。工作方面，尽管没有太多技术上的长进，但是对于工作的流程和进度的把控有了更进一步的认知和实践，我学会更好的安排时间来面对繁重的各项工作，也更加明白了职场中的处事原则。以前我觉得只要技术牛逼，到哪里都能发光发热(也确实有这样的人)，但现在我觉得能安安分分把工作完成交付的人才能发光发热，甚至安安分分把领导交付的任务优先完成才能发光发热。我开始觉得工作的本质就是产生商业价值，功能做的再花哨，技术实现多么高性能高可用，最终还是需要用户买单，用户不买单，所做的一切都是无用功的，这就是商业的价值。虽然道理谁都懂，但是当整个部门都在为上云，saas，商业化，盈利来自保的时候，那种感觉是如此的强烈。</p><p>另外一件值得一提的事就是离开腾讯了。</p><p>我是2021年7月份以校招生的身份加入腾讯的。在腾讯一年多的时间里，我学习到的知识，开阔的视野是我以前所不能及的。需求评审，技术方案，开发，UT, CR, CICD,  SLA保障，维护，我对整个开发的流程有了更为清楚的认知，平日里的技术分享和KM里面高质量的文章也是我日常吸取知识的源泉。在离开前的那一个月，每天看一些km里面自己收藏的文章，看看乐问，是一天里较为轻松愉悦的时刻。另外，在腾讯里也认识了很多优秀的人，校招生的封培，codeworld, 以及效能部门和大数据部门里的同事，我从他们身上学到了很多，也交了一些朋友。即使其中有些人和我一样，也都离开了腾讯，大家也偶尔都会在小群里联系。</p><p>我很感谢在腾讯里的经历，也希望腾讯能越来越好。</p><p>我在9月份来到了新的公司，这是完全不同于腾讯的公司文化。我不必每天九点多十点多下班，也不必在周末里加班加点来赶进度，不必每天打开电脑，面对那堆积如山的工单问题，也没有项目经理每天在我工位面前拉通对齐了。我有了更为宽松的工作环境，不再有那么大的工作压力。并且在新公司中，我扮演的角色也从执行者，慢慢开始自己own一些工作项，做一些新技术的research和实践。work life balance, 我想我满意了现在工作。</p><p>生活上，我开始尝试一些新的东西。</p><p>骑行，switch， 摄影，口琴，动漫，甚至在来到南京后，开始更多的出去走动，中山陵，美龄宫，鱼嘴公园，先锋书店，莫愁湖……新的生活是新鲜的，有种探索未知的愉悦。这里面我最喜欢的是骑行，当我骑行在南京的梧桐树下，当骑行的风声在我耳边轻微响起的时候，我感到无比的愉悦，新年的第一骑会选择去骑老山或者黄龙枧吧，神往已久。</p><p>会有遗憾吗？</p><p>今年最大的遗憾是外婆永远的离开了。虽然在外婆病重的时候，我提前请假回家看望了外婆，但那个时候，外婆已是完全不能自理，在神志上也只是稍有片刻才能认出我是谁，每天进食困难，在我用调羹的喂食下勉强能喝下几口粥。虽然不愿意承认，但那时候已是感觉外婆时日无多。在我返回南京一周后，外婆永久的离开了人世。我从一岁开始，就是外婆在抚养我长大，而我却不能在她年事已高病魔缠身的时候在其身边照顾。有无奈，更是愧疚。希望外婆在世界的另外一边，不必再与病魔斗争，万事顺意。我会想念你。</p><p>2023年呢？有什么规划吗？想去做什么？我不知道。</p><p>但是我想，我会更为正确的浪费剩下的时间。</p><p>就写这么多了，明年见！</p>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>年终总结</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2021/10/04/hello-world/"/>
    <url>/2021/10/04/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    <categories>
      
      <category>Hello World</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
